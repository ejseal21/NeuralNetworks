{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Fall 2019\n",
    "\n",
    "CS343: Neural Networks\n",
    "\n",
    "Project 1: Single layer networks\n",
    "\n",
    "**FINAL DUE 11:59pm Thurs Sept 19**\n",
    "- `binary_classification.ipynb`\n",
    "- `adaline.py`\n",
    "- `adaline_logistic.py`\n",
    "- `binary_regression.ipynb` (this notebook)\n",
    "\n",
    "**REMINDER**: Submit rubric on Google Classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from adaline import Adaline\n",
    "\n",
    "# Set the color style so that Professor Layton can see your plots\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "# Make the font size larger\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# Turn off scientific notation when printing\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def plot_adaline_train(net, loss_list, acc_list, plotMarkers=False):\n",
    "    n_epochs = net.get_num_epochs()\n",
    "    lr = net.get_learning_rate()\n",
    "    \n",
    "    x = np.arange(1, n_epochs+1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "    fig.suptitle(f'ADALINE (lr={lr}, {n_epochs} epochs)')\n",
    "    \n",
    "    curveStr = '-r'\n",
    "    if plotMarkers:\n",
    "        curveStr += 'o'\n",
    "    \n",
    "    \n",
    "    ax1.plot(x, loss_list, curveStr)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (Sum squared error)')\n",
    "    ax2.plot(x, acc_list, curveStr)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paste in your code to load Old Faithful data with standardized features below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4) ADALINE for regression\n",
    "\n",
    "Given ADALINE's linear (identity) activation and sum-of-squares loss function, the learned weights can be used for more than just classification. In this task, you will use ADALINE to perform a linear regression (the same neural network subsumes what you did in CS251!).\n",
    "\n",
    "- **In the cell below**, train the ADALINE network to do a regression with `eruptions` as a predictor (standardized x value) and `waiting` (raw) as a response variable (y value) (i.e. use the former to predict the latter). I suggest using the standardized version of the predictor (otherwise you may run into numeric stability issues), but it's fine to use the raw/unstandardized response variable. Default hyperparameters should work well. To help set up the regression network training inputs, think about the regression equation: $y_i = m \\times x_i + b$\n",
    "\n",
    "**Tips:**\n",
    "- **You shouldn't make any code changes to your `Adaline` class.**\n",
    "- Think carefully about the design of your network: **How many input neurons do you need / how many weights do you need to learn the linear regression? What is each weight learning? What are the target values that the network is learning?**\n",
    "- You may need to add a singleton dimension so that that you input ndarray has a defined dimension for Num Features. i.e. shape=(272,1), NOT shape=(272,)\n",
    "\n",
    "Write your training code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Have the cell below create a plot similar to the classification boundary one**, showing a scatter plot of the data and the overlayed regression line. Have the x-axis map onto standardized `eruptions` and y-axis onto raw `waiting` values.\n",
    "\n",
    "**Tips**\n",
    "- You will need to use the model linear equation to go from x values to predicted y values. $y_i = m \\times x_i + b$\n",
    "- Look at the class boundary plot code. You will need to generate linearly spaced x values before plotting your regression y values on your regression line. \n",
    "\n",
    "Write all your code in the cell below, which should output the scatter plot + regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(x_feat_std, y_feat_raw, x_i, y_i):\n",
    "    plt.plot(x_feat_std, y_feat_raw, 'o', x_i, y_i, 'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5) ADALINE and logistic regression\n",
    "\n",
    "In this task, you will extend ADALINE to logistic regression, where we explicitly represent the probability of class membership.\n",
    "\n",
    "For example data point $i$ is 80% likely to be in class A and 20% in class B.\n",
    "\n",
    "**Remember:** Despite the name, logistic regression is actually about solving a **classification** problem. So this is more similar to Task 2 than Task 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logistic regression implementation\n",
    "\n",
    "- Create a subclass of `Adaline` called `AdalineLogistic` in a new file called `adaline_logistic.py`. **Only override existing methods as needed to make the following changes. DO NOT MODIFY `adaline.py` FOR ANY REASON!!**.\n",
    "\n",
    "\n",
    "1. Use the sigmoid activation function. $z = f(x) = \\frac{1}{1+e^{-x}}$\n",
    "2. Represent the output classes as 0 or +1. This should require a code change (activation values >=0.5 are classified as 1, otherwise class 0) and preprocessing of the old faithful data.\n",
    "3. Use the cross-entropy loss function: $\\sum_{i=1}^n \\left [ -y_i Log(f(z_i)) - (1-y_i)Log(1 - f(z_i)) \\right ] $\n",
    "where $z_i$ is the activation to input sample $i$ and $y_i$ is the corresponding $i^{th}$ class label (0 or 1).\n",
    "4. **In the cell below**, train your network using the standardized Old Faithful data. Default hyperparameters should work fine.\n",
    "5. **In the cell below**, plot your loss and accuracy as a function of epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "11. Why did we need to relabel the classes from -1/+1 to 0/1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers\n",
    "\n",
    "11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaline_logistic import AdalineLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **In the cell below,** Plot the logistic regression decision boundary and the data (Use your code from Task 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Test point probabilities\n",
    "\n",
    "#### Questions\n",
    "\n",
    "12. Determine the probability that the following test points belong to either class:\n",
    "\n",
    "Format: standardized (eruptions, waiting)\n",
    "- (0.4, 0.98)\n",
    "- (0.5, -2)\n",
    "- (-1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers\n",
    "\n",
    "12. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Logistic regression on breast cancer diagnosis data\n",
    "\n",
    "In this task, you will use your logistic regression network to classify more complex data. This is a dataset collected by the University of Wisconsin Hospitals, Madison by Dr. William H. Wolberg. Each data sample corresponds to a patient. There are 10 measured features measured from patients (clump thickness, uniformity of cell size, etc) and a binary class label: whether the patient was diagnosed with cancer. You're welcome to read more about the dataset if you are interested. \n",
    "\n",
    "Plotting pairs of features against one another revealed complex relationships. To compress the dimensionality, I performed PCA on the dataset. I saved off the top 4 PCA components and split the data into train and test sets. You're welcome to explore the raw data (download on Project page).\n",
    "\n",
    "**Todo** in the cell below:\n",
    "\n",
    "- Download the PCA cancer train and test data. \n",
    "- Import the data and the classes, and preprocess the data (standardize).\n",
    "- Train the logistic regression network on the training set. **Plot the loss and accuracy across epochs below**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'data/wisconsin_cancer/breast-cancer-wisconsin_train.csv'\n",
    "test_data = 'data/wisconsin_cancer/breast-cancer-wisconsin_test.csv'\n",
    "\n",
    "def preprocess_data(filename, feats, class_var):\n",
    "    '''Imports, standardizes, and returns data (x) and class labels (y).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename: str. filename of data to import.\n",
    "    feats: list. List of strings of the features to import/preprocess/return\n",
    "    class_var: str. Feature name of the class column.\n",
    "    \n",
    "    Returns:\n",
    "    -----------\n",
    "    x: standardized features. \n",
    "    y: Class labels\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "13. How accurately does ADALINE classify the cancer diagnoses on the test set? (**Provide the specific accuracy number**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers\n",
    "\n",
    "13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "**NOTE:** Never integrate extensions into your base project so that it changes the expected behavior of core functions. It is better to duplicate the base project and add features from there.\n",
    "\n",
    "1. Extend the ADALINE model to multi-class classification using the One-Vs-Rest (OvR) method. Recall that with this scheme, we train the network multiple times with each of the $n$ output classes serving as the +1 class (others set to 0 class). For example, for classes [a, b, c] would would train 3x with the following class labels: [1, 0, 0], [0, 1, 0], [0, 0, 1], respectively. We then classify based on the class that generates the highest max probability / activation value. Test it on a dataset with more than two classes (e.g. Iris). \n",
    "2. Create plots of the ADALINE regression after training on different numbers of epochs. One options is to plot all the curves in a single plot and establish a color scheme for time so that the viewer can visually discern the time sequence. Another possibility is to create a NxM grid of plots showing the progression (be sure to label the titles with #epochs).\n",
    "3. Demonstrate how ADALINE can handle multiple linear regression.\n",
    "4. Test the performance of single layer neural networks at classifying a binary class dataset of your choice. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
