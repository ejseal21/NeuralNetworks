{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cole Turner and Ethan Seal**\n",
    "\n",
    "Fall 2019\n",
    "\n",
    "CS 343: Neural Networks\n",
    "\n",
    "Project 2: Multi-layer Perceptrons\n",
    "\n",
    "**Draft due 11:59pm Thurs Sept 26**\n",
    "\n",
    "\n",
    "Summary of files in this project:\n",
    "- `softmax_layer.ipynb`\n",
    "- `single_layer_net.py`\n",
    "- `preprocess_data.py`\n",
    "- `mlp.ipynb`\n",
    "- `mlp.py`\n",
    "\n",
    "**REMINDER**: Submit rubric on Google Classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for obtaining the STL-dataset\n",
    "import load_stl10_dataset\n",
    "\n",
    "# for preprocessing dataset\n",
    "import preprocess_data\n",
    "\n",
    "# Set the color style so that Professor Layton can see your plots\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "# Make the font size larger\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# Turn off scientific notation when printing\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### a. STL-10\n",
    "\n",
    "**TODO**: Run the cell below, to preprocess STL-10 dataset like you did in the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached numpy arrays the images and labels. Loading them...\n",
      "Images are: (5000, 32, 32, 3)\n",
      "Labels are: (5000,)\n",
      "stl_imgs dtype is float64 and it should be float64\n",
      "stl_imgs max is 0.668 and it should be 0.668\n",
      "stl_imgs shape is (5000, 3072) and it should be (5000, 3072)\n",
      "stl_labels span 0->9 and it should be 0->9\n",
      "Train data shape:  (3500, 3072)\n",
      "Train labels shape:  (3500,)\n",
      "Test data shape:  (500, 3072)\n",
      "Test labels shape:  (500,)\n",
      "Validation data shape:  (500, 3072)\n",
      "Validation labels shape:  (500,)\n",
      "dev data shape:  (500, 3072)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from the internet, convert it to Numpy ndarray, resize to 32x32\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "stl_imgs, stl_labels = load_stl10_dataset.load()\n",
    "\n",
    "# Load in the string names for each class\n",
    "classes = np.loadtxt(os.path.join('data', 'stl10_binary', 'class_names.txt'), dtype=str)\n",
    "\n",
    "# Preprocess image pixel values for the MLP net\n",
    "stl_imgs, stl_labels = preprocess_data.preprocess_stl(stl_imgs, stl_labels)\n",
    "print(f'stl_imgs dtype is {stl_imgs.dtype} and it should be float64')\n",
    "print(f'stl_imgs max is {np.max(stl_imgs[:, 1:]):.3f} and it should be 0.668')\n",
    "print(f'stl_imgs shape is {stl_imgs.shape} and it should be (5000, 3072)')\n",
    "print(f'stl_labels span {stl_labels.min()}->{stl_labels.max()} and it should be 0->9')\n",
    "    \n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.create_splits(stl_imgs, stl_labels)  \n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circle in a square\n",
    "\n",
    "**TODO** Run the code below from the other notebook to load in the CIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIS Train data shape:  (80, 2)\n",
      "CIS Train labels shape:  (80,)\n",
      "CIS Validation data shape:  (20, 2)\n",
      "CIS Validation labels shape:  (20,)\n",
      "CIS Test data shape:  (10000, 2)\n",
      "CIS Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "val_size = 20\n",
    "\n",
    "cis_train_path = os.path.join('data', 'cis', 'cis_train.dat')\n",
    "cis_test_path = os.path.join('data', 'cis', 'cis_test.dat')\n",
    "\n",
    "cis_train_all = np.loadtxt(cis_train_path, delimiter='\\t')\n",
    "\n",
    "# shuffle the data\n",
    "s_inds = np.arange(len(cis_train_all))\n",
    "cis_train_all = cis_train_all[s_inds]\n",
    "\n",
    "cis_train_x = cis_train_all[:, :2]\n",
    "cis_train_y = cis_train_all[:, 2].astype(int)\n",
    "\n",
    "cis_val_x = cis_train_x[:val_size]\n",
    "cis_train_x = cis_train_x[val_size:]\n",
    "cis_val_y = cis_train_y[:val_size]\n",
    "cis_train_y = cis_train_y[val_size:]\n",
    "\n",
    "cis_test_all = np.loadtxt(cis_test_path, delimiter='\\t')\n",
    "cis_test_x = cis_test_all[:, :2]\n",
    "cis_test_y = cis_test_all[:, 2].astype(int)\n",
    "\n",
    "print ('CIS Train data shape: ', cis_train_x.shape)\n",
    "print ('CIS Train labels shape: ', cis_train_y.shape)\n",
    "print ('CIS Validation data shape: ', cis_val_x.shape)\n",
    "print ('CIS Validation labels shape: ', cis_val_y.shape)\n",
    "print ('CIS Test data shape: ', cis_test_x.shape)\n",
    "print ('CIS Test labels shape: ', cis_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Circle in a square dataset\n",
    "\n",
    "**Properties:**\n",
    "- 2 classes of features\n",
    "\n",
    "**TODO**:\n",
    "1. Download the circle in a square dataset. Folder structure is `<project folder>/data/cis/<cis dat files>`\n",
    "2. Create numpy arrays for the train/test data and separate variables for the associated labels by running the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIS Train data shape:  (80, 2)\n",
      "CIS Train labels shape:  (80,)\n",
      "CIS Validation data shape:  (20, 2)\n",
      "CIS Validation labels shape:  (20,)\n",
      "CIS Test data shape:  (10000, 2)\n",
      "CIS Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "val_size = 20\n",
    "\n",
    "cis_train_path = os.path.join('data', 'cis', 'cis_train.dat')\n",
    "cis_test_path = os.path.join('data', 'cis', 'cis_test.dat')\n",
    "\n",
    "cis_train_all = np.loadtxt(\n",
    "cis_train_path, delimiter='\\t')\n",
    "\n",
    "cis_train_x = cis_train_all[:, :2]\n",
    "cis_train_y = cis_train_all[:, 2].astype(int)\n",
    "\n",
    "cis_val_x = cis_train_x[:val_size]\n",
    "cis_train_x = cis_train_x[val_size:]\n",
    "cis_val_y = cis_train_y[:val_size]\n",
    "cis_train_y = cis_train_y[val_size:]\n",
    "\n",
    "cis_test_all = np.loadtxt(cis_test_path, delimiter='\\t')\n",
    "cis_test_x = cis_test_all[:, :2]\n",
    "cis_test_y = cis_test_all[:, 2].astype(int)\n",
    "\n",
    "print ('CIS Train data shape: ', cis_train_x.shape)\n",
    "print ('CIS Train labels shape: ', cis_train_y.shape)\n",
    "print ('CIS Validation data shape: ', cis_val_x.shape)\n",
    "print ('CIS Validation labels shape: ', cis_val_y.shape)\n",
    "print ('CIS Test data shape: ', cis_test_x.shape)\n",
    "print ('CIS Test labels shape: ', cis_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you should see a...black circle in a white unit square :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD0CAYAAAC7KMweAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXhU5f338ffsCxMyIEFkV6B3wFbkhxUCKAVZioDiQrX4k9pqn/L8qrZKtWAtLrTU1qI8Vu1ixWrtr4oKAiIiFFAEgdaCgNibTUQWWRSyJ5NZnj8miUNMwgzMnHNm8n1dl1ecnHDO95qc881n7rPctlgshhBCiOxhN7sAIYQQqZHGLYQQWUYatxBCZBlp3EIIkWWkcQshRJaRxi2EEFnGacRGjh4tNfWaw0DAQ1lZtZklNMmqtVm1LrBubVatC6xbm1XrAvNrKyjIszW1rEUkbqfTYXYJTbJqbVatC6xbm1XrAuvWZtW6wNq1tYjGLYQQuUQatxBCZBlp3EIIkWWkcQshRJaRxi2EEFlGGrcQQmQZadwmstlsGftqs5Hkf42vI301JvdfKus8ndrO9P0w+ndjhRqMeD/E6bEl8zxupdQA4Nda6280+P54YAYQBuZqrZ9q7N+bfQNOMOjnxIkKM0s4icvlIC/Pi90uO68QkUiU0tIqwuGo2aWcxOy+0dwNOKe8c1IpdTdwI1De4Psu4FHg67XL1iqlFmutPz2zcnObw2EnP98niUOIWk6ng2DQz+eflxONysQuyUhmqGQ3cHUj3+8N7NJaH9dah4B3gEvSWVwu8vlcZpcghCV5vXJsJOuUiVtr/YpSqnsji1oDxQmvS4H8xtYRCHhMvX3U4bATDPpN234ih8MuaVuIBmw2Gz6fC7fbkMcnJcVKfaOhM3mXSoC8hNd5wInGftDsh8iYPVaVKBj0Y7NJ8xYiUSwWIxyOUlxcaXYp9czuGwUFeU0uO5PG/SHQSynVFigDLgV+ewbrazGkaQtxMjkmUpNy41ZKTQICWus/KaXuBJYRHyufq7U+kO4Cc1EsFpMdVYgEyVzdJr6Q1OWAZ0ouB/xCMOjH5bLu4yKFMEsoFJahkgQt/nncViPpQoiTyTGRGmncJpBhEiFOJsdEaqRxm0DShRAnk2MiNdK4TSDpQoiTyTGRGmncQgjTSeJOjTRuIYTpJHGnRhq34SRZCNGQJO7USOM2mCQLIb5MjovUSOM2mCQLIcSZksZtOEkWQogzI43bYPKJUAhxpqRxG0xGSoT4MhlCTI00biGE6eTkZGqkcQshTCeJOzXSuIUQppPEnRpp3CaQdCHEyeSYSI00bhNIuhDiZHJMpMY6Uyq3GDGZuuw01aWyuvev4dczXXdj62pqW/L7Sy9J3KmRxm0COehPj81m4/e//z2rV6+moqICp9NJJBLBbrcTjUbrvzocjpNeN/Y1FvvyH9BYLHbSz0QiERwOB+FwGIfDUf968uTJjB07Fo/HY+K7kVvivwdp3smSOScNFgz6cTrt0rybkNhQG/taXV3N9ddfz7Jly6ipqSEajRpeo9vt5q9//Svjx4/H6XTidDolkZ+hWCxGTU1E5pxM0Nyck5K4DSfDJM1Zu3Ytv/zlLykuLsbj8VBVVYXX66WyshKfz0dVVRU+n482bdrw6aefmlJjKBTiuuuuo3PnzvTq1YvKysr6Gv1+P4888gjnn38+LpfLlPqykSTu1EjjNlx6xmRzRcOEPXjwYEaOHMm9995LOBympqbG7BKbtH//fvbv3/+l748YMYKXX36ZAQMG4Ha7sdvlE9apxD/5y3uULGnchpOmnWjHjh3cdNNNnDhxAp/PR3l5Oa1ataJt27YcOHDA7PJOy2effcawYcPo0qULBQUFzJs3j65du0oCb0b8D7fZVWQPGeM2WDDow+l0tLjmXZesG7LZbCxevJjvf//7fP7554TDYROqy6xzzjmHF154gQEDBuB0OrHbv7gKt6XtB02RMe4vkzFui2mJB2t5eTlFRUUUFxcDEIlEcLlcVFdX4/V6icViOdm0AQ4dOsTQoUNp3749rVq1orKykjZt2vDOO++Qn5+Pw+Ewu0TTSeJOjTRuw7WMMe6G11z7/X7mzZvH5MmT2bRpE5FIxOQKjXfkyJH6///0008ZOHAgzz33HP3798fpjB+Kub5fNCW+n5hdRfaQxm243G/aED8QBwwYwL59++qvuY5Go9hsthbZtBuzc+dOioqKyM/Pp127drz33nvk5eWdNJTSUkjiTk3L20NMZ8vpu8RisVh9g16yZAmXXHIJlZWVnDhxgpKSkvqhEvGF4uJidu/ezZAhQ9iwYQORSCSn95HGSOJOjSRuE+Ry4rbZbIwcOZINGzZQUVFRf8ehOLVt27Zx7bXXsn37dvLy8nJ6P2lIEndqJHGbIJfSVN1JxUgkQjgcJhqNMn/+fG666SY8Ho+lr8O2ooMHDzJo0CBWrVpVf2doLu0vTZHEnRpJ3CbIpSRls9m44447mDt3LhUV1rjkMttt376dESNGAFBYWMjGjRtp1apVTo9959IxYYRTNm6llB14EugLVAO3aK13JSz/CfBtIArM0lovyFCtOSMXriqJxWJUVVVht9t56KGH6Ny5M7Nnz+bo0aNml5ZT/vOf/3DJJZcwZ84cBg8ejNPpzPp9pzEt4VNFOiXzJ3wC4NVaFwHTgNl1C5RSQeB2oAgYBczJRJG5JhcOPJvNxu9+9zvatm1LIBBg2rRp0rQz5P333+eHP/whVVVVpjxUywi5cEwYKZnGPQR4A0BrvR64KGFZOfAx0Kr2v9zcq9IsG9NFLBajpKSE0tLS+itEfvCDHzBnzhy6desmB16Gbd++naKiIhYvXsyxY8dy7malbDwmzJTMGHdrIPEarohSyqm1rttzPgG2Aw7gV42tIBDw4HSad3eYw2EnGPSbtv1EDkf2PXCobmhn9erVXH/99VRWWue25Jbkgw8+4KqrrgJg4MCBrFixAq/Xi8PhyPrhN5vNhtNpneMUrNU3GkqmcZcAeQmv7QlNewxwDnBu7etlSqm1WuuNiSsoK6s+40LPhNnPHEgUDPqx2bKreX/22WdEo1Euvvhi/vd//5cHH3yQrVu35lzqyybr169n0KBBzJkzh6KiIrxer9klnZH41UlReVZJgoKCvCaXJTNUsha4HEApNRDYmrDsOFAJVGutq4ATQPC0K20hsqVp13183bFjB+eeey6dOnXiqquuYtOmTdK0LWDLli38/Oc/JxKJ1F8rn61DDtlyTFhFMo17AVCllFoHPArcoZS6Uyl1hdZ6DfBPYL1S6l1gB7A8c+Xmhmw5uA4dOsTu3bvrH006aNAgeTSpxaxdu5aLL76Yt99+m6qqqqxtgNlyTFiFPNbVYMGgH5fL2k+Dqxsv/fDDDykqKqK8vFwStsVdeumlvP7663g8npOmUssmoVBYhkoSNPdY19y9ot+yrJ8sPv74YzZv3kxlZSXPP/88w4YNk4lxLe7tt9+mX79+rF27lurq6qxr2pK4UyN3ThrOugdUXUpzuVyMGTOG48ePU11t7ollkbydO3dy33338dprr2G323G5XFmTvLOhRiuRxG046yaL3bt3s2rVKv7zn//w+OOPM2LECHw+n9lliRS89dZbfO1rX2PDhg2EQqGsaYiSuFMjidtgVjyQ6lJZu3btGD9+fP0ztEV22rt3LzNmzGDRokUAuN1uyydvK9dmRZK4DWbFZLFz505eeuklli9fzrRp0xg5cqQk7Sy3atUqCgsL2bx5M+FwWBpjjpGrSgxmpatK6n731dXVjBo1ivfee0+Sdo4ZNmwYixYtwuVy4Xa7AWumW5ks+MtksmDRqF27drFixQpisRhXXXUVZ511FsuWLZNb2nPIqlWr6NGjB8uWLaNv376WbNpgzT8mViaNuwU777zzWLNmDa+++ipVVVWWHMYRZ+7IkSNMnTqVhQsX4nA46m+Pt1KzlH0vNTLG3YJprenTpw+jR4+u/xgtclPfvn2ZO3cuhw8fxmazWappg0xdlipp3CYwO13EYjFisRiFhYUcPHiQpUuXyp2ROe7dd99l8uTJFBQU1P/+rUSmLkuNNG4TmJ12du/ezV133cWPfvQjHA4Hw4YNy+lpsUT8aYJdu3bl0KFDlk3cInkyxm24mGnX1NalrB49enDWWWdx//33157Nlwl9W4LS0lJuvPFGXn/9dVwuF61atbJMw7TaJwCrk5hlArMOlgMHDvC9732PSZMmsW3bNoYMGZKzU2GJxtUl75KSEss0bag7JqR5J0sSt+FspiXuTp06MXz4cKZMmUIkEpHnkLRQZWVlXHPNNSxevBifz4ff7ze9iccTt3X+kFidJG7DmXfr8YEDB3j55Zfp16+fDI+0YE6nk6lTp/Lee+9ht1tjNiZJ3KmRxm04m+HjebFYjGg0SqdOnbjpppvYunWrTIjQgoXDYX7xi1/Qu3dvy1xhIok7NTJUYjjjE/fx48e5+uqrqaiowGaz0b17d7Zs2WJoDcJa3n//fZRS7N+/H6/Xa3rqlsSdGknchjMucdcl7WAwyMyZMzl06BCbN2+Wpi0AqKqqYvjw4ezZs8f0O2clcadGErfhjEvclZWVXHrppZSWlhKNRnG73YRCIUO2LbLDli1b+K//+i8++eQT3G63aclb7pxMjSRuExiVbHw+H8899xxer5e9e/eyZ88eQ7YrsktpaSlDhw7lww8/JBQKmZK85c7J1EjiNoFRqaaqqoqJEydy/PhxuaVdNMnv9/P3v/+d/Px8055ZI4k7NZK4DZf5Me66KwU8Hg+LFi2iV69ecku7aFJFRQVXXnklH330EeFwWBJ3FpDEbYJMJ+5oNEq/fv3Yt28f1dXV2O12uUNSNGvnzp2MHTuW3bt3EwwGcTiMnexDEndqJIaZINOJxm63s2LFCkaNGkVNTY3MaiOSUlxcTFFREatXryYajRqavCVxp0YStwkynbhjsRijR49m+/btRCKRjG5L5I5AIMDq1aspKCgwfGhNEndqJHGbINNJxmazsWLFCiZPnlw/24kQp1JeXs7gwYNZsmQJ1dXVkrgtTBK3CYy4quSKK67gvffekwdJiaT5fD7eeustOnToYPjVJWbfuZltJHGbIFNJJhqNUl5eTlVVFa+++ipTpkyhdevWGdmWyD0VFRVcdNFFPP/885SXlxueuEXybEa8YUePlpr6WwkG/Zw4YY0TdMGgH5crc2fsv/Wtb/Haa6/JTO3itOXl5bFt2zbOPvtsPB6PYdsNhcIUF1tnvzW7bxQU5DX5MUQStwky9ccyEonw+OOPM23aNNq3b5+RbYjcV11dzfDhw3nhhRcoLS01JA1L4k7NKce4lVJ24EmgL1AN3KK13pWwfAxwX+3LfwM/1FrLb6EZmRrPczgcTJs2jXnz5lFeXp6RbYjc53Q6ef311+nSpQs+n8+QbcoYd2qSSdwTAK/WugiYBsyuW6CUygMeBsZprQcCe4F2Gagzp6Q7XUQiEfbv38+BAwe47777+NnPfkbHjh3Tug3RclRUVPD1r3+dxx9/nOPHj0vitqBkGvcQ4A0ArfV64KKEZYOArcBspdQa4LDW+mjaq8wx6U4XDoeDP//5zyil6N69O/fccw8HDx5M6zZEy1JSUsKDDz7I0aNH68+XZLK5SuJOTTKXA7YGihNeR5RSTq11mHi6HgZcCJQBa5RS72qtdySuIBDw4HQaewttIofDTjDoN237iRyO9O+g4XCY6667jmAwyGOPPcbevXslwYgz5nQ6uf7667n11lu5+uqrCQaDGdtWLBbD6bTOcQrW6hsNJdO4S4C8hNf22qYN8BnwT631pwBKqbeJN/GTGndZmbnXEpt9djhRMOgn3TelOZ1Oli5dys9//nO5vV2kTXV1Nc888ww9evQgEAhkdJJrm81GTU1EripJUFCQ1+SyZFrIWuByAKXUQOJDI3XeA76qlGqnlHICA4Htp19qS5D+JBwOhxk8eDAzZ86kZ8+e8rFTpEUgEODWW2/lxRdf5PPPP8/ofiWfEFOTTOJeAIxUSq0jPrfQd5VSdwK7tNaLlFLTgWW1PztPa70tQ7XmiPTv/E6nky1btnDvvfeaPgWVyB3FxcU89NBDXHDBBeTl5WU8cYvkyQ04BgsGfbhc6X3SQE1NDStXrmTTpk08/fTT7Nq169T/SIhT6NixIxdeeCHXXnstEyZMoE2bNhnbViwWk6GSBpq7AUeeVWK49CaLWCyGy+Xi+PHjPPjggzKnpEibw4cPc/vttzNo0CBJ3BYjd04aLJ37ZzQaZd68ecydO5dQKMTUqVPp3r17+jYgWrRIJMKYMWOYPn06R48eleZqIZK4DZbOkSmbzUZBQQE333wzNTU1krZF2sViMf74xz8ybtw4hgwZQqtWrYD0J2Q5L5MaSdxZLBaLsXPnTqZMmULXrl3NLkfkqF69evHmm2+yYsUKKisrM5K8Jc2nRhp3FrPZbPTt25ennnqK/fv3m12OyFFaawYMGMDIkSPxeDwZSceSuFMjjTuLxWIx3nrrLSZNmiRPAxQZc/7556O1ZvXq1YTDYUncFiCN2wTpShc2m43Ro0fz0ksvcezYsbSsU4iGtm7dytlnn83w4cOx2+2SuC1AGrcJ0pkuXnrpJcaMGUN+fn7a1ilEogsvvJCamhrWrVuHzWaTxG0B0rgNF0trurjxxhtZvXo1J06cSNs6hUi0efNmKioqGDx4MJFIRBK3BUjjNkE608UTTzzB17/+dcMeeC9ann79+tGxY0c2b96My+XKYOKW5p0sadyGs6U1XUydOpXt27fLHJMiYzZt2sQHH3xA3759qampyWDiluGSZEnjNlz6bhu22Ww88MADdOnSBYfDvOedi9zWr18/hgwZwq5du3C73ZK4LUAat+HSl7hjsRi//OUvKS4upqamJi3rFKKhTZs2sWTJEs4991xCoZAkbguQxm249CbuqVOn4nA45OSOyJgLL7yQb3/72xw9ehSPxyNXlViANG4TpDNx/+53vyMQCKRlfUI0ZvPmzfzxj38kPz8/w4lbJEseMmWCdCbuKVOmcOjQIcLh8Kn/gRCnoW/fvtx1111EIhHcbndGtmGz2dL6ALZcJ4nbcOkd43766afp3bu3nJwUGfP+++8zY8YMQqEQ4XA4Y4lbRkuSJ4nbcOkd47755pv55z//KScnRcb06dOHOXPmEAwGcToz0zIkcadGErfh0pu4n332WUaPHp2xj7BCbN++nVtuuYX9+/cTjUYlcVuAJG4TpDtxv/nmmzKJgsgYpRQvvvgibdq0wW7PTNaTxJ0aSdwmSGfinjt3Lrfcckv9zCRCpNuOHTsYN24cmzZtksRtEZK4TZDOxH3bbbfxwgsvUFFhjVnsRe4577zzWL58Oa1atcpo4hbJk8RtgnQm7scee4zp06fTtm3btKxTiIb27t3L0KFDefvttzP8rBKRLEncJkhn4p4+fTpPP/20JG6RMR07dmTlypUEAoGMXlUikieJ2wTpShfRaJSZM2cyc+ZMOnToIDu/yIjDhw8zdOhQli1bRmVlpSRuC5DEbYJ0NVi73c7DDz/MnDlzKC8vT8s6hWjorLPOYsWKFQSDQVwuV0a2IaEjNZK4TZDOxH3bbbfx61//mq5du8rOLzKiuLiYESNGsGjRIsrLyyVxW4AkbhOkM3H/5S9/YebMmZK4Rcb4/X6WLl1K27Zt8Xq9GdmGhI7USOI2QbrSRSQSYeLEifz2t7+lR48eGbtUS7Rs4XCY8ePHs2DBAkpLSzOyDUncqZHEbYJ0pQuHw8HSpUu5++675aoSkVEvvfQSHTp0wO/3194sk96ELIk7NRLRslgkEuGSSy7h4YcfprCwUBK3yAiXy8UNN9zA/PnzKSkpyUiTlcSdmlMmbqWUHXgS6AtUA7dorXc18jNLgIVa6z9kolDxZQ6Hg82bN3PXXXdl7DItISorK3n66afp2rUrgUBAErcFJBPRJgBerXURMA2Y3cjP/AKQW/eSkr7mGolE6N69O7/61a8oLCyUnV9kRH5+Pj/60Y949dVXKS4ulsRtAcmMcQ8B3gDQWq9XSl2UuFApdS0QBZamv7zck86d3uFwcOzYMaZPn05VVZXs/CIjPvvsM2bNmkVhYSF5eXmSuC0gmcbdGihOeB1RSjm11mGl1FeBScC1wIymVhAIeHA6zZuhxeGwEwz6Tdt+Irs9vTvo1VdfTZ8+fZg4cSLbtm1L67pFy9alSxf69euH3W5n9uzZXHnllYwdO5bWrVtnZHtOp3WOU7BW32gomcZdAuQlvLZrresmOJwMdAJWAt2BkFJqr9b6jcQVlJVVp6HU0xcM+jlxwhpXXQSDftJ9DrGwsJD77ruPyZMnEwqFiEQi6d2AaJEOHDjAE088wTe+8Y36CakzlYxjsRjhcJTi4sqMrP90mN03CgrymlyWTAtZC1wOoJQaCGytW6C1vltrPUBr/Q3gL8AjDZu2yLyamhpKS0u5/fbb6datm9nliBzRrVs3Fi1axGuvvUZpaWlGhzNkqCQ1ySTuBcBIpdQ6wAZ8Vyl1J7BLa70oo9WJpDidTs455xxuvfVWme1dpE3d41yvuOIKvF5vRsa268j5mdScsnFrraPAlAbf/k8jP3d/mmoSKYpEInz44Yd873vfY9GiRezbt8/skkQO6NmzJ9u2bcPr9TJmzJiMzrIkiTs1csdGDnA4HPTv359nn32WI0eOmF2OyBE7d+6kc+fOjB07FrfbndFULIk7NdK4c0A0GmX58uVMnDiRYDBodjkiRyilKC8v5x//+AeRSETGuC1EnlVignSPFTocDq688kpGjx5NZaV1zsqL7Ka1pqamhhEjRmC322WM20IkcRsuMzv/RRddxL59+2jXrl3a1y1alm7duvGnP/2JZ599lq5du7J27VrsdrsBiVuad7IkcRvOlrHk4vf7mT9/PpdffjllZWWSvsVp+fjjj/nXv/7Fo48+it1ux+PxZHwoI564ZbgkWZK4DZe5j5uRSITZs2fTr1+/jKxftAzdunVj1KhRbNq0CZfLZcj4syTu1EjjNpwtY+N5TqeTe++9lx07dsiYoThtH3/8Ma+88goXXHABNTU1huxLkrhTI0Mlhstc4gY4//zz+fDDD+natStVVVUZ247IPQUFBbzwwgv4/X4ikQh79uzhggsukMRtQZK4DZe5xF3H4/GwcuVKevXqhcfjyei2RO44evQos2bNonv37vTv39+wpg2SuFMljdtwmU3cEJ8j8JZbbsHlclFdbe4DvkT2aNeuHQ899BBlZWWGnJBMZLPZkNG95EnjNkGmE7fT6eRvf/sbPp8Pl8uV0W2J3HHs2DFuu+02AMPGtuvEr7QybHNZT8a4TZDpJFM3+/uxY8eoqanJ6LZE7mjbti3PPPMMrVq1wu12G7ptSdypkcRtuMyPcTudThYvXsxXvvIVHA7zJrAQ2eXzzz/n+uuv59ChQ4TDYUncFiaJ23CZH+MG6NSpE0uWLKFHjx4cPHhQLg8UTfL5fGzbto22bdvicDiw2+04nca2BkncqZHEbbjMJ+46breb9evXM3bsWOzpnnZH5IzKykqGDx/O+vXr8fv9+P3GT9cliTs1krhNYNTZ+nA4zPDhw9m7dy/RaNSQbYrs43a7WbVqFeecc45pQ2uSuFMjMcwERiVul8vFunXruO666ww/2SSyg8PhIBwOM2TIEBYuXEh1dbUpw2qSuFNjM+KXdPRoqal/S82e9DNRMOjH5TI21VRXV9OnTx/27dsnU5uJena7nX/961/07t0br9drdjmEQmGZLDhBQUFek3/KJHGbwOhE4/F42LhxIzfddBM+n8/QbQvrsdlseL1eXC4Xo0ePZu7cuZSUlJh6AltOnqdGErfBzEjcdSoqKvja177GJ598Itd3t3Cvv/46l156aUbnkUyVJO6TSeK2GLPShcPhYMWKFfz3f/+3pQ5YYSybzcZ3vvMdHn30UY4cOWKJE9eSuFMjV5WYwKz59WKxGOPGjWP37t3yDJMWLBaL8fjjj3P55ZcTCATMLgeQOSdTJYnbBGalC6/Xy/r16/nxj38skwq3QDabjQ4dOtChQwemTp3Kb37zGw4ePCiJOwtJ4jaBmekiLy+PGTNmsHjxYqqqquSZ3S1ILBZj6tSpTJkyxTJJu44k7tRI4m6B/H4/GzZsYOrUqbRp08bsckSG2Ww2evXqRc+ePXnqqae4//77+eijjyyRtOtI4k6NJO4WKhAIMG3aNBYsWEBVVZVMLJzDYrEYY8aMYdasWfh8Pux2e8YmrD5dVqolG0jiNpx1kkVZWRl/+MMf+Na3vkV+fr7Z5YgMsdvtrF27lnvuuYedO3cSiUQs1yglcadGErfhrHPABINBpk6dygcffEBFhTWucxfpF41GueCCC5g1axZerxeHwyGJO8tJ4jacdZKF1+vlnXfe4Z577pGx7hw1bNgwRo0axcGDB7nvvvskcecISdyGs9YB43a7ufPOO1m4cCHbt2+nvLzc7JJEGnk8Hl5++WVcLhdut9tySbuOFWuyslPe8q6UsgNPAn2BauAWrfWuhOV3ANfXvnxda/1Aw3XILe9faNPGj9NpvVlpwuEws2bNYvbs2ZSUlJhdjjhDV1xxBa1btyYcDnPeeecxadIkevfubennssst7ydr7pb3ZBL3BMCrtS5SSg0EZgNXAiilzgNuAAYQHwNYo5RaoLXecuZl5yarfiJ0Op385Cc/YcmSJXzwwQeSvLPcoUOHeO6553C73fVP/rNyqpWhktQk8+d3CPAGgNZ6PXBRwrJPgG9qrSNa6yjgAuSOjizl9/t59913ueOOO0yZBUWcuYkTJ3LXXXdx8cUX8+STT7J7927LDo8ksnp9VpPMUMmfgVe01ktrX+8DztNahxN+xgY8DORprX/QcB2VlaGYmcMDDoedSMQaNxs4HHbsdmvvpBUVFVx22WVs2bJFrjbJMj179mTNmjUEAoH6B4llQ1OMxWLEYljmOAXz+4bL5TijoZISIC/htb1B0/YCc4FS4H8aW0FZmbkPNDJ7rCpRMOjHbrfeGHciv9/PunXrmDZtGnPmzCEUCpldkjiFG264gT59+puAvakAAAu/SURBVBAKhXjxxRcZMWIEffr0yYqmDfE/LjU1MsadqKAgr8llyTTutcB4YF7tGPfWugW1SXshsFJr/eszrLPFyJaPrjNmzGDdunX8+9//prKyUsYhLWz58uXce++9dO7cGb/fj81ms/w+lkj2rdSkclXJBcSvZfsucDmwC3AAfwfWJ/yT6VrrdxPXIVeVfMHMiRRORywW48c//jFPPPEEkUjE7HJEAzfccAODBg0iFovh8XgYPHgwhYWFWdW068hVJSdr7qoSmQHHYMGgD6fTkVUHVnl5OePGjWP9+vWEQiFLPZyopQsEAixZsoT+/fvj9Xqx2+1ZtW/VicVi1NREpHEnkBlwLCbbDqxWrVqxatUqbrzxRktfB9ySXHfddfz1r3/lmWee4fDhwxw4cACHI7sCQaJ43TJckiy5c9JwtqwY427MI488wt69e1mzZg01NTUydGKiV155hauuuopx48bhdDpxOLJn+K0x8U/+2XdMmEUat+Gys2lD/GP5m2++ya5du/joo4/42c9+xqZNmwiHw6f+x+KMDB8+nNtvv538/Hxqampwu92EQiEOHTrEueeea3Z5Z0wSd2qkcRsuexN3nZ49e9KzZ08uuugirr32WtauXUsoFJIrAzJo5cqVXHrppdx99904HA5cLldW70MNSeJOjQxYGi67m3aiNm3a8I9//IOioqKs/6huVQMGDGD16tVs3bqVb37zmxw9ehS3250z+1AdSdypkcZtglxLpvPnz2fEiBG43W45eZlmGzZs4Pnnn6dz587069ePLl26mF1SRkjiTo0MlZgg19JSmzZtWLp0KUeOHOHzzz/nyiuvZPfu3XLy8jR0796dV199lbZt21JZWYnf76e8vJxQKEQwGDS7vIyx2WyWfQCbFUk8MkGuJe467du3p7CwkDVr1nDZZZfhdEouSNXevXu58847iUQinHvuuXTq1AmlFO3btze7tIyKn/cxu4rsIUeWCXItcTfUvn17li5dSmFhIXv27JHknYT27duzbt06gsEgkUgEj8eDy+UyuyzDSOJOjSRuw9lyNnEnqpugdvz48ZK8k3DkyBGuueYa9uzZw1lnnUXr1q3NLslQkrhTI0eUCXI9cdcpKChgwYIFhEIhKioq+OpXv8rBgwdbxB+uU3G5XGzfvp2zzz4bt9sNxJuX3W5vkVfoSOJOjSRuE7S0xuV2uwkGg2zcuJEJEybgdDpb1NUndX+oE7/W1NQwdOhQli9fjsPhqJ+ppq6JtzSSuFMjidsELSVxN9SxY0fmz59/0vcOHTpEnz59OHHihElVZd7ChQu57LLLZFahZrTUY+J0tZzYYyEtLXE355xzzmHjxo2MHz8en8+XEwewy+Wqv7vR4XAwadIkHnvsMU6cOCG/+ybI+5IaSdwmyIXmlE69evVi0aJFAOzcuZP+/ftTWlpqclWn74EHHuC2224jEAiYXUrWkGMiNZK4TSDpomm9evViw4YNTJgwgWAwSCAQwO/313+1wgHu8/nw+XwEAoH6r3U1+nw+Zs2axU9/+lM++eQTuRQySXJMpEYStwms0HysrHfv3ixYsKDRZW+88QbXXHONqZMYDxw4kMWLF+Pz+bDb7Vn/0DArkPcvNTIDjsGCQT9OZ3bOUmIV7777Lg888ACbN28mEokQiURwOBxEIpGTGmnd12g0it1ur/+a2Ggb/kzdJXl166z7fiQSwel0Eg6HcTgc9O/fnwceeIALL7wQj8dj8juS/WQGnC+Tqcss1rizac5JIYwic06eTKYusxgZzxPiZHJMpEYatwlkmESIk8kxkRpp3EII00niTo00biGE6SRxp0Yat+EkWQjRkCTu1EjjNpgkCyG+TI6L1EjjNpgkCyHEmZLGbThJFkI0JIEmNdK4hRCmk6GS1EjjFkKYThJ3aqRxCyFMJ4k7NdK4hRCmk8SdmlM+1lUpZQeeBPoC1cAtWutdCcu/D/wACAO/0Fq/lqFahRA5ShJ3apJJ3BMAr9a6CJgGzK5boJTqANwODAZGA79SSskzLk9B0oUQJ5NjIjXJNO4hwBsAWuv1wEUJyy4G1mqtq7XWxcAu4IK0V5ljJF0IcTI5JlKTzAw4rYHihNcRpZRTax1uZFkpkN9wBYGAB6fTvGdQOxx2gkFrzLDtcNhkxhQhGojFYpY6TsFafaOhZBp3CZCX8Npe27QbW5YHnGi4grKy6tMuMB3MfiB6IqfTujuDEGYqLq4kEomaXUY9s/tGQUFek8uSadxrgfHAPKXUQGBrwrKNwC+VUl7AA/QGtp1+qbkvHI5SVlZNIOAhFgMJ3qKli8WgrKzKUk3b6pJp3AuAkUqpdcTv1/6uUupOYJfWepFS6jFgDfHx8p9prasyV25uqKqqoaqqBpfLQatWHsrLqxPmSYxis9mJRmPY7bb6r1/Mjdj49xsuj5/ssdH00wjjyxr+m7oa8vJ8lJRU1s7V2Py2Gs7lmLg8PiTUVC1fLIvP9dh4LQ3fj9atvZSWVjXxfsR/Ph3vx5ff+2iz70fd7/L0348vaknl/Wh+/4j//Be1pe/9aFhL0/tH08tbt/Zy/Lg1Pg1nE5lz0mRWrc2qdYF1a7NqXWDd2qxaF5hfm8w5KYQQOUQatxBCZBlp3EIIkWWkcQshRJaRxi2EEFlGGrcQQmQZadxCCJFlDLmOWwghRPpI4hZCiCwjjVsIIbKMNG4hhMgyyTxkKusopXzA80B74s8I/47W+miDn3mY+CQRTuBPWuunMliPZad/S6K2O4Dra1++rrV+wAp1JfzMEmCh1voPRtSVTG1KqTHAfbUv/w38UGud8ZNJSdT1E+DbQBSYpbVekOmaGtQ3APi11vobDb4/HphBfP+fm8lj8TRq+zbwYyACbAH+R2tt+mMMczVx/19gq9b6EuA54N7EhUqpYUDP2unYhgA/VUq1yWA9Vp7+rbnazgNuAAYBRcAopZRRMxw1WVeCXwBtDaonUXPvWR7wMDBOaz0Q2Au0s0BdQeL7WREwCphjUE11278b+DPgbfB9F/BobU1Dgf9Te0xYoTYf8X1smNZ6EPFJYsYZWVtTcrVx10+3BiwFRjRY/i7wvdr/jwEOoMaIeiw4/VtztX0CfFNrHalNGS7AqMf2NlcXSqlriSfHpQbVk6i52gYRf2b9bKXUGuBww097JtVVDnwMtKr9z+jUuBu4upHv9yb+iOjjWusQ8A5wiaGVNV1bNTBIa133iEAnxu3/zcr6oRKl1M3AHQ2+fZgvplT70nRqtc8Mr6r9a/8s8aGSsgyWecbTv5lRm9a6BjimlLIRT5GbtNY7zK5LKfVVYBJwLfGP2EZr7vfZDhgGXAiUAWuUUu8a9L41VxfE/xBvJx5UfmVAPfW01q8opbo3ssjs/b/J2mrDymEApdRtQABYbmRtTcn6xq21fhp4OvF7Sqn5fDGlWqPTqdUOjbwMrNZaZ3onPuPp3zKoudqond1oLvED6n8sUtdkoBOwEugOhJRSe7XWb2CM5mr7DPin1vpTAKXU28SbuBGNu7m6xgDnAOfWvl6mlFqrtd5oQF3NMXv/b1bteYPfAF8BrjHiXEUycnWoZC1wee3/jyE+Q0+92rGrfxA/ETLTyHqamP7tEqWUVymVj/HTvzVZW23SXgi8r7X+gdY6YoW6tNZ3a60H1J5I+gvwiIFNu9nagPeAryql2imlnMBA4inX7LqOA5VAde0nzhNA0KC6mvMh0Esp1VYp5QYuJT6UaRV/JD72PSFhyMR0WZ+4m/B74Fml1DtAiPjHapRSvyGesgcD5wHfr72iA+C7WuuPMlSPlad/a7I24h+phwKe2islAKZrrY04sJp9zwzYfnNO9fucDiyr/dl5Wmuj/hCfqq4RwHqlVJT4WLJpH/uVUpOAgNb6T7U1LiO+/8/VWh8wq67E2oB/ATcTPzZXKqUA/p/RV+M0Rm55F0KILJOrQyVCCJGzpHELIUSWkcYthBBZRhq3EEJkGWncQgiRZaRxCyFElpHGLYQQWUYatxBCZJn/D42Je0Vsp2n1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(cis_test_x[:,0], cis_test_x[:,1], c=cis_test_y)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3) Implement Multilayer Perceptron (MLP) with softmax activation and cross-entropy loss\n",
    "\n",
    "Now that we've tested the softmax activation function and cross-entropy loss functions in a single-layer net, let's implement the MLP version.\n",
    "\n",
    "Much of your work on the single layer net will carry over, so go ahead and copy-paste and modify as needed!\n",
    "\n",
    "The structure of our MLP will be:\n",
    "\n",
    "Input layer (X units) -> Hidden layer (Y units) with Rectified Linear activation (ReLu) -> Output layer (Z units) with softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Implement the following functions in `mlp.py`\n",
    "\n",
    "- `initialize_wts`\n",
    "- `accuracy`\n",
    "- `one_hot`\n",
    "- `predict`\n",
    "- `forward`\n",
    "- `backward`\n",
    "- `fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Test key functions with randomly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy net for debugging\n",
    "num_inputs = 3\n",
    "num_features = 6\n",
    "num_hidden_units = 7\n",
    "num_classes = 5\n",
    "\n",
    "net = MLP(num_features, num_hidden_units, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input shape: (3, 6)\n",
      "Test class vector shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "# Generate random data and classes\n",
    "np.random.seed(0)\n",
    "test_x = np.random.normal(loc=0, scale=100, size=(num_inputs, num_features))\n",
    "test_y = np.random.uniform(low=0, high=num_classes-1, size=(num_inputs,))\n",
    "test_y = test_y.astype(int)\n",
    "print(f'Test input shape: {test_x.shape}')\n",
    "print(f'Test class vector shape: {test_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `initialize_wts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y wt shape is (6, 7) and should be (6, 7)\n",
      "y bias shape is (7,) and should be (7,)\n",
      "z wt shape is (7, 5) and should be (7, 5)\n",
      "z bias shape is (5,) and should be (5,)\n",
      "1st few y wts are\n",
      "[ 0.018 -0.002  0.004  0.007  0.015  0.002]\n",
      "and should be\n",
      "[ 0.018 -0.002  0.004  0.007  0.015  0.002]\n",
      "y bias is\n",
      "[-0.017  0.02  -0.005 -0.004 -0.013  0.008 -0.016]\n",
      "and should be\n",
      "[-0.017  0.02  -0.005 -0.004 -0.013  0.008 -0.016]\n",
      "1st few z wts are\n",
      "[-0.002 -0.    -0.004  0.002  0.001  0.004  0.001]\n",
      "and should be\n",
      "[-0.002 -0.    -0.004  0.002  0.001  0.004  0.001]\n",
      "z bias is\n",
      "[ 0.015  0.019  0.012 -0.002 -0.011]\n",
      "and should be\n",
      "[ 0.015  0.019  0.012 -0.002 -0.011]\n"
     ]
    }
   ],
   "source": [
    "net.initialize_wts(M=num_features, H=num_hidden_units, C=num_classes, std=0.01)\n",
    "print(f'y wt shape is {net.y_wts.shape} and should be (6, 7)')\n",
    "print(f'y bias shape is {net.y_b.shape} and should be (7,)')\n",
    "print(f'z wt shape is {net.z_wts.shape} and should be (7, 5)')\n",
    "print(f'z bias shape is {net.z_b.shape} and should be (5,)')\n",
    "\n",
    "print(f'1st few y wts are\\n{net.y_wts[:,0]}\\nand should be\\n[ 0.018 -0.002  0.004  0.007  0.015  0.002]')\n",
    "print(f'y bias is\\n{net.y_b}\\nand should be\\n[-0.017  0.02  -0.005 -0.004 -0.013  0.008 -0.016]')\n",
    "print(f'1st few z wts are\\n{net.z_wts[:,0]}\\nand should be\\n[-0.002 -0.    -0.004  0.002  0.001  0.004  0.001]')\n",
    "print(f'z bias is\\n{net.z_b}\\nand should be\\n[ 0.015  0.019  0.012 -0.002 -0.011]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes are [3 0 0] and should be [3 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_y_pred = net.predict(test_x)\n",
    "print(f'Predicted classes are {test_y_pred} and should be [3 0 0]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `forward` method focusing on`ReLU`(net act of hidden layer `y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your y activation is\n",
      "[[ 7.643  4.49   0.799  9.977 -0.    -0.    -0.   ]\n",
      " [ 2.353  2.737  2.175  2.547  0.345 -0.    -0.   ]\n",
      " [ 3.98   2.691  1.19   3.029 -0.    -0.    -0.   ]]\n",
      "The correct y activation (ReLU) is\n",
      "[[7.66  4.47  0.804 9.981 0.    0.    0.   ]\n",
      " [2.37  2.717 2.18  2.552 0.357 0.    0.   ]\n",
      " [3.997 2.671 1.195 3.034 0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "_,y_net_act_test,_,_,_ = net.forward(test_x, test_y)\n",
    "\n",
    "correct_y_act = np.array([[7.66 , 4.47 , 0.804, 9.981, 0.   , 0.   , 0.   ],\n",
    "       [2.37 , 2.717, 2.18 , 2.552, 0.357, 0.   , 0.   ],\n",
    "       [3.997, 2.671, 1.195, 3.034, 0.   , 0.   , 0.   ]])\n",
    "\n",
    "print(f'Your y activation is\\n{y_net_act_test}')\n",
    "print(f'The correct y activation (ReLU) is\\n{correct_y_act}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `forward` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your z activation (class probabilities) is\n",
      "[[0.219 0.2   0.191 0.219 0.171]\n",
      " [0.208 0.204 0.201 0.205 0.183]\n",
      " [0.208 0.202 0.202 0.205 0.183]]\n",
      "The correct z activation (class probabilities) is\n",
      "[[0.219 0.2   0.191 0.219 0.171]\n",
      " [0.208 0.204 0.201 0.205 0.183]\n",
      " [0.208 0.202 0.202 0.205 0.183]]\n",
      "The sums across rows (for each data sample) are [1. 1. 1.].\n",
      "  You should know what should be :)\n"
     ]
    }
   ],
   "source": [
    "_,_,_,probs,_ = net.forward(test_x, test_y)\n",
    "\n",
    "correct_probs = np.array([[0.219, 0.2  , 0.191, 0.219, 0.171],\n",
    "       [0.208, 0.204, 0.201, 0.205, 0.183],\n",
    "       [0.208, 0.202, 0.202, 0.205, 0.183]])\n",
    "\n",
    "print(f'Your z activation (class probabilities) is\\n{probs}')\n",
    "print(f'The correct z activation (class probabilities) is\\n{correct_probs}')\n",
    "print(f'The sums across rows (for each data sample) are {np.sum(probs, axis=1)}.')\n",
    "print(f'  You should know what should be :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `forward` method, focusing on loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your average loss is\n",
      "1.564402690536365\n",
      "The correct average loss is approx\n",
      "1.564402690536365\n"
     ]
    }
   ],
   "source": [
    "y_in, y_act ,z_in, z_act, loss = net.forward(test_x, test_y)\n",
    "correct_loss = 1.564402690536365\n",
    "\n",
    "print(f'Your average loss is\\n{loss}')\n",
    "print(f'The correct average loss is approx\\n{correct_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `forward` method, focusing on regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your regularized average loss is\n",
      "5.257207314928798\n",
      "The correct regularized average loss is approx\n",
      "5.257207314928798\n"
     ]
    }
   ],
   "source": [
    "y_in, y_act ,z_in, z_act, loss = net.forward(test_x, test_y, reg=1000)\n",
    "correct_loss = 5.257207314928798\n",
    "\n",
    "print(f'Your regularized average loss is\\n{loss}')\n",
    "print(f'The correct regularized average loss is approx\\n{correct_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `backward` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your gradient for y_wts is\n",
      " [[-0.476  0.057 -0.458 -0.115  0.03  -0.005  0.005]\n",
      " [-0.002  0.014 -0.046 -0.162  0.004  0.004  0.001]\n",
      " [-0.088  0.038 -0.166 -0.325 -0.001 -0.004 -0.013]\n",
      " [-0.331  0.067 -0.398 -0.332  0.001  0.    -0.001]\n",
      " [-0.318  0.089 -0.465 -0.615 -0.001 -0.01  -0.002]\n",
      " [-0.315 -0.036 -0.036  0.806  0.029 -0.005 -0.007]]\n",
      "Your gradient for y_b is\n",
      " [-0.005  0.    -0.004 -0.     0.     0.     0.   ]\n",
      "Your gradient for z_wts is\n",
      " [[-2.879  0.933  0.131  0.987  0.816]\n",
      " [-1.69   0.669 -0.261  0.699  0.584]\n",
      " [-0.374  0.278 -0.45   0.284  0.242]\n",
      " [-3.221  1.041  0.154  1.111  0.904]\n",
      " [ 0.024  0.027 -0.091  0.029  0.015]\n",
      " [ 0.002 -0.003 -0.004 -0.003 -0.002]\n",
      " [ 0.    -0.006  0.005  0.002 -0.008]]\n",
      "Your gradient for z_b is\n",
      " [-0.455  0.202 -0.135  0.209  0.179]\n"
     ]
    }
   ],
   "source": [
    "y_in, y_act ,z_in, z_act, loss = net.forward(test_x, test_y, reg=0.5)\n",
    "grads = net.backward(test_x, test_y, y_in, y_act ,z_in, z_act, reg=0.5)\n",
    "\n",
    "print('Your gradient for y_wts is\\n', grads[0])\n",
    "print('Your gradient for y_b is\\n', grads[1])\n",
    "print('Your gradient for z_wts is\\n', grads[2])\n",
    "print('Your gradient for z_b is\\n', grads[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct gradients are:\n",
    "\n",
    "`\n",
    "Your gradient for y_wts is\n",
    " [[-0.476  0.057 -0.458 -0.115  0.03  -0.005  0.005]\n",
    " [-0.002  0.014 -0.046 -0.162  0.004  0.004  0.001]\n",
    " [-0.088  0.038 -0.166 -0.325 -0.001 -0.004 -0.013]\n",
    " [-0.331  0.067 -0.398 -0.332  0.001  0.    -0.001]\n",
    " [-0.318  0.089 -0.465 -0.615 -0.001 -0.01  -0.002]\n",
    " [-0.315 -0.036 -0.036  0.806  0.029 -0.005 -0.007]]\n",
    "Your gradient for y_b is\n",
    " [-0.005  0.    -0.004 -0.     0.     0.     0.   ]\n",
    "Your gradient for z_wts is\n",
    " [[-2.879  0.933  0.131  0.987  0.816]\n",
    " [-1.69   0.669 -0.261  0.699  0.584]\n",
    " [-0.374  0.278 -0.45   0.284  0.242]\n",
    " [-3.221  1.041  0.154  1.111  0.904]\n",
    " [ 0.024  0.027 -0.091  0.029  0.015]\n",
    " [ 0.002 -0.003 -0.004 -0.003 -0.002]\n",
    " [ 0.    -0.006  0.005  0.002 -0.008]]\n",
    "Your gradient for z_b is\n",
    " [-0.455  0.202 -0.135  0.209  0.179]\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss over epoch. \n",
    "\n",
    "The below code should generate a curve that rapidly drops to 0 (there might be fluctuations and it might not be monotonic and that's ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 30 epochs and 30 iterations total, 1 iter/epoch.\n",
      "  Completed iter 0/30. Training loss: 3.78.\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = MLP(num_features, num_hidden_units, num_classes)\n",
    "loss, acc_t, acc_v = net.fit(test_x, test_y, test_x, test_y, reg=0, lr=0.001, mini_batch_sz=3, n_epochs=30)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg cross-entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Test MLP with Circle in Square dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test case where training data = test data.\n",
    "\n",
    "You should see a nice drop and plateau in loss (after a bunch of print outs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 700 epochs and 70000 iterations total, 100 iter/epoch.\n",
      "  Completed iter 0/70000. Training loss: 0.70.\n",
      "  Completed iter 100/70000. Training loss: 0.69.\n",
      "  Completed iter 200/70000. Training loss: 0.69.\n",
      "  Completed iter 300/70000. Training loss: 0.69.\n",
      "  Completed iter 400/70000. Training loss: 0.69.\n",
      "  Completed iter 500/70000. Training loss: 0.69.\n",
      "  Completed iter 600/70000. Training loss: 0.69.\n",
      "  Completed iter 700/70000. Training loss: 0.69.\n",
      "  Completed iter 800/70000. Training loss: 0.69.\n",
      "  Completed iter 900/70000. Training loss: 0.69.\n",
      "  Completed iter 1000/70000. Training loss: 0.69.\n",
      "  Completed iter 1100/70000. Training loss: 0.69.\n",
      "  Completed iter 1200/70000. Training loss: 0.69.\n",
      "  Completed iter 1300/70000. Training loss: 0.69.\n",
      "  Completed iter 1400/70000. Training loss: 0.69.\n",
      "  Completed iter 1500/70000. Training loss: 0.69.\n",
      "  Completed iter 1600/70000. Training loss: 0.69.\n",
      "  Completed iter 1700/70000. Training loss: 0.68.\n",
      "  Completed iter 1800/70000. Training loss: 0.69.\n",
      "  Completed iter 1900/70000. Training loss: 0.69.\n",
      "  Completed iter 2000/70000. Training loss: 0.69.\n",
      "  Completed iter 2100/70000. Training loss: 0.68.\n",
      "  Completed iter 2200/70000. Training loss: 0.69.\n",
      "  Completed iter 2300/70000. Training loss: 0.68.\n",
      "  Completed iter 2400/70000. Training loss: 0.68.\n",
      "  Completed iter 2500/70000. Training loss: 0.68.\n",
      "  Completed iter 2600/70000. Training loss: 0.69.\n",
      "  Completed iter 2700/70000. Training loss: 0.68.\n",
      "  Completed iter 2800/70000. Training loss: 0.68.\n",
      "  Completed iter 2900/70000. Training loss: 0.68.\n",
      "  Completed iter 3000/70000. Training loss: 0.67.\n",
      "  Completed iter 3100/70000. Training loss: 0.69.\n",
      "  Completed iter 3200/70000. Training loss: 0.67.\n",
      "  Completed iter 3300/70000. Training loss: 0.68.\n",
      "  Completed iter 3400/70000. Training loss: 0.68.\n",
      "  Completed iter 3500/70000. Training loss: 0.69.\n",
      "  Completed iter 3600/70000. Training loss: 0.68.\n",
      "  Completed iter 3700/70000. Training loss: 0.68.\n",
      "  Completed iter 3800/70000. Training loss: 0.67.\n",
      "  Completed iter 3900/70000. Training loss: 0.68.\n",
      "  Completed iter 4000/70000. Training loss: 0.67.\n",
      "  Completed iter 4100/70000. Training loss: 0.67.\n",
      "  Completed iter 4200/70000. Training loss: 0.66.\n",
      "  Completed iter 4300/70000. Training loss: 0.67.\n",
      "  Completed iter 4400/70000. Training loss: 0.66.\n",
      "  Completed iter 4500/70000. Training loss: 0.66.\n",
      "  Completed iter 4600/70000. Training loss: 0.66.\n",
      "  Completed iter 4700/70000. Training loss: 0.67.\n",
      "  Completed iter 4800/70000. Training loss: 0.66.\n",
      "  Completed iter 4900/70000. Training loss: 0.66.\n",
      "  Completed iter 5000/70000. Training loss: 0.65.\n",
      "  Completed iter 5100/70000. Training loss: 0.67.\n",
      "  Completed iter 5200/70000. Training loss: 0.66.\n",
      "  Completed iter 5300/70000. Training loss: 0.65.\n",
      "  Completed iter 5400/70000. Training loss: 0.66.\n",
      "  Completed iter 5500/70000. Training loss: 0.64.\n",
      "  Completed iter 5600/70000. Training loss: 0.65.\n",
      "  Completed iter 5700/70000. Training loss: 0.64.\n",
      "  Completed iter 5800/70000. Training loss: 0.65.\n",
      "  Completed iter 5900/70000. Training loss: 0.65.\n",
      "  Completed iter 6000/70000. Training loss: 0.64.\n",
      "  Completed iter 6100/70000. Training loss: 0.63.\n",
      "  Completed iter 6200/70000. Training loss: 0.65.\n",
      "  Completed iter 6300/70000. Training loss: 0.63.\n",
      "  Completed iter 6400/70000. Training loss: 0.63.\n",
      "  Completed iter 6500/70000. Training loss: 0.63.\n",
      "  Completed iter 6600/70000. Training loss: 0.62.\n",
      "  Completed iter 6700/70000. Training loss: 0.62.\n",
      "  Completed iter 6800/70000. Training loss: 0.62.\n",
      "  Completed iter 6900/70000. Training loss: 0.63.\n",
      "  Completed iter 7000/70000. Training loss: 0.60.\n",
      "  Completed iter 7100/70000. Training loss: 0.61.\n",
      "  Completed iter 7200/70000. Training loss: 0.62.\n",
      "  Completed iter 7300/70000. Training loss: 0.60.\n",
      "  Completed iter 7400/70000. Training loss: 0.61.\n",
      "  Completed iter 7500/70000. Training loss: 0.60.\n",
      "  Completed iter 7600/70000. Training loss: 0.59.\n",
      "  Completed iter 7700/70000. Training loss: 0.58.\n",
      "  Completed iter 7800/70000. Training loss: 0.61.\n",
      "  Completed iter 7900/70000. Training loss: 0.58.\n",
      "  Completed iter 8000/70000. Training loss: 0.60.\n",
      "  Completed iter 8100/70000. Training loss: 0.57.\n",
      "  Completed iter 8200/70000. Training loss: 0.58.\n",
      "  Completed iter 8300/70000. Training loss: 0.55.\n",
      "  Completed iter 8400/70000. Training loss: 0.60.\n",
      "  Completed iter 8500/70000. Training loss: 0.58.\n",
      "  Completed iter 8600/70000. Training loss: 0.57.\n",
      "  Completed iter 8700/70000. Training loss: 0.54.\n",
      "  Completed iter 8800/70000. Training loss: 0.58.\n",
      "  Completed iter 8900/70000. Training loss: 0.57.\n",
      "  Completed iter 9000/70000. Training loss: 0.54.\n",
      "  Completed iter 9100/70000. Training loss: 0.55.\n",
      "  Completed iter 9200/70000. Training loss: 0.53.\n",
      "  Completed iter 9300/70000. Training loss: 0.54.\n",
      "  Completed iter 9400/70000. Training loss: 0.57.\n",
      "  Completed iter 9500/70000. Training loss: 0.53.\n",
      "  Completed iter 9600/70000. Training loss: 0.54.\n",
      "  Completed iter 9700/70000. Training loss: 0.51.\n",
      "  Completed iter 9800/70000. Training loss: 0.53.\n",
      "  Completed iter 9900/70000. Training loss: 0.53.\n",
      "  Completed iter 10000/70000. Training loss: 0.52.\n",
      "  Completed iter 10100/70000. Training loss: 0.52.\n",
      "  Completed iter 10200/70000. Training loss: 0.50.\n",
      "  Completed iter 10300/70000. Training loss: 0.49.\n",
      "  Completed iter 10400/70000. Training loss: 0.52.\n",
      "  Completed iter 10500/70000. Training loss: 0.54.\n",
      "  Completed iter 10600/70000. Training loss: 0.50.\n",
      "  Completed iter 10700/70000. Training loss: 0.50.\n",
      "  Completed iter 10800/70000. Training loss: 0.49.\n",
      "  Completed iter 10900/70000. Training loss: 0.44.\n",
      "  Completed iter 11000/70000. Training loss: 0.46.\n",
      "  Completed iter 11100/70000. Training loss: 0.47.\n",
      "  Completed iter 11200/70000. Training loss: 0.47.\n",
      "  Completed iter 11300/70000. Training loss: 0.46.\n",
      "  Completed iter 11400/70000. Training loss: 0.44.\n",
      "  Completed iter 11500/70000. Training loss: 0.47.\n",
      "  Completed iter 11600/70000. Training loss: 0.43.\n",
      "  Completed iter 11700/70000. Training loss: 0.44.\n",
      "  Completed iter 11800/70000. Training loss: 0.42.\n",
      "  Completed iter 11900/70000. Training loss: 0.43.\n",
      "  Completed iter 12000/70000. Training loss: 0.42.\n",
      "  Completed iter 12100/70000. Training loss: 0.46.\n",
      "  Completed iter 12200/70000. Training loss: 0.41.\n",
      "  Completed iter 12300/70000. Training loss: 0.42.\n",
      "  Completed iter 12400/70000. Training loss: 0.42.\n",
      "  Completed iter 12500/70000. Training loss: 0.43.\n",
      "  Completed iter 12600/70000. Training loss: 0.37.\n",
      "  Completed iter 12700/70000. Training loss: 0.41.\n",
      "  Completed iter 12800/70000. Training loss: 0.41.\n",
      "  Completed iter 12900/70000. Training loss: 0.40.\n",
      "  Completed iter 13000/70000. Training loss: 0.37.\n",
      "  Completed iter 13100/70000. Training loss: 0.38.\n",
      "  Completed iter 13200/70000. Training loss: 0.33.\n",
      "  Completed iter 13300/70000. Training loss: 0.39.\n",
      "  Completed iter 13400/70000. Training loss: 0.35.\n",
      "  Completed iter 13500/70000. Training loss: 0.37.\n",
      "  Completed iter 13600/70000. Training loss: 0.36.\n",
      "  Completed iter 13700/70000. Training loss: 0.33.\n",
      "  Completed iter 13800/70000. Training loss: 0.35.\n",
      "  Completed iter 13900/70000. Training loss: 0.34.\n",
      "  Completed iter 14000/70000. Training loss: 0.32.\n",
      "  Completed iter 14100/70000. Training loss: 0.34.\n",
      "  Completed iter 14200/70000. Training loss: 0.36.\n",
      "  Completed iter 14300/70000. Training loss: 0.35.\n",
      "  Completed iter 14400/70000. Training loss: 0.34.\n",
      "  Completed iter 14500/70000. Training loss: 0.32.\n",
      "  Completed iter 14600/70000. Training loss: 0.32.\n",
      "  Completed iter 14700/70000. Training loss: 0.32.\n",
      "  Completed iter 14800/70000. Training loss: 0.31.\n",
      "  Completed iter 14900/70000. Training loss: 0.33.\n",
      "  Completed iter 15000/70000. Training loss: 0.32.\n",
      "  Completed iter 15100/70000. Training loss: 0.31.\n",
      "  Completed iter 15200/70000. Training loss: 0.33.\n",
      "  Completed iter 15300/70000. Training loss: 0.30.\n",
      "  Completed iter 15400/70000. Training loss: 0.30.\n",
      "  Completed iter 15500/70000. Training loss: 0.32.\n",
      "  Completed iter 15600/70000. Training loss: 0.29.\n",
      "  Completed iter 15700/70000. Training loss: 0.32.\n",
      "  Completed iter 15800/70000. Training loss: 0.33.\n",
      "  Completed iter 15900/70000. Training loss: 0.29.\n",
      "  Completed iter 16000/70000. Training loss: 0.30.\n",
      "  Completed iter 16100/70000. Training loss: 0.29.\n",
      "  Completed iter 16200/70000. Training loss: 0.27.\n",
      "  Completed iter 16300/70000. Training loss: 0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 16400/70000. Training loss: 0.32.\n",
      "  Completed iter 16500/70000. Training loss: 0.30.\n",
      "  Completed iter 16600/70000. Training loss: 0.27.\n",
      "  Completed iter 16700/70000. Training loss: 0.28.\n",
      "  Completed iter 16800/70000. Training loss: 0.24.\n",
      "  Completed iter 16900/70000. Training loss: 0.29.\n",
      "  Completed iter 17000/70000. Training loss: 0.26.\n",
      "  Completed iter 17100/70000. Training loss: 0.26.\n",
      "  Completed iter 17200/70000. Training loss: 0.30.\n",
      "  Completed iter 17300/70000. Training loss: 0.26.\n",
      "  Completed iter 17400/70000. Training loss: 0.27.\n",
      "  Completed iter 17500/70000. Training loss: 0.26.\n",
      "  Completed iter 17600/70000. Training loss: 0.29.\n",
      "  Completed iter 17700/70000. Training loss: 0.26.\n",
      "  Completed iter 17800/70000. Training loss: 0.25.\n",
      "  Completed iter 17900/70000. Training loss: 0.25.\n",
      "  Completed iter 18000/70000. Training loss: 0.24.\n",
      "  Completed iter 18100/70000. Training loss: 0.22.\n",
      "  Completed iter 18200/70000. Training loss: 0.25.\n",
      "  Completed iter 18300/70000. Training loss: 0.25.\n",
      "  Completed iter 18400/70000. Training loss: 0.28.\n",
      "  Completed iter 18500/70000. Training loss: 0.25.\n",
      "  Completed iter 18600/70000. Training loss: 0.27.\n",
      "  Completed iter 18700/70000. Training loss: 0.30.\n",
      "  Completed iter 18800/70000. Training loss: 0.23.\n",
      "  Completed iter 18900/70000. Training loss: 0.25.\n",
      "  Completed iter 19000/70000. Training loss: 0.23.\n",
      "  Completed iter 19100/70000. Training loss: 0.23.\n",
      "  Completed iter 19200/70000. Training loss: 0.23.\n",
      "  Completed iter 19300/70000. Training loss: 0.22.\n",
      "  Completed iter 19400/70000. Training loss: 0.24.\n",
      "  Completed iter 19500/70000. Training loss: 0.22.\n",
      "  Completed iter 19600/70000. Training loss: 0.19.\n",
      "  Completed iter 19700/70000. Training loss: 0.22.\n",
      "  Completed iter 19800/70000. Training loss: 0.22.\n",
      "  Completed iter 19900/70000. Training loss: 0.23.\n",
      "  Completed iter 20000/70000. Training loss: 0.23.\n",
      "  Completed iter 20100/70000. Training loss: 0.24.\n",
      "  Completed iter 20200/70000. Training loss: 0.20.\n",
      "  Completed iter 20300/70000. Training loss: 0.22.\n",
      "  Completed iter 20400/70000. Training loss: 0.22.\n",
      "  Completed iter 20500/70000. Training loss: 0.18.\n",
      "  Completed iter 20600/70000. Training loss: 0.18.\n",
      "  Completed iter 20700/70000. Training loss: 0.21.\n",
      "  Completed iter 20800/70000. Training loss: 0.22.\n",
      "  Completed iter 20900/70000. Training loss: 0.18.\n",
      "  Completed iter 21000/70000. Training loss: 0.23.\n",
      "  Completed iter 21100/70000. Training loss: 0.23.\n",
      "  Completed iter 21200/70000. Training loss: 0.22.\n",
      "  Completed iter 21300/70000. Training loss: 0.20.\n",
      "  Completed iter 21400/70000. Training loss: 0.23.\n",
      "  Completed iter 21500/70000. Training loss: 0.21.\n",
      "  Completed iter 21600/70000. Training loss: 0.23.\n",
      "  Completed iter 21700/70000. Training loss: 0.24.\n",
      "  Completed iter 21800/70000. Training loss: 0.22.\n",
      "  Completed iter 21900/70000. Training loss: 0.22.\n",
      "  Completed iter 22000/70000. Training loss: 0.19.\n",
      "  Completed iter 22100/70000. Training loss: 0.23.\n",
      "  Completed iter 22200/70000. Training loss: 0.22.\n",
      "  Completed iter 22300/70000. Training loss: 0.20.\n",
      "  Completed iter 22400/70000. Training loss: 0.19.\n",
      "  Completed iter 22500/70000. Training loss: 0.20.\n",
      "  Completed iter 22600/70000. Training loss: 0.21.\n",
      "  Completed iter 22700/70000. Training loss: 0.21.\n",
      "  Completed iter 22800/70000. Training loss: 0.17.\n",
      "  Completed iter 22900/70000. Training loss: 0.20.\n",
      "  Completed iter 23000/70000. Training loss: 0.19.\n",
      "  Completed iter 23100/70000. Training loss: 0.21.\n",
      "  Completed iter 23200/70000. Training loss: 0.21.\n",
      "  Completed iter 23300/70000. Training loss: 0.17.\n",
      "  Completed iter 23400/70000. Training loss: 0.21.\n",
      "  Completed iter 23500/70000. Training loss: 0.16.\n",
      "  Completed iter 23600/70000. Training loss: 0.20.\n",
      "  Completed iter 23700/70000. Training loss: 0.21.\n",
      "  Completed iter 23800/70000. Training loss: 0.17.\n",
      "  Completed iter 23900/70000. Training loss: 0.16.\n",
      "  Completed iter 24000/70000. Training loss: 0.16.\n",
      "  Completed iter 24100/70000. Training loss: 0.17.\n",
      "  Completed iter 24200/70000. Training loss: 0.21.\n",
      "  Completed iter 24300/70000. Training loss: 0.18.\n",
      "  Completed iter 24400/70000. Training loss: 0.14.\n",
      "  Completed iter 24500/70000. Training loss: 0.15.\n",
      "  Completed iter 24600/70000. Training loss: 0.17.\n",
      "  Completed iter 24700/70000. Training loss: 0.17.\n",
      "  Completed iter 24800/70000. Training loss: 0.19.\n",
      "  Completed iter 24900/70000. Training loss: 0.15.\n",
      "  Completed iter 25000/70000. Training loss: 0.18.\n",
      "  Completed iter 25100/70000. Training loss: 0.16.\n",
      "  Completed iter 25200/70000. Training loss: 0.18.\n",
      "  Completed iter 25300/70000. Training loss: 0.17.\n",
      "  Completed iter 25400/70000. Training loss: 0.15.\n",
      "  Completed iter 25500/70000. Training loss: 0.16.\n",
      "  Completed iter 25600/70000. Training loss: 0.18.\n",
      "  Completed iter 25700/70000. Training loss: 0.17.\n",
      "  Completed iter 25800/70000. Training loss: 0.16.\n",
      "  Completed iter 25900/70000. Training loss: 0.20.\n",
      "  Completed iter 26000/70000. Training loss: 0.17.\n",
      "  Completed iter 26100/70000. Training loss: 0.16.\n",
      "  Completed iter 26200/70000. Training loss: 0.14.\n",
      "  Completed iter 26300/70000. Training loss: 0.17.\n",
      "  Completed iter 26400/70000. Training loss: 0.17.\n",
      "  Completed iter 26500/70000. Training loss: 0.17.\n",
      "  Completed iter 26600/70000. Training loss: 0.18.\n",
      "  Completed iter 26700/70000. Training loss: 0.17.\n",
      "  Completed iter 26800/70000. Training loss: 0.18.\n",
      "  Completed iter 26900/70000. Training loss: 0.16.\n",
      "  Completed iter 27000/70000. Training loss: 0.17.\n",
      "  Completed iter 27100/70000. Training loss: 0.18.\n",
      "  Completed iter 27200/70000. Training loss: 0.18.\n",
      "  Completed iter 27300/70000. Training loss: 0.12.\n",
      "  Completed iter 27400/70000. Training loss: 0.14.\n",
      "  Completed iter 27500/70000. Training loss: 0.17.\n",
      "  Completed iter 27600/70000. Training loss: 0.17.\n",
      "  Completed iter 27700/70000. Training loss: 0.12.\n",
      "  Completed iter 27800/70000. Training loss: 0.19.\n",
      "  Completed iter 27900/70000. Training loss: 0.14.\n",
      "  Completed iter 28000/70000. Training loss: 0.17.\n",
      "  Completed iter 28100/70000. Training loss: 0.18.\n",
      "  Completed iter 28200/70000. Training loss: 0.15.\n",
      "  Completed iter 28300/70000. Training loss: 0.15.\n",
      "  Completed iter 28400/70000. Training loss: 0.14.\n",
      "  Completed iter 28500/70000. Training loss: 0.17.\n",
      "  Completed iter 28600/70000. Training loss: 0.13.\n",
      "  Completed iter 28700/70000. Training loss: 0.15.\n",
      "  Completed iter 28800/70000. Training loss: 0.13.\n",
      "  Completed iter 28900/70000. Training loss: 0.13.\n",
      "  Completed iter 29000/70000. Training loss: 0.14.\n",
      "  Completed iter 29100/70000. Training loss: 0.15.\n",
      "  Completed iter 29200/70000. Training loss: 0.17.\n",
      "  Completed iter 29300/70000. Training loss: 0.14.\n",
      "  Completed iter 29400/70000. Training loss: 0.13.\n",
      "  Completed iter 29500/70000. Training loss: 0.13.\n",
      "  Completed iter 29600/70000. Training loss: 0.18.\n",
      "  Completed iter 29700/70000. Training loss: 0.18.\n",
      "  Completed iter 29800/70000. Training loss: 0.14.\n",
      "  Completed iter 29900/70000. Training loss: 0.18.\n",
      "  Completed iter 30000/70000. Training loss: 0.14.\n",
      "  Completed iter 30100/70000. Training loss: 0.17.\n",
      "  Completed iter 30200/70000. Training loss: 0.12.\n",
      "  Completed iter 30300/70000. Training loss: 0.12.\n",
      "  Completed iter 30400/70000. Training loss: 0.14.\n",
      "  Completed iter 30500/70000. Training loss: 0.17.\n",
      "  Completed iter 30600/70000. Training loss: 0.15.\n",
      "  Completed iter 30700/70000. Training loss: 0.13.\n",
      "  Completed iter 30800/70000. Training loss: 0.13.\n",
      "  Completed iter 30900/70000. Training loss: 0.15.\n",
      "  Completed iter 31000/70000. Training loss: 0.14.\n",
      "  Completed iter 31100/70000. Training loss: 0.13.\n",
      "  Completed iter 31200/70000. Training loss: 0.11.\n",
      "  Completed iter 31300/70000. Training loss: 0.16.\n",
      "  Completed iter 31400/70000. Training loss: 0.18.\n",
      "  Completed iter 31500/70000. Training loss: 0.16.\n",
      "  Completed iter 31600/70000. Training loss: 0.13.\n",
      "  Completed iter 31700/70000. Training loss: 0.17.\n",
      "  Completed iter 31800/70000. Training loss: 0.13.\n",
      "  Completed iter 31900/70000. Training loss: 0.15.\n",
      "  Completed iter 32000/70000. Training loss: 0.15.\n",
      "  Completed iter 32100/70000. Training loss: 0.11.\n",
      "  Completed iter 32200/70000. Training loss: 0.15.\n",
      "  Completed iter 32300/70000. Training loss: 0.16.\n",
      "  Completed iter 32400/70000. Training loss: 0.11.\n",
      "  Completed iter 32500/70000. Training loss: 0.14.\n",
      "  Completed iter 32600/70000. Training loss: 0.14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 32700/70000. Training loss: 0.13.\n",
      "  Completed iter 32800/70000. Training loss: 0.12.\n",
      "  Completed iter 32900/70000. Training loss: 0.13.\n",
      "  Completed iter 33000/70000. Training loss: 0.15.\n",
      "  Completed iter 33100/70000. Training loss: 0.11.\n",
      "  Completed iter 33200/70000. Training loss: 0.10.\n",
      "  Completed iter 33300/70000. Training loss: 0.09.\n",
      "  Completed iter 33400/70000. Training loss: 0.13.\n",
      "  Completed iter 33500/70000. Training loss: 0.13.\n",
      "  Completed iter 33600/70000. Training loss: 0.12.\n",
      "  Completed iter 33700/70000. Training loss: 0.15.\n",
      "  Completed iter 33800/70000. Training loss: 0.16.\n",
      "  Completed iter 33900/70000. Training loss: 0.10.\n",
      "  Completed iter 34000/70000. Training loss: 0.12.\n",
      "  Completed iter 34100/70000. Training loss: 0.14.\n",
      "  Completed iter 34200/70000. Training loss: 0.10.\n",
      "  Completed iter 34300/70000. Training loss: 0.13.\n",
      "  Completed iter 34400/70000. Training loss: 0.12.\n",
      "  Completed iter 34500/70000. Training loss: 0.14.\n",
      "  Completed iter 34600/70000. Training loss: 0.11.\n",
      "  Completed iter 34700/70000. Training loss: 0.12.\n",
      "  Completed iter 34800/70000. Training loss: 0.13.\n",
      "  Completed iter 34900/70000. Training loss: 0.12.\n",
      "  Completed iter 35000/70000. Training loss: 0.12.\n",
      "  Completed iter 35100/70000. Training loss: 0.16.\n",
      "  Completed iter 35200/70000. Training loss: 0.16.\n",
      "  Completed iter 35300/70000. Training loss: 0.12.\n",
      "  Completed iter 35400/70000. Training loss: 0.14.\n",
      "  Completed iter 35500/70000. Training loss: 0.13.\n",
      "  Completed iter 35600/70000. Training loss: 0.12.\n",
      "  Completed iter 35700/70000. Training loss: 0.13.\n",
      "  Completed iter 35800/70000. Training loss: 0.13.\n",
      "  Completed iter 35900/70000. Training loss: 0.13.\n",
      "  Completed iter 36000/70000. Training loss: 0.09.\n",
      "  Completed iter 36100/70000. Training loss: 0.12.\n",
      "  Completed iter 36200/70000. Training loss: 0.14.\n",
      "  Completed iter 36300/70000. Training loss: 0.09.\n",
      "  Completed iter 36400/70000. Training loss: 0.16.\n",
      "  Completed iter 36500/70000. Training loss: 0.12.\n",
      "  Completed iter 36600/70000. Training loss: 0.13.\n",
      "  Completed iter 36700/70000. Training loss: 0.12.\n",
      "  Completed iter 36800/70000. Training loss: 0.15.\n",
      "  Completed iter 36900/70000. Training loss: 0.11.\n",
      "  Completed iter 37000/70000. Training loss: 0.11.\n",
      "  Completed iter 37100/70000. Training loss: 0.10.\n",
      "  Completed iter 37200/70000. Training loss: 0.10.\n",
      "  Completed iter 37300/70000. Training loss: 0.10.\n",
      "  Completed iter 37400/70000. Training loss: 0.12.\n",
      "  Completed iter 37500/70000. Training loss: 0.11.\n",
      "  Completed iter 37600/70000. Training loss: 0.11.\n",
      "  Completed iter 37700/70000. Training loss: 0.11.\n",
      "  Completed iter 37800/70000. Training loss: 0.10.\n",
      "  Completed iter 37900/70000. Training loss: 0.12.\n",
      "  Completed iter 38000/70000. Training loss: 0.14.\n",
      "  Completed iter 38100/70000. Training loss: 0.13.\n",
      "  Completed iter 38200/70000. Training loss: 0.11.\n",
      "  Completed iter 38300/70000. Training loss: 0.11.\n",
      "  Completed iter 38400/70000. Training loss: 0.14.\n",
      "  Completed iter 38500/70000. Training loss: 0.12.\n",
      "  Completed iter 38600/70000. Training loss: 0.13.\n",
      "  Completed iter 38700/70000. Training loss: 0.12.\n",
      "  Completed iter 38800/70000. Training loss: 0.11.\n",
      "  Completed iter 38900/70000. Training loss: 0.14.\n",
      "  Completed iter 39000/70000. Training loss: 0.12.\n",
      "  Completed iter 39100/70000. Training loss: 0.12.\n",
      "  Completed iter 39200/70000. Training loss: 0.11.\n",
      "  Completed iter 39300/70000. Training loss: 0.13.\n",
      "  Completed iter 39400/70000. Training loss: 0.11.\n",
      "  Completed iter 39500/70000. Training loss: 0.11.\n",
      "  Completed iter 39600/70000. Training loss: 0.11.\n",
      "  Completed iter 39700/70000. Training loss: 0.11.\n",
      "  Completed iter 39800/70000. Training loss: 0.12.\n",
      "  Completed iter 39900/70000. Training loss: 0.10.\n",
      "  Completed iter 40000/70000. Training loss: 0.13.\n",
      "  Completed iter 40100/70000. Training loss: 0.12.\n",
      "  Completed iter 40200/70000. Training loss: 0.12.\n",
      "  Completed iter 40300/70000. Training loss: 0.12.\n",
      "  Completed iter 40400/70000. Training loss: 0.12.\n",
      "  Completed iter 40500/70000. Training loss: 0.09.\n",
      "  Completed iter 40600/70000. Training loss: 0.15.\n",
      "  Completed iter 40700/70000. Training loss: 0.11.\n",
      "  Completed iter 40800/70000. Training loss: 0.12.\n",
      "  Completed iter 40900/70000. Training loss: 0.14.\n",
      "  Completed iter 41000/70000. Training loss: 0.14.\n",
      "  Completed iter 41100/70000. Training loss: 0.13.\n",
      "  Completed iter 41200/70000. Training loss: 0.10.\n",
      "  Completed iter 41300/70000. Training loss: 0.16.\n",
      "  Completed iter 41400/70000. Training loss: 0.15.\n",
      "  Completed iter 41500/70000. Training loss: 0.15.\n",
      "  Completed iter 41600/70000. Training loss: 0.12.\n",
      "  Completed iter 41700/70000. Training loss: 0.12.\n",
      "  Completed iter 41800/70000. Training loss: 0.08.\n",
      "  Completed iter 41900/70000. Training loss: 0.10.\n",
      "  Completed iter 42000/70000. Training loss: 0.10.\n",
      "  Completed iter 42100/70000. Training loss: 0.14.\n",
      "  Completed iter 42200/70000. Training loss: 0.13.\n",
      "  Completed iter 42300/70000. Training loss: 0.12.\n",
      "  Completed iter 42400/70000. Training loss: 0.13.\n",
      "  Completed iter 42500/70000. Training loss: 0.11.\n",
      "  Completed iter 42600/70000. Training loss: 0.12.\n",
      "  Completed iter 42700/70000. Training loss: 0.10.\n",
      "  Completed iter 42800/70000. Training loss: 0.10.\n",
      "  Completed iter 42900/70000. Training loss: 0.08.\n",
      "  Completed iter 43000/70000. Training loss: 0.10.\n",
      "  Completed iter 43100/70000. Training loss: 0.10.\n",
      "  Completed iter 43200/70000. Training loss: 0.14.\n",
      "  Completed iter 43300/70000. Training loss: 0.10.\n",
      "  Completed iter 43400/70000. Training loss: 0.12.\n",
      "  Completed iter 43500/70000. Training loss: 0.09.\n",
      "  Completed iter 43600/70000. Training loss: 0.12.\n",
      "  Completed iter 43700/70000. Training loss: 0.10.\n",
      "  Completed iter 43800/70000. Training loss: 0.08.\n",
      "  Completed iter 43900/70000. Training loss: 0.09.\n",
      "  Completed iter 44000/70000. Training loss: 0.11.\n",
      "  Completed iter 44100/70000. Training loss: 0.13.\n",
      "  Completed iter 44200/70000. Training loss: 0.13.\n",
      "  Completed iter 44300/70000. Training loss: 0.13.\n",
      "  Completed iter 44400/70000. Training loss: 0.11.\n",
      "  Completed iter 44500/70000. Training loss: 0.09.\n",
      "  Completed iter 44600/70000. Training loss: 0.11.\n",
      "  Completed iter 44700/70000. Training loss: 0.08.\n",
      "  Completed iter 44800/70000. Training loss: 0.13.\n",
      "  Completed iter 44900/70000. Training loss: 0.14.\n",
      "  Completed iter 45000/70000. Training loss: 0.11.\n",
      "  Completed iter 45100/70000. Training loss: 0.14.\n",
      "  Completed iter 45200/70000. Training loss: 0.11.\n",
      "  Completed iter 45300/70000. Training loss: 0.10.\n",
      "  Completed iter 45400/70000. Training loss: 0.10.\n",
      "  Completed iter 45500/70000. Training loss: 0.10.\n",
      "  Completed iter 45600/70000. Training loss: 0.09.\n",
      "  Completed iter 45700/70000. Training loss: 0.06.\n",
      "  Completed iter 45800/70000. Training loss: 0.11.\n",
      "  Completed iter 45900/70000. Training loss: 0.09.\n",
      "  Completed iter 46000/70000. Training loss: 0.10.\n",
      "  Completed iter 46100/70000. Training loss: 0.11.\n",
      "  Completed iter 46200/70000. Training loss: 0.11.\n",
      "  Completed iter 46300/70000. Training loss: 0.11.\n",
      "  Completed iter 46400/70000. Training loss: 0.08.\n",
      "  Completed iter 46500/70000. Training loss: 0.13.\n",
      "  Completed iter 46600/70000. Training loss: 0.11.\n",
      "  Completed iter 46700/70000. Training loss: 0.07.\n",
      "  Completed iter 46800/70000. Training loss: 0.10.\n",
      "  Completed iter 46900/70000. Training loss: 0.13.\n",
      "  Completed iter 47000/70000. Training loss: 0.09.\n",
      "  Completed iter 47100/70000. Training loss: 0.06.\n",
      "  Completed iter 47200/70000. Training loss: 0.09.\n",
      "  Completed iter 47300/70000. Training loss: 0.14.\n",
      "  Completed iter 47400/70000. Training loss: 0.09.\n",
      "  Completed iter 47500/70000. Training loss: 0.13.\n",
      "  Completed iter 47600/70000. Training loss: 0.11.\n",
      "  Completed iter 47700/70000. Training loss: 0.11.\n",
      "  Completed iter 47800/70000. Training loss: 0.08.\n",
      "  Completed iter 47900/70000. Training loss: 0.08.\n",
      "  Completed iter 48000/70000. Training loss: 0.10.\n",
      "  Completed iter 48100/70000. Training loss: 0.12.\n",
      "  Completed iter 48200/70000. Training loss: 0.12.\n",
      "  Completed iter 48300/70000. Training loss: 0.11.\n",
      "  Completed iter 48400/70000. Training loss: 0.14.\n",
      "  Completed iter 48500/70000. Training loss: 0.08.\n",
      "  Completed iter 48600/70000. Training loss: 0.07.\n",
      "  Completed iter 48700/70000. Training loss: 0.09.\n",
      "  Completed iter 48800/70000. Training loss: 0.10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 48900/70000. Training loss: 0.12.\n",
      "  Completed iter 49000/70000. Training loss: 0.14.\n",
      "  Completed iter 49100/70000. Training loss: 0.11.\n",
      "  Completed iter 49200/70000. Training loss: 0.08.\n",
      "  Completed iter 49300/70000. Training loss: 0.11.\n",
      "  Completed iter 49400/70000. Training loss: 0.10.\n",
      "  Completed iter 49500/70000. Training loss: 0.09.\n",
      "  Completed iter 49600/70000. Training loss: 0.07.\n",
      "  Completed iter 49700/70000. Training loss: 0.09.\n",
      "  Completed iter 49800/70000. Training loss: 0.10.\n",
      "  Completed iter 49900/70000. Training loss: 0.11.\n",
      "  Completed iter 50000/70000. Training loss: 0.09.\n",
      "  Completed iter 50100/70000. Training loss: 0.10.\n",
      "  Completed iter 50200/70000. Training loss: 0.08.\n",
      "  Completed iter 50300/70000. Training loss: 0.11.\n",
      "  Completed iter 50400/70000. Training loss: 0.11.\n",
      "  Completed iter 50500/70000. Training loss: 0.09.\n",
      "  Completed iter 50600/70000. Training loss: 0.11.\n",
      "  Completed iter 50700/70000. Training loss: 0.07.\n",
      "  Completed iter 50800/70000. Training loss: 0.10.\n",
      "  Completed iter 50900/70000. Training loss: 0.09.\n",
      "  Completed iter 51000/70000. Training loss: 0.10.\n",
      "  Completed iter 51100/70000. Training loss: 0.07.\n",
      "  Completed iter 51200/70000. Training loss: 0.10.\n",
      "  Completed iter 51300/70000. Training loss: 0.07.\n",
      "  Completed iter 51400/70000. Training loss: 0.07.\n",
      "  Completed iter 51500/70000. Training loss: 0.09.\n",
      "  Completed iter 51600/70000. Training loss: 0.07.\n",
      "  Completed iter 51700/70000. Training loss: 0.07.\n",
      "  Completed iter 51800/70000. Training loss: 0.09.\n",
      "  Completed iter 51900/70000. Training loss: 0.12.\n",
      "  Completed iter 52000/70000. Training loss: 0.08.\n",
      "  Completed iter 52100/70000. Training loss: 0.11.\n",
      "  Completed iter 52200/70000. Training loss: 0.13.\n",
      "  Completed iter 52300/70000. Training loss: 0.08.\n",
      "  Completed iter 52400/70000. Training loss: 0.12.\n",
      "  Completed iter 52500/70000. Training loss: 0.10.\n",
      "  Completed iter 52600/70000. Training loss: 0.09.\n",
      "  Completed iter 52700/70000. Training loss: 0.08.\n",
      "  Completed iter 52800/70000. Training loss: 0.12.\n",
      "  Completed iter 52900/70000. Training loss: 0.08.\n",
      "  Completed iter 53000/70000. Training loss: 0.07.\n",
      "  Completed iter 53100/70000. Training loss: 0.07.\n",
      "  Completed iter 53200/70000. Training loss: 0.08.\n",
      "  Completed iter 53300/70000. Training loss: 0.10.\n",
      "  Completed iter 53400/70000. Training loss: 0.10.\n",
      "  Completed iter 53500/70000. Training loss: 0.09.\n",
      "  Completed iter 53600/70000. Training loss: 0.11.\n",
      "  Completed iter 53700/70000. Training loss: 0.10.\n",
      "  Completed iter 53800/70000. Training loss: 0.08.\n",
      "  Completed iter 53900/70000. Training loss: 0.10.\n",
      "  Completed iter 54000/70000. Training loss: 0.09.\n",
      "  Completed iter 54100/70000. Training loss: 0.08.\n",
      "  Completed iter 54200/70000. Training loss: 0.10.\n",
      "  Completed iter 54300/70000. Training loss: 0.07.\n",
      "  Completed iter 54400/70000. Training loss: 0.08.\n",
      "  Completed iter 54500/70000. Training loss: 0.10.\n",
      "  Completed iter 54600/70000. Training loss: 0.08.\n",
      "  Completed iter 54700/70000. Training loss: 0.08.\n",
      "  Completed iter 54800/70000. Training loss: 0.10.\n",
      "  Completed iter 54900/70000. Training loss: 0.11.\n",
      "  Completed iter 55000/70000. Training loss: 0.08.\n",
      "  Completed iter 55100/70000. Training loss: 0.09.\n",
      "  Completed iter 55200/70000. Training loss: 0.07.\n",
      "  Completed iter 55300/70000. Training loss: 0.08.\n",
      "  Completed iter 55400/70000. Training loss: 0.11.\n",
      "  Completed iter 55500/70000. Training loss: 0.11.\n",
      "  Completed iter 55600/70000. Training loss: 0.07.\n",
      "  Completed iter 55700/70000. Training loss: 0.09.\n",
      "  Completed iter 55800/70000. Training loss: 0.12.\n",
      "  Completed iter 55900/70000. Training loss: 0.08.\n",
      "  Completed iter 56000/70000. Training loss: 0.08.\n",
      "  Completed iter 56100/70000. Training loss: 0.08.\n",
      "  Completed iter 56200/70000. Training loss: 0.09.\n",
      "  Completed iter 56300/70000. Training loss: 0.13.\n",
      "  Completed iter 56400/70000. Training loss: 0.12.\n",
      "  Completed iter 56500/70000. Training loss: 0.07.\n",
      "  Completed iter 56600/70000. Training loss: 0.09.\n",
      "  Completed iter 56700/70000. Training loss: 0.09.\n",
      "  Completed iter 56800/70000. Training loss: 0.09.\n",
      "  Completed iter 56900/70000. Training loss: 0.12.\n",
      "  Completed iter 57000/70000. Training loss: 0.06.\n",
      "  Completed iter 57100/70000. Training loss: 0.07.\n",
      "  Completed iter 57200/70000. Training loss: 0.08.\n",
      "  Completed iter 57300/70000. Training loss: 0.09.\n",
      "  Completed iter 57400/70000. Training loss: 0.10.\n",
      "  Completed iter 57500/70000. Training loss: 0.07.\n",
      "  Completed iter 57600/70000. Training loss: 0.09.\n",
      "  Completed iter 57700/70000. Training loss: 0.06.\n",
      "  Completed iter 57800/70000. Training loss: 0.07.\n",
      "  Completed iter 57900/70000. Training loss: 0.07.\n",
      "  Completed iter 58000/70000. Training loss: 0.05.\n",
      "  Completed iter 58100/70000. Training loss: 0.10.\n",
      "  Completed iter 58200/70000. Training loss: 0.09.\n",
      "  Completed iter 58300/70000. Training loss: 0.07.\n",
      "  Completed iter 58400/70000. Training loss: 0.10.\n",
      "  Completed iter 58500/70000. Training loss: 0.12.\n",
      "  Completed iter 58600/70000. Training loss: 0.09.\n",
      "  Completed iter 58700/70000. Training loss: 0.08.\n",
      "  Completed iter 58800/70000. Training loss: 0.12.\n",
      "  Completed iter 58900/70000. Training loss: 0.11.\n",
      "  Completed iter 59000/70000. Training loss: 0.09.\n",
      "  Completed iter 59100/70000. Training loss: 0.10.\n",
      "  Completed iter 59200/70000. Training loss: 0.09.\n",
      "  Completed iter 59300/70000. Training loss: 0.10.\n",
      "  Completed iter 59400/70000. Training loss: 0.09.\n",
      "  Completed iter 59500/70000. Training loss: 0.07.\n",
      "  Completed iter 59600/70000. Training loss: 0.08.\n",
      "  Completed iter 59700/70000. Training loss: 0.09.\n",
      "  Completed iter 59800/70000. Training loss: 0.10.\n",
      "  Completed iter 59900/70000. Training loss: 0.06.\n",
      "  Completed iter 60000/70000. Training loss: 0.08.\n",
      "  Completed iter 60100/70000. Training loss: 0.08.\n",
      "  Completed iter 60200/70000. Training loss: 0.07.\n",
      "  Completed iter 60300/70000. Training loss: 0.06.\n",
      "  Completed iter 60400/70000. Training loss: 0.09.\n",
      "  Completed iter 60500/70000. Training loss: 0.07.\n",
      "  Completed iter 60600/70000. Training loss: 0.09.\n",
      "  Completed iter 60700/70000. Training loss: 0.09.\n",
      "  Completed iter 60800/70000. Training loss: 0.05.\n",
      "  Completed iter 60900/70000. Training loss: 0.12.\n",
      "  Completed iter 61000/70000. Training loss: 0.06.\n",
      "  Completed iter 61100/70000. Training loss: 0.06.\n",
      "  Completed iter 61200/70000. Training loss: 0.09.\n",
      "  Completed iter 61300/70000. Training loss: 0.07.\n",
      "  Completed iter 61400/70000. Training loss: 0.10.\n",
      "  Completed iter 61500/70000. Training loss: 0.09.\n",
      "  Completed iter 61600/70000. Training loss: 0.05.\n",
      "  Completed iter 61700/70000. Training loss: 0.08.\n",
      "  Completed iter 61800/70000. Training loss: 0.08.\n",
      "  Completed iter 61900/70000. Training loss: 0.10.\n",
      "  Completed iter 62000/70000. Training loss: 0.09.\n",
      "  Completed iter 62100/70000. Training loss: 0.08.\n",
      "  Completed iter 62200/70000. Training loss: 0.08.\n",
      "  Completed iter 62300/70000. Training loss: 0.10.\n",
      "  Completed iter 62400/70000. Training loss: 0.07.\n",
      "  Completed iter 62500/70000. Training loss: 0.07.\n",
      "  Completed iter 62600/70000. Training loss: 0.09.\n",
      "  Completed iter 62700/70000. Training loss: 0.08.\n",
      "  Completed iter 62800/70000. Training loss: 0.09.\n",
      "  Completed iter 62900/70000. Training loss: 0.09.\n",
      "  Completed iter 63000/70000. Training loss: 0.07.\n",
      "  Completed iter 63100/70000. Training loss: 0.08.\n",
      "  Completed iter 63200/70000. Training loss: 0.09.\n",
      "  Completed iter 63300/70000. Training loss: 0.08.\n",
      "  Completed iter 63400/70000. Training loss: 0.07.\n",
      "  Completed iter 63500/70000. Training loss: 0.09.\n",
      "  Completed iter 63600/70000. Training loss: 0.12.\n",
      "  Completed iter 63700/70000. Training loss: 0.11.\n",
      "  Completed iter 63800/70000. Training loss: 0.08.\n",
      "  Completed iter 63900/70000. Training loss: 0.06.\n",
      "  Completed iter 64000/70000. Training loss: 0.06.\n",
      "  Completed iter 64100/70000. Training loss: 0.08.\n",
      "  Completed iter 64200/70000. Training loss: 0.08.\n",
      "  Completed iter 64300/70000. Training loss: 0.10.\n",
      "  Completed iter 64400/70000. Training loss: 0.08.\n",
      "  Completed iter 64500/70000. Training loss: 0.07.\n",
      "  Completed iter 64600/70000. Training loss: 0.10.\n",
      "  Completed iter 64700/70000. Training loss: 0.07.\n",
      "  Completed iter 64800/70000. Training loss: 0.07.\n",
      "  Completed iter 64900/70000. Training loss: 0.09.\n",
      "  Completed iter 65000/70000. Training loss: 0.09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 65100/70000. Training loss: 0.08.\n",
      "  Completed iter 65200/70000. Training loss: 0.05.\n",
      "  Completed iter 65300/70000. Training loss: 0.08.\n",
      "  Completed iter 65400/70000. Training loss: 0.07.\n",
      "  Completed iter 65500/70000. Training loss: 0.06.\n",
      "  Completed iter 65600/70000. Training loss: 0.09.\n",
      "  Completed iter 65700/70000. Training loss: 0.08.\n",
      "  Completed iter 65800/70000. Training loss: 0.07.\n",
      "  Completed iter 65900/70000. Training loss: 0.09.\n",
      "  Completed iter 66000/70000. Training loss: 0.08.\n",
      "  Completed iter 66100/70000. Training loss: 0.07.\n",
      "  Completed iter 66200/70000. Training loss: 0.04.\n",
      "  Completed iter 66300/70000. Training loss: 0.07.\n",
      "  Completed iter 66400/70000. Training loss: 0.08.\n",
      "  Completed iter 66500/70000. Training loss: 0.07.\n",
      "  Completed iter 66600/70000. Training loss: 0.09.\n",
      "  Completed iter 66700/70000. Training loss: 0.06.\n",
      "  Completed iter 66800/70000. Training loss: 0.10.\n",
      "  Completed iter 66900/70000. Training loss: 0.09.\n",
      "  Completed iter 67000/70000. Training loss: 0.07.\n",
      "  Completed iter 67100/70000. Training loss: 0.07.\n",
      "  Completed iter 67200/70000. Training loss: 0.09.\n",
      "  Completed iter 67300/70000. Training loss: 0.06.\n",
      "  Completed iter 67400/70000. Training loss: 0.07.\n",
      "  Completed iter 67500/70000. Training loss: 0.09.\n",
      "  Completed iter 67600/70000. Training loss: 0.08.\n",
      "  Completed iter 67700/70000. Training loss: 0.09.\n",
      "  Completed iter 67800/70000. Training loss: 0.07.\n",
      "  Completed iter 67900/70000. Training loss: 0.11.\n",
      "  Completed iter 68000/70000. Training loss: 0.11.\n",
      "  Completed iter 68100/70000. Training loss: 0.08.\n",
      "  Completed iter 68200/70000. Training loss: 0.09.\n",
      "  Completed iter 68300/70000. Training loss: 0.08.\n",
      "  Completed iter 68400/70000. Training loss: 0.08.\n",
      "  Completed iter 68500/70000. Training loss: 0.09.\n",
      "  Completed iter 68600/70000. Training loss: 0.09.\n",
      "  Completed iter 68700/70000. Training loss: 0.08.\n",
      "  Completed iter 68800/70000. Training loss: 0.07.\n",
      "  Completed iter 68900/70000. Training loss: 0.06.\n",
      "  Completed iter 69000/70000. Training loss: 0.05.\n",
      "  Completed iter 69100/70000. Training loss: 0.09.\n",
      "  Completed iter 69200/70000. Training loss: 0.06.\n",
      "  Completed iter 69300/70000. Training loss: 0.06.\n",
      "  Completed iter 69400/70000. Training loss: 0.12.\n",
      "  Completed iter 69500/70000. Training loss: 0.07.\n",
      "  Completed iter 69600/70000. Training loss: 0.08.\n",
      "  Completed iter 69700/70000. Training loss: 0.08.\n",
      "  Completed iter 69800/70000. Training loss: 0.09.\n",
      "  Completed iter 69900/70000. Training loss: 0.07.\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train = test\n",
    "hidden_size = 50\n",
    "net = MLP(cis_train_x.shape[1], hidden_size, 2)\n",
    "loss, acc_t, acc_v = net.fit(cis_test_x, cis_test_y, cis_val_x, cis_val_y, reg=0, lr=0.01, mini_batch_sz=100, n_epochs=700)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg cross-entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Run the below cell after training and generate the CIS plot. You should see a well-defined circle inside a square region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cis_test_y_pred = net.predict(cis_test_x)\n",
    "plt.scatter(cis_test_x[:,0], cis_test_x[:,1], c=cis_test_y_pred)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second test case where training data != test data:** You should see a jagged polygon approximation to a circle inside a square region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train != test\n",
    "net = MLP(cis_train_x.shape[1], hidden_size, 2)\n",
    "loss, acc_t, acc_v = net.fit(cis_train_x, cis_train_y, cis_val_x, cis_val_y, reg=0, lr=0.01, mini_batch_sz=len(cis_train_x), n_epochs=10000)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg cross-entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Run the below cell after training and generate the CIS plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_test_y_pred = net.predict(cis_test_x)\n",
    "plt.scatter(cis_test_x[:,0], cis_test_x[:,1], c=cis_test_y_pred)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: How do you interpret the circle-in-square results? Do you think the single-layer net (with softmax) can handle the CIS dataset? Why or why not? (You're invited to try it, maybe as an extension :)\n",
    "\n",
    "**Question 6**: Play with # hidden units, epochs, regularization strength on CIS training...how does each parameter affect the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Train on STL-10 dataset, plot performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try training the MLP on the below set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP(x_train.shape[1], 100, 10)\n",
    "loss, acc_t, acc_v = net.fit(x_train, y_train, x_val, y_val,\n",
    "                             lr=0.05, reg=0.01, mini_batch_sz=500, n_epochs=50, verbose=0)\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Avg loss (cross entropy)')\n",
    "plt.title('STL-10 loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_t, label='Training accuracy')\n",
    "plt.plot(acc_v, label='Validation accuracy')\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Avg loss (cross entropy)')\n",
    "plt.title('STL-10 accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**: What do the above loss and training and validation accuracy curves suggest about the quality of the hyperparameters used during training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Optimize on STL-10 dataset, plot performance\n",
    "\n",
    "**TODO** Write code in the cell below to perform a grid search to find the combinations of\n",
    "\n",
    "- learning rate\n",
    "- regularization strength\n",
    "- number hidden units\n",
    "- mini-batch size\n",
    "\n",
    "that yields the highest STL-10 validation set accuracy.\n",
    "\n",
    "You should be able to achieve higher accuracy than in the single layer version of the softmax network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_val_acc = 0\n",
    "best_lr = None\n",
    "best_reg = None\n",
    "best_hidden = None\n",
    "best_mini_batch_sz = None\n",
    "\n",
    "def gridSearch(lower_bound=.0001, upper_bound=.099):\n",
    "    best_val_acc = 0\n",
    "    accuracy_vals = []\n",
    "    loss_vals = []\n",
    "    learning_rates = np.linspace(.0001, .099, num=1)\n",
    "    reg_vals = np.linspace(0, 5, num=1)\n",
    "    batch_sizes = np.linspace(1, 500, num=1, dtype=int)\n",
    "    hidden_vals = np.linspace(50, 200, num = 3, dtype = int)\n",
    "    \n",
    "    \n",
    "#     accuracy_vals.append(0)\n",
    "    \n",
    "    count = 0\n",
    "    for rate in learning_rates:\n",
    "        count +=1\n",
    "        for reg_val in reg_vals:\n",
    "            for hidden in hidden_vals:\n",
    "                for batch_size in batch_sizes:\n",
    "                    net = MLP(x_train.shape[1], hidden, 10)\n",
    "                    loss, acc_t, acc_v = net.fit(x_train, y_train, x_val, y_val, lr=rate, reg=reg_val, \n",
    "                                                 mini_batch_sz=batch_size, n_epochs=7, verbose=0)\n",
    "                    accuracy_vals.append(acc_v)\n",
    "                    if max(accuracy_vals) <= accuracy_vals[-1]:\n",
    "                        best_lr = rate\n",
    "                        best_reg = reg_val\n",
    "                        best_hidden = hidden\n",
    "                        best_mini_batch_sz = batch_size \n",
    "                        best_val_acc = accuracy_vals[-1]\n",
    "        print(count)\n",
    "\n",
    "        print(\"Best learning rate: \", str(best_lr))\n",
    "        print(\"Best regulization value: \", str(best_reg))\n",
    "        print(\"Best batch size: \", str(best_mini_batch_sz))\n",
    "        print(\"Best hidden val: \", str(best_hidden))\n",
    "        print(accuracy_vals)\n",
    "    \n",
    "\n",
    "gridSearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Set the parameters below to the best ones found by your grid search.\n",
    "- Generate and include the Test STL-10 loss curve\n",
    "- Generate and include the training and validation accuracy curves in the second cell down.\n",
    "\n",
    "Adjust the number of training epochs as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 5000 epochs and 5000 iterations total, 1 iter/epoch.\n",
      "  Completed iter 0/5000. Training loss: 1541.98.\n",
      "  Completed iter 100/5000. Training loss: 3.42.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-99cabc717ca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mbestNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m loss, acc_t, acc_v = bestNet.fit(x_test, y_test, x_val, y_val,\n\u001b[1;32m----> 9\u001b[1;33m                                  lr=best_lr, reg=best_reg, mini_batch_sz=best_mini_batch_sz, n_epochs=5000, verbose=1)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\onedrive\\documents\\classes\\NeuralNetworks\\project2\\mlp.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, y, x_validation, y_validation, resume_training, n_epochs, lr, mini_batch_sz, reg, verbose)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;31m#update weights and biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_wts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_wts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdy_wts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_b\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdy_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz_wts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz_wts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdz_wts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the net with the bestparam settings\n",
    "best_lr = .071\n",
    "best_reg = .5\n",
    "best_hidden = 200\n",
    "best_mini_batch_sz = 500\n",
    "\n",
    "bestNet = MLP(x_train.shape[1], best_hidden, 10)\n",
    "loss, acc_t, acc_v = bestNet.fit(x_test, y_test, x_val, y_val,\n",
    "                                 lr=best_lr, reg=best_reg, mini_batch_sz=best_mini_batch_sz, n_epochs=5000, verbose=1)\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Avg loss (cross entropy)')\n",
    "plt.title('Test STL-10 data loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_t, label='Training accuracy')\n",
    "plt.plot(acc_v, label='Validation accuracy')\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('Avg loss (cross entropy)')\n",
    "plt.title('Test STL-10 data accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Visualize learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "\n",
    "- In the cell below, get the weights of your best net's hidden layer (Y), reshape/transpose them so that they are `(N, 32, 32, 3)`.\n",
    "- Run the `plot_weights` function to generate a grid visualization of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bestNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-c83b90318b65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_y_wts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_y_wts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbest_y_wts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_y_wts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_y_wts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bestNet' is not defined"
     ]
    }
   ],
   "source": [
    "best_y_wts = bestNet.get_y_wts()\n",
    "best_y_wts = best_y_wts.T.reshape()\n",
    "print(best_y_wts.T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(wts):\n",
    "    grid_sz = int(np.sqrt(len(wts)))\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for x in range(grid_sz):\n",
    "        for y in range(grid_sz):\n",
    "            lin_ind = np.ravel_multi_index((x, y), dims=(grid_sz, grid_sz))\n",
    "            plt.subplot(grid_sz, grid_sz, lin_ind+1)\n",
    "            currImg = wts[lin_ind]\n",
    "            low, high = np.min(currImg), np.max(currImg)\n",
    "            currImg = 255*(currImg - low) / (high - low)\n",
    "            currImg = currImg.astype('uint8')\n",
    "            plt.imshow(currImg)\n",
    "            plt.gca().axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights(best_y_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "**Reminder**: Please do not integrate extensions into your base project so that it changes the expected behavior of core functions. It is better to duplicate the base project and add features from there.\n",
    "\n",
    "1) Instead of computing the loss over a mini-batch, compute it over epochs instead. Compare and contrast the approaches. Be sure to include analysis figures.\n",
    "\n",
    "2) Investigate how the single layer softmax network does with the CIS dataset. Explain and provide plots showing your results.\n",
    "\n",
    "3) If you have time to spare (or want to throw more computing power at the STL-10 dataset), process through the SLP and MLP and tune hyperparameters with the dataset at its original resolution (96x96 images). Show images of your learned weights. Can you find a training sweet spot where the learned weight visualizations look particularly cool?\n",
    "\n",
    "4) Implement the sigmoid classifer (same network structure, except use sigmoid for netact) with the cross-entropy loss by creating another subclass of `SingleLayerNet` and/or `MLP`. Compare and contrast results achieved by the softmax/cross-entropy network.\n",
    "\n",
    "5) Explore the effects of batch gradient descent, stochastic gradient descent, and mini-batch gradient descent.\n",
    "\n",
    "6) Obtain, preprocess, train, and evaluate the performance of `SingleLayerNet` and/or `MLP` on another dataset with comparable types of image features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 1\n",
    "We took on the first suggested extension and tried out a few different values for the number of samples in a mini-batch. First, we made the size of a mini batch equal to the size of an epoch, so for all intents and purposes there were no mini batches. This was about as effective as using a mini-batch, but it took a very long time, so using batches is better if you don't have a perfect computer. \n",
    "\n",
    "Next, we set the mini-batch size to 1, which resulted in a sort of cone shape for the loss values. They started at about 0.7 and went as low as 0 and above 2.0. It reached 0 very quickly, but it was quite unpredictable because it was updating at every sample and a loss of 0 just means that it got a single sample correct.\n",
    "\n",
    "We also set the mini-batch size to 100. This seemed to be a happy medium between the two, because it did not take that long to run and it reached a loss of 0.07, which is very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 7000 epochs and 7000 iterations total, 1 iter/epoch.\n",
      "  Completed iter 0/7000. Training loss: 0.70.\n",
      "  Completed iter 100/7000. Training loss: 0.69.\n",
      "  Completed iter 200/7000. Training loss: 0.69.\n",
      "  Completed iter 300/7000. Training loss: 0.69.\n",
      "  Completed iter 400/7000. Training loss: 0.69.\n",
      "  Completed iter 500/7000. Training loss: 0.69.\n",
      "  Completed iter 600/7000. Training loss: 0.69.\n",
      "  Completed iter 700/7000. Training loss: 0.69.\n",
      "  Completed iter 800/7000. Training loss: 0.69.\n",
      "  Completed iter 900/7000. Training loss: 0.69.\n",
      "  Completed iter 1000/7000. Training loss: 0.69.\n",
      "  Completed iter 1100/7000. Training loss: 0.69.\n",
      "  Completed iter 1200/7000. Training loss: 0.69.\n",
      "  Completed iter 1300/7000. Training loss: 0.69.\n",
      "  Completed iter 1400/7000. Training loss: 0.69.\n",
      "  Completed iter 1500/7000. Training loss: 0.69.\n",
      "  Completed iter 1600/7000. Training loss: 0.69.\n",
      "  Completed iter 1700/7000. Training loss: 0.69.\n",
      "  Completed iter 1800/7000. Training loss: 0.69.\n",
      "  Completed iter 1900/7000. Training loss: 0.69.\n",
      "  Completed iter 2000/7000. Training loss: 0.68.\n",
      "  Completed iter 2100/7000. Training loss: 0.68.\n",
      "  Completed iter 2200/7000. Training loss: 0.68.\n",
      "  Completed iter 2300/7000. Training loss: 0.68.\n",
      "  Completed iter 2400/7000. Training loss: 0.68.\n",
      "  Completed iter 2500/7000. Training loss: 0.68.\n",
      "  Completed iter 2600/7000. Training loss: 0.68.\n",
      "  Completed iter 2700/7000. Training loss: 0.68.\n",
      "  Completed iter 2800/7000. Training loss: 0.68.\n",
      "  Completed iter 2900/7000. Training loss: 0.68.\n",
      "  Completed iter 3000/7000. Training loss: 0.68.\n",
      "  Completed iter 3100/7000. Training loss: 0.68.\n",
      "  Completed iter 3200/7000. Training loss: 0.68.\n",
      "  Completed iter 3300/7000. Training loss: 0.68.\n",
      "  Completed iter 3400/7000. Training loss: 0.68.\n",
      "  Completed iter 3500/7000. Training loss: 0.67.\n",
      "  Completed iter 3600/7000. Training loss: 0.67.\n",
      "  Completed iter 3700/7000. Training loss: 0.67.\n",
      "  Completed iter 3800/7000. Training loss: 0.67.\n",
      "  Completed iter 3900/7000. Training loss: 0.67.\n",
      "  Completed iter 4000/7000. Training loss: 0.67.\n",
      "  Completed iter 4100/7000. Training loss: 0.67.\n",
      "  Completed iter 4200/7000. Training loss: 0.67.\n",
      "  Completed iter 4300/7000. Training loss: 0.67.\n",
      "  Completed iter 4400/7000. Training loss: 0.67.\n",
      "  Completed iter 4500/7000. Training loss: 0.67.\n",
      "  Completed iter 4600/7000. Training loss: 0.66.\n",
      "  Completed iter 4700/7000. Training loss: 0.66.\n",
      "  Completed iter 4800/7000. Training loss: 0.66.\n",
      "  Completed iter 4900/7000. Training loss: 0.66.\n",
      "  Completed iter 5000/7000. Training loss: 0.66.\n",
      "  Completed iter 5100/7000. Training loss: 0.66.\n",
      "  Completed iter 5200/7000. Training loss: 0.65.\n",
      "  Completed iter 5300/7000. Training loss: 0.65.\n",
      "  Completed iter 5400/7000. Training loss: 0.65.\n",
      "  Completed iter 5500/7000. Training loss: 0.65.\n",
      "  Completed iter 5600/7000. Training loss: 0.65.\n",
      "  Completed iter 5700/7000. Training loss: 0.65.\n",
      "  Completed iter 5800/7000. Training loss: 0.64.\n",
      "  Completed iter 5900/7000. Training loss: 0.64.\n",
      "  Completed iter 6000/7000. Training loss: 0.64.\n",
      "  Completed iter 6100/7000. Training loss: 0.64.\n",
      "  Completed iter 6200/7000. Training loss: 0.64.\n",
      "  Completed iter 6300/7000. Training loss: 0.63.\n",
      "  Completed iter 6400/7000. Training loss: 0.63.\n",
      "  Completed iter 6500/7000. Training loss: 0.63.\n",
      "  Completed iter 6600/7000. Training loss: 0.63.\n",
      "  Completed iter 6700/7000. Training loss: 0.62.\n",
      "  Completed iter 6800/7000. Training loss: 0.62.\n",
      "  Completed iter 6900/7000. Training loss: 0.62.\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    ".hidden_size = 50\n",
    "net = MLP(cis_train_x.shape[1], hidden_size, 2)\n",
    "loss, acc_t, acc_v = net.fit(cis_test_x, cis_test_y, cis_val_x, cis_val_y, reg=0, lr=0.01, mini_batch_sz=cis_test_x.shape[0], n_epochs=7000)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg cross-entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 5 epochs and 50000 iterations total, 10000 iter/epoch.\n",
      "  Completed iter 0/50000. Training loss: 0.83.\n",
      "  Completed iter 100/50000. Training loss: 0.69.\n",
      "  Completed iter 200/50000. Training loss: 0.66.\n",
      "  Completed iter 300/50000. Training loss: 0.62.\n",
      "  Completed iter 400/50000. Training loss: 0.65.\n",
      "  Completed iter 500/50000. Training loss: 0.57.\n",
      "  Completed iter 600/50000. Training loss: 0.62.\n",
      "  Completed iter 700/50000. Training loss: 0.60.\n",
      "  Completed iter 800/50000. Training loss: 0.67.\n",
      "  Completed iter 900/50000. Training loss: 0.70.\n",
      "  Completed iter 1000/50000. Training loss: 0.61.\n",
      "  Completed iter 1100/50000. Training loss: 0.64.\n",
      "  Completed iter 1200/50000. Training loss: 0.75.\n",
      "  Completed iter 1300/50000. Training loss: 0.71.\n",
      "  Completed iter 1400/50000. Training loss: 0.65.\n",
      "  Completed iter 1500/50000. Training loss: 0.71.\n",
      "  Completed iter 1600/50000. Training loss: 0.82.\n",
      "  Completed iter 1700/50000. Training loss: 0.72.\n",
      "  Completed iter 1800/50000. Training loss: 0.64.\n",
      "  Completed iter 1900/50000. Training loss: 0.64.\n",
      "  Completed iter 2000/50000. Training loss: 0.73.\n",
      "  Completed iter 2100/50000. Training loss: 0.64.\n",
      "  Completed iter 2200/50000. Training loss: 0.68.\n",
      "  Completed iter 2300/50000. Training loss: 0.76.\n",
      "  Completed iter 2400/50000. Training loss: 0.78.\n",
      "  Completed iter 2500/50000. Training loss: 0.56.\n",
      "  Completed iter 2600/50000. Training loss: 0.75.\n",
      "  Completed iter 2700/50000. Training loss: 0.70.\n",
      "  Completed iter 2800/50000. Training loss: 0.80.\n",
      "  Completed iter 2900/50000. Training loss: 0.77.\n",
      "  Completed iter 3000/50000. Training loss: 0.76.\n",
      "  Completed iter 3100/50000. Training loss: 0.68.\n",
      "  Completed iter 3200/50000. Training loss: 0.69.\n",
      "  Completed iter 3300/50000. Training loss: 0.64.\n",
      "  Completed iter 3400/50000. Training loss: 0.50.\n",
      "  Completed iter 3500/50000. Training loss: 0.65.\n",
      "  Completed iter 3600/50000. Training loss: 0.74.\n",
      "  Completed iter 3700/50000. Training loss: 0.80.\n",
      "  Completed iter 3800/50000. Training loss: 0.69.\n",
      "  Completed iter 3900/50000. Training loss: 0.70.\n",
      "  Completed iter 4000/50000. Training loss: 0.67.\n",
      "  Completed iter 4100/50000. Training loss: 0.67.\n",
      "  Completed iter 4200/50000. Training loss: 0.71.\n",
      "  Completed iter 4300/50000. Training loss: 0.61.\n",
      "  Completed iter 4400/50000. Training loss: 0.67.\n",
      "  Completed iter 4500/50000. Training loss: 0.77.\n",
      "  Completed iter 4600/50000. Training loss: 0.71.\n",
      "  Completed iter 4700/50000. Training loss: 0.61.\n",
      "  Completed iter 4800/50000. Training loss: 0.83.\n",
      "  Completed iter 4900/50000. Training loss: 0.79.\n",
      "  Completed iter 5000/50000. Training loss: 0.72.\n",
      "  Completed iter 5100/50000. Training loss: 0.56.\n",
      "  Completed iter 5200/50000. Training loss: 0.78.\n",
      "  Completed iter 5300/50000. Training loss: 0.53.\n",
      "  Completed iter 5400/50000. Training loss: 0.59.\n",
      "  Completed iter 5500/50000. Training loss: 0.62.\n",
      "  Completed iter 5600/50000. Training loss: 0.68.\n",
      "  Completed iter 5700/50000. Training loss: 0.81.\n",
      "  Completed iter 5800/50000. Training loss: 0.78.\n",
      "  Completed iter 5900/50000. Training loss: 0.70.\n",
      "  Completed iter 6000/50000. Training loss: 0.74.\n",
      "  Completed iter 6100/50000. Training loss: 0.91.\n",
      "  Completed iter 6200/50000. Training loss: 0.52.\n",
      "  Completed iter 6300/50000. Training loss: 0.47.\n",
      "  Completed iter 6400/50000. Training loss: 0.69.\n",
      "  Completed iter 6500/50000. Training loss: 0.65.\n",
      "  Completed iter 6600/50000. Training loss: 0.73.\n",
      "  Completed iter 6700/50000. Training loss: 0.50.\n",
      "  Completed iter 6800/50000. Training loss: 0.61.\n",
      "  Completed iter 6900/50000. Training loss: 0.40.\n",
      "  Completed iter 7000/50000. Training loss: 0.61.\n",
      "  Completed iter 7100/50000. Training loss: 0.43.\n",
      "  Completed iter 7200/50000. Training loss: 0.83.\n",
      "  Completed iter 7300/50000. Training loss: 0.48.\n",
      "  Completed iter 7400/50000. Training loss: 0.51.\n",
      "  Completed iter 7500/50000. Training loss: 0.48.\n",
      "  Completed iter 7600/50000. Training loss: 0.61.\n",
      "  Completed iter 7700/50000. Training loss: 0.52.\n",
      "  Completed iter 7800/50000. Training loss: 0.53.\n",
      "  Completed iter 7900/50000. Training loss: 0.59.\n",
      "  Completed iter 8000/50000. Training loss: 0.51.\n",
      "  Completed iter 8100/50000. Training loss: 0.66.\n",
      "  Completed iter 8200/50000. Training loss: 0.51.\n",
      "  Completed iter 8300/50000. Training loss: 0.66.\n",
      "  Completed iter 8400/50000. Training loss: 0.45.\n",
      "  Completed iter 8500/50000. Training loss: 0.41.\n",
      "  Completed iter 8600/50000. Training loss: 0.56.\n",
      "  Completed iter 8700/50000. Training loss: 0.44.\n",
      "  Completed iter 8800/50000. Training loss: 0.73.\n",
      "  Completed iter 8900/50000. Training loss: 0.37.\n",
      "  Completed iter 9000/50000. Training loss: 0.46.\n",
      "  Completed iter 9100/50000. Training loss: 0.91.\n",
      "  Completed iter 9200/50000. Training loss: 0.41.\n",
      "  Completed iter 9300/50000. Training loss: 0.45.\n",
      "  Completed iter 9400/50000. Training loss: 0.65.\n",
      "  Completed iter 9500/50000. Training loss: 0.45.\n",
      "  Completed iter 9600/50000. Training loss: 0.34.\n",
      "  Completed iter 9700/50000. Training loss: 0.64.\n",
      "  Completed iter 9800/50000. Training loss: 0.50.\n",
      "  Completed iter 9900/50000. Training loss: 0.44.\n",
      "  Completed iter 10000/50000. Training loss: 0.41.\n",
      "  Completed iter 10100/50000. Training loss: 0.60.\n",
      "  Completed iter 10200/50000. Training loss: 0.68.\n",
      "  Completed iter 10300/50000. Training loss: 0.34.\n",
      "  Completed iter 10400/50000. Training loss: 0.14.\n",
      "  Completed iter 10500/50000. Training loss: 1.12.\n",
      "  Completed iter 10600/50000. Training loss: 0.31.\n",
      "  Completed iter 10700/50000. Training loss: 0.42.\n",
      "  Completed iter 10800/50000. Training loss: 0.23.\n",
      "  Completed iter 10900/50000. Training loss: 0.52.\n",
      "  Completed iter 11000/50000. Training loss: 0.69.\n",
      "  Completed iter 11100/50000. Training loss: 0.46.\n",
      "  Completed iter 11200/50000. Training loss: 0.31.\n",
      "  Completed iter 11300/50000. Training loss: 0.55.\n",
      "  Completed iter 11400/50000. Training loss: 0.27.\n",
      "  Completed iter 11500/50000. Training loss: 0.47.\n",
      "  Completed iter 11600/50000. Training loss: 0.44.\n",
      "  Completed iter 11700/50000. Training loss: 0.29.\n",
      "  Completed iter 11800/50000. Training loss: 0.67.\n",
      "  Completed iter 11900/50000. Training loss: 0.59.\n",
      "  Completed iter 12000/50000. Training loss: 0.17.\n",
      "  Completed iter 12100/50000. Training loss: 0.23.\n",
      "  Completed iter 12200/50000. Training loss: 0.96.\n",
      "  Completed iter 12300/50000. Training loss: 0.40.\n",
      "  Completed iter 12400/50000. Training loss: 1.03.\n",
      "  Completed iter 12500/50000. Training loss: 0.26.\n",
      "  Completed iter 12600/50000. Training loss: 0.30.\n",
      "  Completed iter 12700/50000. Training loss: 0.45.\n",
      "  Completed iter 12800/50000. Training loss: 0.31.\n",
      "  Completed iter 12900/50000. Training loss: 0.27.\n",
      "  Completed iter 13000/50000. Training loss: 0.20.\n",
      "  Completed iter 13100/50000. Training loss: 0.26.\n",
      "  Completed iter 13200/50000. Training loss: 0.34.\n",
      "  Completed iter 13300/50000. Training loss: 0.51.\n",
      "  Completed iter 13400/50000. Training loss: 0.32.\n",
      "  Completed iter 13500/50000. Training loss: 0.35.\n",
      "  Completed iter 13600/50000. Training loss: 0.23.\n",
      "  Completed iter 13700/50000. Training loss: 0.14.\n",
      "  Completed iter 13800/50000. Training loss: 0.41.\n",
      "  Completed iter 13900/50000. Training loss: 0.14.\n",
      "  Completed iter 14000/50000. Training loss: 0.39.\n",
      "  Completed iter 14100/50000. Training loss: 0.22.\n",
      "  Completed iter 14200/50000. Training loss: 0.23.\n",
      "  Completed iter 14300/50000. Training loss: 0.74.\n",
      "  Completed iter 14400/50000. Training loss: 0.08.\n",
      "  Completed iter 14500/50000. Training loss: 0.52.\n",
      "  Completed iter 14600/50000. Training loss: 0.37.\n",
      "  Completed iter 14700/50000. Training loss: 0.13.\n",
      "  Completed iter 14800/50000. Training loss: 1.03.\n",
      "  Completed iter 14900/50000. Training loss: 0.27.\n",
      "  Completed iter 15000/50000. Training loss: 0.27.\n",
      "  Completed iter 15100/50000. Training loss: 0.67.\n",
      "  Completed iter 15200/50000. Training loss: 0.24.\n",
      "  Completed iter 15300/50000. Training loss: 0.09.\n",
      "  Completed iter 15400/50000. Training loss: 0.62.\n",
      "  Completed iter 15500/50000. Training loss: 0.34.\n",
      "  Completed iter 15600/50000. Training loss: 0.12.\n",
      "  Completed iter 15700/50000. Training loss: 0.12.\n",
      "  Completed iter 15800/50000. Training loss: 0.24.\n",
      "  Completed iter 15900/50000. Training loss: 0.46.\n",
      "  Completed iter 16000/50000. Training loss: 0.19.\n",
      "  Completed iter 16100/50000. Training loss: 0.43.\n",
      "  Completed iter 16200/50000. Training loss: 0.72.\n",
      "  Completed iter 16300/50000. Training loss: 0.28.\n",
      "  Completed iter 16400/50000. Training loss: 0.26.\n",
      "  Completed iter 16500/50000. Training loss: 0.02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 16600/50000. Training loss: 0.28.\n",
      "  Completed iter 16700/50000. Training loss: 0.27.\n",
      "  Completed iter 16800/50000. Training loss: 0.21.\n",
      "  Completed iter 16900/50000. Training loss: 0.33.\n",
      "  Completed iter 17000/50000. Training loss: 0.33.\n",
      "  Completed iter 17100/50000. Training loss: 0.68.\n",
      "  Completed iter 17200/50000. Training loss: 0.23.\n",
      "  Completed iter 17300/50000. Training loss: 0.22.\n",
      "  Completed iter 17400/50000. Training loss: 0.18.\n",
      "  Completed iter 17500/50000. Training loss: 0.33.\n",
      "  Completed iter 17600/50000. Training loss: 0.02.\n",
      "  Completed iter 17700/50000. Training loss: 0.20.\n",
      "  Completed iter 17800/50000. Training loss: 0.32.\n",
      "  Completed iter 17900/50000. Training loss: 0.30.\n",
      "  Completed iter 18000/50000. Training loss: 0.43.\n",
      "  Completed iter 18100/50000. Training loss: 0.72.\n",
      "  Completed iter 18200/50000. Training loss: 0.15.\n",
      "  Completed iter 18300/50000. Training loss: 0.05.\n",
      "  Completed iter 18400/50000. Training loss: 0.24.\n",
      "  Completed iter 18500/50000. Training loss: 0.02.\n",
      "  Completed iter 18600/50000. Training loss: 0.73.\n",
      "  Completed iter 18700/50000. Training loss: 0.37.\n",
      "  Completed iter 18800/50000. Training loss: 0.02.\n",
      "  Completed iter 18900/50000. Training loss: 0.09.\n",
      "  Completed iter 19000/50000. Training loss: 0.04.\n",
      "  Completed iter 19100/50000. Training loss: 0.14.\n",
      "  Completed iter 19200/50000. Training loss: 0.57.\n",
      "  Completed iter 19300/50000. Training loss: 0.15.\n",
      "  Completed iter 19400/50000. Training loss: 0.02.\n",
      "  Completed iter 19500/50000. Training loss: 0.28.\n",
      "  Completed iter 19600/50000. Training loss: 0.32.\n",
      "  Completed iter 19700/50000. Training loss: 0.56.\n",
      "  Completed iter 19800/50000. Training loss: 0.30.\n",
      "  Completed iter 19900/50000. Training loss: 0.06.\n",
      "  Completed iter 20000/50000. Training loss: 0.59.\n",
      "  Completed iter 20100/50000. Training loss: 0.26.\n",
      "  Completed iter 20200/50000. Training loss: 0.10.\n",
      "  Completed iter 20300/50000. Training loss: 0.32.\n",
      "  Completed iter 20400/50000. Training loss: 0.19.\n",
      "  Completed iter 20500/50000. Training loss: 0.39.\n",
      "  Completed iter 20600/50000. Training loss: 0.21.\n",
      "  Completed iter 20700/50000. Training loss: 0.02.\n",
      "  Completed iter 20800/50000. Training loss: 0.28.\n",
      "  Completed iter 20900/50000. Training loss: 0.07.\n",
      "  Completed iter 21000/50000. Training loss: 0.64.\n",
      "  Completed iter 21100/50000. Training loss: 0.02.\n",
      "  Completed iter 21200/50000. Training loss: 0.17.\n",
      "  Completed iter 21300/50000. Training loss: 0.67.\n",
      "  Completed iter 21400/50000. Training loss: 0.32.\n",
      "  Completed iter 21500/50000. Training loss: 0.56.\n",
      "  Completed iter 21600/50000. Training loss: 0.95.\n",
      "  Completed iter 21700/50000. Training loss: 0.20.\n",
      "  Completed iter 21800/50000. Training loss: 0.26.\n",
      "  Completed iter 21900/50000. Training loss: 0.02.\n",
      "  Completed iter 22000/50000. Training loss: 0.90.\n",
      "  Completed iter 22100/50000. Training loss: 0.37.\n",
      "  Completed iter 22200/50000. Training loss: 0.00.\n",
      "  Completed iter 22300/50000. Training loss: 0.44.\n",
      "  Completed iter 22400/50000. Training loss: 0.02.\n",
      "  Completed iter 22500/50000. Training loss: 0.18.\n",
      "  Completed iter 22600/50000. Training loss: 0.03.\n",
      "  Completed iter 22700/50000. Training loss: 0.01.\n",
      "  Completed iter 22800/50000. Training loss: 0.45.\n",
      "  Completed iter 22900/50000. Training loss: 0.03.\n",
      "  Completed iter 23000/50000. Training loss: 0.25.\n",
      "  Completed iter 23100/50000. Training loss: 0.13.\n",
      "  Completed iter 23200/50000. Training loss: 0.00.\n",
      "  Completed iter 23300/50000. Training loss: 0.88.\n",
      "  Completed iter 23400/50000. Training loss: 0.03.\n",
      "  Completed iter 23500/50000. Training loss: 0.04.\n",
      "  Completed iter 23600/50000. Training loss: 0.06.\n",
      "  Completed iter 23700/50000. Training loss: 0.35.\n",
      "  Completed iter 23800/50000. Training loss: 0.14.\n",
      "  Completed iter 23900/50000. Training loss: 0.39.\n",
      "  Completed iter 24000/50000. Training loss: 0.59.\n",
      "  Completed iter 24100/50000. Training loss: 0.28.\n",
      "  Completed iter 24200/50000. Training loss: 0.35.\n",
      "  Completed iter 24300/50000. Training loss: 1.34.\n",
      "  Completed iter 24400/50000. Training loss: 0.03.\n",
      "  Completed iter 24500/50000. Training loss: 0.32.\n",
      "  Completed iter 24600/50000. Training loss: 0.20.\n",
      "  Completed iter 24700/50000. Training loss: 0.00.\n",
      "  Completed iter 24800/50000. Training loss: 0.15.\n",
      "  Completed iter 24900/50000. Training loss: 0.30.\n",
      "  Completed iter 25000/50000. Training loss: 0.23.\n",
      "  Completed iter 25100/50000. Training loss: 0.01.\n",
      "  Completed iter 25200/50000. Training loss: 0.47.\n",
      "  Completed iter 25300/50000. Training loss: 0.31.\n",
      "  Completed iter 25400/50000. Training loss: 0.01.\n",
      "  Completed iter 25500/50000. Training loss: 0.08.\n",
      "  Completed iter 25600/50000. Training loss: 0.09.\n",
      "  Completed iter 25700/50000. Training loss: 0.01.\n",
      "  Completed iter 25800/50000. Training loss: 0.29.\n",
      "  Completed iter 25900/50000. Training loss: 0.49.\n",
      "  Completed iter 26000/50000. Training loss: 0.00.\n",
      "  Completed iter 26100/50000. Training loss: 0.22.\n",
      "  Completed iter 26200/50000. Training loss: 0.04.\n",
      "  Completed iter 26300/50000. Training loss: 0.35.\n",
      "  Completed iter 26400/50000. Training loss: 0.27.\n",
      "  Completed iter 26500/50000. Training loss: 0.83.\n",
      "  Completed iter 26600/50000. Training loss: 1.22.\n",
      "  Completed iter 26700/50000. Training loss: 0.08.\n",
      "  Completed iter 26800/50000. Training loss: 0.44.\n",
      "  Completed iter 26900/50000. Training loss: 0.00.\n",
      "  Completed iter 27000/50000. Training loss: 0.04.\n",
      "  Completed iter 27100/50000. Training loss: 0.00.\n",
      "  Completed iter 27200/50000. Training loss: 0.04.\n",
      "  Completed iter 27300/50000. Training loss: 0.56.\n",
      "  Completed iter 27400/50000. Training loss: 0.22.\n",
      "  Completed iter 27500/50000. Training loss: 0.19.\n",
      "  Completed iter 27600/50000. Training loss: 0.14.\n",
      "  Completed iter 27700/50000. Training loss: 0.03.\n",
      "  Completed iter 27800/50000. Training loss: 0.15.\n",
      "  Completed iter 27900/50000. Training loss: 0.13.\n",
      "  Completed iter 28000/50000. Training loss: 0.35.\n",
      "  Completed iter 28100/50000. Training loss: 0.00.\n",
      "  Completed iter 28200/50000. Training loss: 0.47.\n",
      "  Completed iter 28300/50000. Training loss: 0.02.\n",
      "  Completed iter 28400/50000. Training loss: 0.02.\n",
      "  Completed iter 28500/50000. Training loss: 0.01.\n",
      "  Completed iter 28600/50000. Training loss: 0.19.\n",
      "  Completed iter 28700/50000. Training loss: 0.02.\n",
      "  Completed iter 28800/50000. Training loss: 0.06.\n",
      "  Completed iter 28900/50000. Training loss: 0.00.\n",
      "  Completed iter 29000/50000. Training loss: 0.28.\n",
      "  Completed iter 29100/50000. Training loss: 0.06.\n",
      "  Completed iter 29200/50000. Training loss: 0.08.\n",
      "  Completed iter 29300/50000. Training loss: 0.08.\n",
      "  Completed iter 29400/50000. Training loss: 0.05.\n",
      "  Completed iter 29500/50000. Training loss: 0.02.\n",
      "  Completed iter 29600/50000. Training loss: 0.71.\n",
      "  Completed iter 29700/50000. Training loss: 0.05.\n",
      "  Completed iter 29800/50000. Training loss: 0.00.\n",
      "  Completed iter 29900/50000. Training loss: 0.17.\n",
      "  Completed iter 30000/50000. Training loss: 0.39.\n",
      "  Completed iter 30100/50000. Training loss: 0.02.\n",
      "  Completed iter 30200/50000. Training loss: 0.03.\n",
      "  Completed iter 30300/50000. Training loss: 0.26.\n",
      "  Completed iter 30400/50000. Training loss: 0.00.\n",
      "  Completed iter 30500/50000. Training loss: 1.32.\n",
      "  Completed iter 30600/50000. Training loss: 0.01.\n",
      "  Completed iter 30700/50000. Training loss: 0.41.\n",
      "  Completed iter 30800/50000. Training loss: 0.00.\n",
      "  Completed iter 30900/50000. Training loss: 0.18.\n",
      "  Completed iter 31000/50000. Training loss: 0.17.\n",
      "  Completed iter 31100/50000. Training loss: 0.00.\n",
      "  Completed iter 31200/50000. Training loss: 0.23.\n",
      "  Completed iter 31300/50000. Training loss: 0.06.\n",
      "  Completed iter 31400/50000. Training loss: 0.00.\n",
      "  Completed iter 31500/50000. Training loss: 0.02.\n",
      "  Completed iter 31600/50000. Training loss: 0.01.\n",
      "  Completed iter 31700/50000. Training loss: 0.06.\n",
      "  Completed iter 31800/50000. Training loss: 0.09.\n",
      "  Completed iter 31900/50000. Training loss: 0.00.\n",
      "  Completed iter 32000/50000. Training loss: 0.80.\n",
      "  Completed iter 32100/50000. Training loss: 0.06.\n",
      "  Completed iter 32200/50000. Training loss: 0.03.\n",
      "  Completed iter 32300/50000. Training loss: 0.13.\n",
      "  Completed iter 32400/50000. Training loss: 0.00.\n",
      "  Completed iter 32500/50000. Training loss: 0.11.\n",
      "  Completed iter 32600/50000. Training loss: 0.00.\n",
      "  Completed iter 32700/50000. Training loss: 0.06.\n",
      "  Completed iter 32800/50000. Training loss: 0.00.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 32900/50000. Training loss: 0.02.\n",
      "  Completed iter 33000/50000. Training loss: 0.12.\n",
      "  Completed iter 33100/50000. Training loss: 0.00.\n",
      "  Completed iter 33200/50000. Training loss: 0.15.\n",
      "  Completed iter 33300/50000. Training loss: 0.01.\n",
      "  Completed iter 33400/50000. Training loss: 0.36.\n",
      "  Completed iter 33500/50000. Training loss: 0.00.\n",
      "  Completed iter 33600/50000. Training loss: 0.00.\n",
      "  Completed iter 33700/50000. Training loss: 0.75.\n",
      "  Completed iter 33800/50000. Training loss: 0.00.\n",
      "  Completed iter 33900/50000. Training loss: 0.02.\n",
      "  Completed iter 34000/50000. Training loss: 0.00.\n",
      "  Completed iter 34100/50000. Training loss: 0.11.\n",
      "  Completed iter 34200/50000. Training loss: 0.01.\n",
      "  Completed iter 34300/50000. Training loss: 0.24.\n",
      "  Completed iter 34400/50000. Training loss: 0.03.\n",
      "  Completed iter 34500/50000. Training loss: 0.22.\n",
      "  Completed iter 34600/50000. Training loss: 0.09.\n",
      "  Completed iter 34700/50000. Training loss: 0.04.\n",
      "  Completed iter 34800/50000. Training loss: 0.10.\n",
      "  Completed iter 34900/50000. Training loss: 0.01.\n",
      "  Completed iter 35000/50000. Training loss: 0.02.\n",
      "  Completed iter 35100/50000. Training loss: 0.00.\n",
      "  Completed iter 35200/50000. Training loss: 0.00.\n",
      "  Completed iter 35300/50000. Training loss: 0.10.\n",
      "  Completed iter 35400/50000. Training loss: 0.00.\n",
      "  Completed iter 35500/50000. Training loss: 0.14.\n",
      "  Completed iter 35600/50000. Training loss: 0.00.\n",
      "  Completed iter 35700/50000. Training loss: 0.00.\n",
      "  Completed iter 35800/50000. Training loss: 0.74.\n",
      "  Completed iter 35900/50000. Training loss: 0.07.\n",
      "  Completed iter 36000/50000. Training loss: 0.17.\n",
      "  Completed iter 36100/50000. Training loss: 0.02.\n",
      "  Completed iter 36200/50000. Training loss: 0.02.\n",
      "  Completed iter 36300/50000. Training loss: 0.05.\n",
      "  Completed iter 36400/50000. Training loss: 0.00.\n",
      "  Completed iter 36500/50000. Training loss: 0.01.\n",
      "  Completed iter 36600/50000. Training loss: 0.26.\n",
      "  Completed iter 36700/50000. Training loss: 0.30.\n",
      "  Completed iter 36800/50000. Training loss: 0.00.\n",
      "  Completed iter 36900/50000. Training loss: 0.01.\n",
      "  Completed iter 37000/50000. Training loss: 0.16.\n",
      "  Completed iter 37100/50000. Training loss: 0.01.\n",
      "  Completed iter 37200/50000. Training loss: 0.05.\n",
      "  Completed iter 37300/50000. Training loss: 0.02.\n",
      "  Completed iter 37400/50000. Training loss: 1.20.\n",
      "  Completed iter 37500/50000. Training loss: 0.40.\n",
      "  Completed iter 37600/50000. Training loss: 0.07.\n",
      "  Completed iter 37700/50000. Training loss: 0.00.\n",
      "  Completed iter 37800/50000. Training loss: 0.00.\n",
      "  Completed iter 37900/50000. Training loss: 0.56.\n",
      "  Completed iter 38000/50000. Training loss: 0.00.\n",
      "  Completed iter 38100/50000. Training loss: 0.44.\n",
      "  Completed iter 38200/50000. Training loss: 0.00.\n",
      "  Completed iter 38300/50000. Training loss: 0.00.\n",
      "  Completed iter 38400/50000. Training loss: 0.09.\n",
      "  Completed iter 38500/50000. Training loss: 0.29.\n",
      "  Completed iter 38600/50000. Training loss: 0.14.\n",
      "  Completed iter 38700/50000. Training loss: 0.01.\n",
      "  Completed iter 38800/50000. Training loss: 0.01.\n",
      "  Completed iter 38900/50000. Training loss: 0.30.\n",
      "  Completed iter 39000/50000. Training loss: 0.03.\n",
      "  Completed iter 39100/50000. Training loss: 0.01.\n",
      "  Completed iter 39200/50000. Training loss: 0.54.\n",
      "  Completed iter 39300/50000. Training loss: 0.03.\n",
      "  Completed iter 39400/50000. Training loss: 0.27.\n",
      "  Completed iter 39500/50000. Training loss: 0.01.\n",
      "  Completed iter 39600/50000. Training loss: 0.00.\n",
      "  Completed iter 39700/50000. Training loss: 0.23.\n",
      "  Completed iter 39800/50000. Training loss: 0.06.\n",
      "  Completed iter 39900/50000. Training loss: 0.00.\n",
      "  Completed iter 40000/50000. Training loss: 0.05.\n",
      "  Completed iter 40100/50000. Training loss: 0.73.\n",
      "  Completed iter 40200/50000. Training loss: 0.00.\n",
      "  Completed iter 40300/50000. Training loss: 0.07.\n",
      "  Completed iter 40400/50000. Training loss: 0.02.\n",
      "  Completed iter 40500/50000. Training loss: 0.00.\n",
      "  Completed iter 40600/50000. Training loss: 0.00.\n",
      "  Completed iter 40700/50000. Training loss: 0.21.\n",
      "  Completed iter 40800/50000. Training loss: 0.00.\n",
      "  Completed iter 40900/50000. Training loss: 0.47.\n",
      "  Completed iter 41000/50000. Training loss: 0.05.\n",
      "  Completed iter 41100/50000. Training loss: 0.14.\n",
      "  Completed iter 41200/50000. Training loss: 0.00.\n",
      "  Completed iter 41300/50000. Training loss: 0.19.\n",
      "  Completed iter 41400/50000. Training loss: 0.02.\n",
      "  Completed iter 41500/50000. Training loss: 0.09.\n",
      "  Completed iter 41600/50000. Training loss: 0.13.\n",
      "  Completed iter 41700/50000. Training loss: 0.03.\n",
      "  Completed iter 41800/50000. Training loss: 0.01.\n",
      "  Completed iter 41900/50000. Training loss: 0.28.\n",
      "  Completed iter 42000/50000. Training loss: 0.00.\n",
      "  Completed iter 42100/50000. Training loss: 0.40.\n",
      "  Completed iter 42200/50000. Training loss: 0.00.\n",
      "  Completed iter 42300/50000. Training loss: 0.07.\n",
      "  Completed iter 42400/50000. Training loss: 0.37.\n",
      "  Completed iter 42500/50000. Training loss: 1.48.\n",
      "  Completed iter 42600/50000. Training loss: 0.51.\n",
      "  Completed iter 42700/50000. Training loss: 0.00.\n",
      "  Completed iter 42800/50000. Training loss: 0.17.\n",
      "  Completed iter 42900/50000. Training loss: 0.16.\n",
      "  Completed iter 43000/50000. Training loss: 0.03.\n",
      "  Completed iter 43100/50000. Training loss: 0.04.\n",
      "  Completed iter 43200/50000. Training loss: 0.05.\n",
      "  Completed iter 43300/50000. Training loss: 0.37.\n",
      "  Completed iter 43400/50000. Training loss: 0.68.\n",
      "  Completed iter 43500/50000. Training loss: 0.00.\n",
      "  Completed iter 43600/50000. Training loss: 0.00.\n",
      "  Completed iter 43700/50000. Training loss: 0.01.\n",
      "  Completed iter 43800/50000. Training loss: 0.06.\n",
      "  Completed iter 43900/50000. Training loss: 0.39.\n",
      "  Completed iter 44000/50000. Training loss: 0.01.\n",
      "  Completed iter 44100/50000. Training loss: 0.05.\n",
      "  Completed iter 44200/50000. Training loss: 0.00.\n",
      "  Completed iter 44300/50000. Training loss: 0.00.\n",
      "  Completed iter 44400/50000. Training loss: 0.05.\n",
      "  Completed iter 44500/50000. Training loss: 0.00.\n",
      "  Completed iter 44600/50000. Training loss: 0.01.\n",
      "  Completed iter 44700/50000. Training loss: 0.04.\n",
      "  Completed iter 44800/50000. Training loss: 0.00.\n",
      "  Completed iter 44900/50000. Training loss: 0.00.\n",
      "  Completed iter 45000/50000. Training loss: 0.45.\n",
      "  Completed iter 45100/50000. Training loss: 0.32.\n",
      "  Completed iter 45200/50000. Training loss: 0.02.\n",
      "  Completed iter 45300/50000. Training loss: 0.24.\n",
      "  Completed iter 45400/50000. Training loss: 0.12.\n",
      "  Completed iter 45500/50000. Training loss: 0.01.\n",
      "  Completed iter 45600/50000. Training loss: 0.15.\n",
      "  Completed iter 45700/50000. Training loss: 0.21.\n",
      "  Completed iter 45800/50000. Training loss: 0.51.\n",
      "  Completed iter 45900/50000. Training loss: 0.09.\n",
      "  Completed iter 46000/50000. Training loss: 0.00.\n",
      "  Completed iter 46100/50000. Training loss: 0.02.\n",
      "  Completed iter 46200/50000. Training loss: 0.51.\n",
      "  Completed iter 46300/50000. Training loss: 0.00.\n",
      "  Completed iter 46400/50000. Training loss: 0.00.\n",
      "  Completed iter 46500/50000. Training loss: 0.30.\n",
      "  Completed iter 46600/50000. Training loss: 0.07.\n",
      "  Completed iter 46700/50000. Training loss: 0.05.\n",
      "  Completed iter 46800/50000. Training loss: 0.12.\n",
      "  Completed iter 46900/50000. Training loss: 0.11.\n",
      "  Completed iter 47000/50000. Training loss: 0.00.\n",
      "  Completed iter 47100/50000. Training loss: 0.00.\n",
      "  Completed iter 47200/50000. Training loss: 0.12.\n",
      "  Completed iter 47300/50000. Training loss: 0.00.\n",
      "  Completed iter 47400/50000. Training loss: 1.28.\n",
      "  Completed iter 47500/50000. Training loss: 0.01.\n",
      "  Completed iter 47600/50000. Training loss: 0.01.\n",
      "  Completed iter 47700/50000. Training loss: 0.22.\n",
      "  Completed iter 47800/50000. Training loss: 0.51.\n",
      "  Completed iter 47900/50000. Training loss: 0.05.\n",
      "  Completed iter 48000/50000. Training loss: 0.00.\n",
      "  Completed iter 48100/50000. Training loss: 0.03.\n",
      "  Completed iter 48200/50000. Training loss: 0.00.\n",
      "  Completed iter 48300/50000. Training loss: 0.30.\n",
      "  Completed iter 48400/50000. Training loss: 1.03.\n",
      "  Completed iter 48500/50000. Training loss: 0.00.\n",
      "  Completed iter 48600/50000. Training loss: 0.01.\n",
      "  Completed iter 48700/50000. Training loss: 0.00.\n",
      "  Completed iter 48800/50000. Training loss: 0.00.\n",
      "  Completed iter 48900/50000. Training loss: 0.30.\n",
      "  Completed iter 49000/50000. Training loss: 0.50.\n",
      "  Completed iter 49100/50000. Training loss: 0.00.\n",
      "  Completed iter 49200/50000. Training loss: 0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 49300/50000. Training loss: 0.35.\n",
      "  Completed iter 49400/50000. Training loss: 0.03.\n",
      "  Completed iter 49500/50000. Training loss: 0.00.\n",
      "  Completed iter 49600/50000. Training loss: 1.03.\n",
      "  Completed iter 49700/50000. Training loss: 0.06.\n",
      "  Completed iter 49800/50000. Training loss: 0.26.\n",
      "  Completed iter 49900/50000. Training loss: 0.19.\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEBCAYAAACZhwWsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3wc1dXw8d+qS1bDRjYYY4zBXHoxzVSbhJbwUD7hSegEEiAkhP4+YCCE5H0oJi+dBAjY9GI6wVTTjI0L7t2+bshVVrEtq2u15f1jduWVtGV2d2br+X4+/li7M7tzRuXM3Tv3nuvwer0IIYTIbDnJDkAIIYT9JNkLIUQWkGQvhBBZQJK9EEJkAUn2QgiRBSTZCyFEFshLdgCh1Nc3xzwmtLS0kJaWTivDSXlyzpkv284X5JyjVVVV5gi1LSNb9nl5uckOIeHknDNftp0vyDlbKSOTvRBCiJ4k2QshRBaQZC+EEFlAkr0QQmQBSfZCCJEFJNkLIUQWkGQvhBBZQJK9EELY6PSX5nLpu4uTHUbqzqAVQohMsLi2BWqTHYW07IUQIitIshdCiCwgyV4IIbKAJHshhMgCkuyFECILSLIXQogsYPnQS6VUPvAiMAwoBO7XWn8csP1c4K+AC3hRa/2C1TEIIYToyY6W/eXANq31KcAvgH/6N/guBI8DZwKjgeuUUnvYEIMQQogAdiT7d4F7Ax67Ar4+CFijtd6htXYCPwCn2BCDEEKIAJZ342itWwCUUmXAe8BfAjaXAzsDHjcDFcHep7S0MObluXJzc6isLInptelKzjnzZdv5Qmads9nzsOucbSmXoJTaG/gQeEZr/WbApiagLOBxGdAY7D3iWWS4srKExsa2mF+fjuScM18iz/eOL1fx8oIt1I0dk5DjhZJJP2Oz5xHPOVdVlYXcZscN2kHAZODPWutvem1eAYxQSvUHWoBTgUesjkEIEZ+XF2xJdgjCYna07O8GdgPuVUr5++5fAPpprZ9XSt0GfIlxv+BFrfVmG2IQQggRwI4++5uBm8NsnwRMsvq4QgghQpNJVUIIkQUk2QuRgjpc7mSHIDKMJHshUsy8LU0MfWQaX6/dluxQUprL46HF6Yq8o0W2t3cl9HhWk2QvRIqZvcmYivJ99Y4kR5Larnp/GcMf+yFhxzvwyemc9MLshB3PapLshRBpabKJTz73fLWat5dsteyYNc1Oy94r0STZi6zV3OnircU1yQ5D2OiFeZu58dOVyQ4jJUiyF1nrf75cxc2faeZtaUp2KCJFtXe5+Xbd9mSHYQlJ9iJr1bYYH8nbu2TkiwjuL1+v4eJ3FrO0tqX7uVcXpufsYkn2QggRwprtRo2aps5do3Ae+v6nZIUTF0n2QgiRBSTZC5HF3ltWmzF90vFava2VgeOmMGND0EK8pk1aWZeSN/4l2QuRYrzexB3rT5NWcPE7ixN3wBT2w3ojyX+4oi6u9/n9R8u5+TNtev9OlwdPAn7okuyFSFGOZAcgbOd0e9j7kan87du1th9Lkr0QQiRJR5cHgDcS0O0jyV5kLW8i+0uESDJJ9iLrSXeJNVweD0MfmZqSNyeFJHshhEVanG46XB5u/kxz4JM/4PbIJ6dUIsleiBTjJf2T5PZ2V8bOTE7Xn48keyFSlEP6lxIqPVO4eZLshRAiQKZeYyXZC5FirGphdrjctDozsytFRE+SvRApyhFnG/O4535k38emWRRN+ntt4RYem14ddNvS2hbGTl6d2IASTJK9yFrp3Ec7cXEN7y4NvwLT1pbUWFXJ7fHy7bptSZ/XcPsXqxg3rTrotinVmV8fSJK9yHqONLwTetNnmhs+SY8VmP41eyMXv7OEyWtkAfVkkmQvRBobOG4Kf/5khe3HqW3pZOC4KcwMUxEy1CVz/Y524z1aU+OTRraSZC9Emntnaa3tx/hx004Axs/bbPo16dxNlokk2QshRAR23W+47L0ltrxvMJLshRAiQOAtnGBdU1bmff8npkSQZC9EBtm0s4MDnviBdb61U4Xwk2QvslaqVjiOJ64PltfS2OFKSH30WLR0uhg4bkrEYaPpqsXpirxTkkiyF1kvVQdepuKI0HiLgG1q6gTgqVkbrAgHgB3tXXG9vq7VycadHZbEcshTM0Ju+8k3KilZJNkLYZPGji7qMmS4YbDrzr1fr2HoI1MD9knO1em2z82v9xrMoU/P4KX5WyyJpd3lCbmtprnTkmPESpK9EDY5+KkZHPp06JZeKFb0Lj09a6MF7wL1YS5W/567iY4wyc3P7t6ypk4XszaGHv8vDBGTvVLqEKXUCUqp45VS3yilfp6IwIRId644F+9IhV6cQ56eQXVjbN0Pve892HU+09Y3ct4bC/lU19t0hJ52dLhY1dAa8+tXNbTi8vS8SCbi/pGZlv1zQCfwF+Ae4D5bIxIihXi9Xj5YXkuXO3ILNlOd/cq8ZIdgyqYma/rdzbj2P8tjel11Yzsnj5/D/05ZZ3FEkZlJ9l3AMqBAaz0LyLM3JCESK1yj6hPdwPUfr+CJmdbdUEy2f8/ZyIFP/mB6/+3tqTvCxA52fqLyd4vN3tRk41GCM5PsvcCbwGdKqd8AsX9+ESKFmBntst030uP//VAd85qq367bxvrGdqZV7+CsV+b1+JTQ5fbw2/eXsrS2JeTrVzW08tJ8c2UKzER47zdrY07gqTpcVURmJtlfBEwAngLqfI+FSHvRJq63l8Q2Nvzid5ZwwvOzufVzzYKaZrYEjMpYWd/K56sbuOnT0BUsf/bSXO5Meq1148r46aoGfj1xUZJjiV6yR8KkAjPJPh+oBkYAVwBD7QxIiEQz+7G93RX7qk9R3aztdRVyus291uP18sD3P0UTVg8NbeaGiX5fvSPo83bMC1i/o503F8U/QezMNLnvYCczyf5VYBDwIPAV8LiZN/aN3pkS5PnblFLLlFJTfP9UNAELYbVJup6L31mc7DD6iDZ5rt4We4mEWRsbOfipGUxaWRfze9jhjOdnccvnmrau+JZXrE2RhVySyUyyzwOmApVa64lAbqQXKKXuAMYDRUE2jwSu1FqP8f2Lb0aEEHEaP28z367L/JWKwlniu2cwc2PiCnMBTFpZjzPMSKfaFvPdL1ZN6srU2xJmkn0B8BgwVSl1GuZG46wFfhVi29HAXUqpH5RSd5kLUwiRbiKVVvi+eju//2gZD3wfeRhiq9ONJ6PuDvc8lxanm4HjpjB5TQPtcX6KCcVM4r4KOAOjpX4BcHmkF2it31dKDQuxeSLwL6AJ+FAp9V9a609671RaWkheXsQPEUHl5uZQWVkS02vTVaznvGRrEy63l6P2qrAhKnvF+3POy+vZ1gn2XiUlBd1fFxcXxHW8nByj5VlWVtz9PqWtxmifwHMpKjaOWViY3+N44c63srKEss7gSSLca/yKu4+ZF3T/fv0KejwO3Mf/dU5Hzxo1FRUlVBbnk59v/B2XlBRQVm582M/JycGZYzxf1+6K+H095OkZ/J/Rw3nwFweG3Ke4OJ+/TlnHtaOGcuigMr5e3RB0v8BjvTi770zjooDvuz8HlZb27KTIyXFEjLn39tLSQgp9v3O5ublBX3/5e0s5d3k97195dNj3joWZZL8O4x7W48AqYFOsB1NKOYAntNY7fY8/BY4C+iT7lig+vvVWWVlCY2N2lXiN9ZyPfsIYb103dozFEVnL6/Uyd0sTxwwu714z9qqPlvGbgwfyywOqYnpPV6+p/sG+f20BNy3b251x/V55fDdpm5rbafS1Y1qajYlALre7+7072o1jdnZ29Tie2+0JefzGxjaam4NPKgr3Gr/27mO6In4fer/W/3VzZ8/hnDt3tkFnPp2+SpDt7U6afROfPB4Pba3G33hXl9vU9/WtBZu544TQ40PW1rXw3OyNfLyslrtO3ZcbQ4xw8h9rW5uT6z/ou3hI4Pfd5bsp39LS83vr8Xgjxtx7e+32tu7FStbvaGNrQ3PQ1323piHm37OqqrKQ28x04zwPDMe4OTsMo4Ufq3JgqVKq1Jf4fwbIbXIR0Ucr6jjntQU9luD7bGU9V32wLIlRWSBBNRFaOl3s7IivOmS8HDh6dO0srg2e7ELZ3NRJq9NcF4eZKpYmBzlF5PF6mbi4JuIs67UBawzUtjj5/YeJ/d0107IfobU+1ff1R0qpqCs7KaUuBUq11s8rpe4GvsMowfCN1vqzaN9PZJ91vvKwVpaJTVYP8KSV9fzxuCHk5VhbhzDcdWP/J37A47X3E1w01y3d0IZuiNx6be/qmUBv/0Lz3HkHRxmZvd5bVstNn2lqIoz4eW9Zz7WCv1qb2EEBZpJ9kVKqRGvdppQqxsRoHACtdTUwyvf1mwHPvwa8FkOsQnQ75tlZ3V/P2tjIqL0rE3BUa5rh/ztlHW6Pl1tO3Ceq1938n2X89ZRh5OZEH0ecNdn6sLIefTTWbU9OTfhw3z5/Pf1tEeYphBt1lAhmmhZPAouUUh8CC4En7A1JiNA6XB5emr+ZDQEf02//YlXE1w0cN4VxU2OfcGS1ml73pOpand3JwJ9Yeg8lfHbmehbUhK6pYnbyVThmB7zcn4RCXpEEzkuw6trmCDHZIXAB8k7f9/27n4JPNksVEZO91voN4HjgAeBE4D92ByXS22PTqxk4bkrcE2GCeWb2xphLBzw2Y33Ur0nUalH1rV1c/7FRSdE/CzbYsUMlH4AzXp4b8/GTWU45GSMqPV4vry20ZsGSzb6bzvFMaksEUxUstdbbge0ASqnZwHF2BiXS24u+VX+aO12U5Mc2fDYbfaIbuhNHLMw07AeOm9L99fi55gfWbY2htkyqjoofOG4Klx+xJ69bUIYhncRyhygV1lQQIilGT5jDvo9N637c6psM87SJPuygLfVef06nTpjT/fWzszeaHn0SiwkmK2kC3P31GtvisIr/O+nF26ObJZhwiT7ambjJXlvWrFiSfapesEUK2NDYnmEzHXtaUd/aIwE3+oYzTphnPnGG0xwwMcrp9pqaXZrqIv06RLOI+cKtoYdr+i+mNc1OHpkefZddrKZY3Fdv119PyG4cpdRDQY7rAPayKRaR5lY1tHLy+DmRd7RYpFZcKD9uir8OjP/QzU57Fvho6jVRKdZzjaTNxFqy8bKqS2B7exf9i/Mtere+ujwevF5v2Psj6Shcy34loHv9WwncnYC4RBqyalm4jTs7GPboVFZvS911cup8Kw7N2WxcMJp7lSrYZGJST7KtDRjG6B9dE00ru48E5cb1IdbEtaoQ2qsLa7pvkk/fYCxkHqqsczoJ2bLXWr+SyECEqG5spzgvh49W1NHW5eHNxVu577T9khLLHg9P4bpjhrD/gOD1T67+YCmfXjGyz6Qfv2s+sm92pJ3dZLG88/wtTYwcXG55LMn0+qIt/GXM8O7Hy+tCrySWLqydwieyUpfbw7QYWj5eb88bacc99yOH/XOmlaHFzOOF5+ZsYlvbrhIDgZ/qA58PpsPGbpGX5lszZDDUe0e7uPrZr84Pu90/6WhViKGJoa5d0cYR16eSLCDJPoO0Ot1JmaX30NSfuHDiIuZs7jnhJ1ID9OFp1Qx6+Hs64lgBym4PBUzEireTINjrI3ULN3X0vRewJUTBM6t8vLLe0vf7cs02wJgjEY3ev08iPhGTvVJqrlLqFqVU/0QEJGK372PTOCsJy6/5J5Pohuj62P2LaLeF6AoxK/CaUt/q5KhnZkYdS6K9NH8Loyf0vJkdLO9/4UuUfolou1rVTbSyPvqfwXmvL+DAJ38Iu89Zr8zn81V9yxdb1WdvlSW1zd0L1qcCMy370wEnMEkpNVEpdbrNMYk4LKtLXpL7RAevH55IX65pYHNTJ89F2Yo044f1jZa+34oYkmE6Oe+NhVHtX9vSyaxNO9neHnlkU7DaPHYOnonl8vfzl+Zx4JPTux+vNFH4zU5myiU0aq2fAa4B3MCbSqkflVLn2B6dEHFqcbq6+4zjNUnv6t6wKrHEMmP26VnWX8gSJdiHhi3NnYyfuymqCWTVQSYypVa7PvWY6cb5k1JqFkZBtP9gjLM/DXjI5thEloq2FbV2eztXvtd3EQqAE56fjQpoXYUzcNwUvvvJvrKz1Y19E3v1jl3PpfOw7jXb2kJ2o0T6eS6oaebur9dEtSj4tiAX8CdmWleJM1KXUDreCjZTG2cv4GJfyWK/LqXUH+wJSYSydnsbd3y5ilcvPIx+BZlTcybURKFocl/vvm2/aBIIwIfL68g1kXXTOC/b4sQXZrP4hhPieo/AewXhqntmOrtG1prps38KuFUp9blS6hGl1G4AWuvUGCOXRf7+7VqmrW9kagZM8IAwLVkLftvjeYf/nrgo7uOblc6t+d7aLBxVddYr89kax9KkVsuEH5OZZD8RY+bsWIz1aGXhEdFDvLl5W1sXczf3LV0QSyJMhREZ909Zx3Kbbr7G8r2OdqGRVOmiaLGxCFy07Jw3kShmSxw/6/tykVLqNzbGIzKI2aTxy9fm09Rp7R+23bXYHA4HK+pbWBRkHdVkreIUSiouNGJGKtXTm2bxSKxkMJPsVyqlLsNYN/ZoYJtS6gAArXXkJYKEZez83Z+/pYmywlxGDOhn41GCszLRR2rXL61t4dBBpZYca/SE2BcLCSb5n0kMf/t2bbJDAKAzia3pTOpe8zPTjXMgxrDL14HbgP7Av4HnbIxLhOFwwMsLNjNpZV1Mr29oczJxydYez5396nxOeiH6ipVtXW7qI6y9mUrOfWNBskPoIbD1mipVFhsilIKIxrtLe/6ehVsaMoUa8qbVt6bP737Elr3W+jSl1ABgP2Cd1ikwc0Zwx5fG0nx1YwdG/dprPlzGjI07OWHvirjjOOe1+aYncu3s6OKsV+Yz/oJDOHRQacxD9cxIRuJY1dDKXV/FtmRiJgj287zhk5U9HocaNQWp1W1j1h1fpk/nhplx9r8GZmCUNp6llLrc9qhEUGb/GAILSM3c0MiaXgWoan2tka4I69i1dLp4bHo1bk/P/R78fh23fmb8EUczY3dqdSPrdrTz6PRq06/5dt32PscPZeLiGmYHudFrh2CXqZPHz7G9bzcN82HGanG6+DRI2YZUZaYb5zbgaK31BcBRwM32hiQiCZZoOgIW9z7rlV1VCM9/cyEnvjC7xyxSf5Kvi/AR9IHvf2LctGo+WtGzu+iJmRt4Y/HWEK8Krr7VyV+/jW5pu6/WbOPidxbzL5OlD276TPOmL66JS7ay/+PT+uzT6fLwxqKauBcBsarHJUV6bkQMhj8WvoZPqjGT7D1a6xYArXUzkPqrMmSR33+4jAU1Tdw6aXn3c0uD1N5WT05n3Q6jhb/Bt7DGnZPDfwRt9V1ArKikeddXq9ncFN246a2+CVGhFquIJNiNX5fHy62f67grO4aqYx+PbM/7H66I7R6UMMfMaJy1SqlHganAqUBq3KrPQsHqdU/S9SysaWKjiURavaOD4bvtWoxDmyzMdPNnmqnrd/DsuQebD5aeM2N7dxm9MHdT0CnvxuuiOkxM4l1GcEMarESVaPF+Sgm3CLiIn5mW/TUYk6nO8P1/ra0RCUu0dcU+nDFYidv3l0Xf6pq2vjHomHMvcM/Xkbt0HCG+ttOcBPX5x6qmOXVmlWayTOxeM9Oy/0RrfabtkYiIopkdOuzRadSNHdPjue/Wbednw8MvSzBn807OeW0BH15yRMR+7UiJ58ZPjZu4N40aGjngBHt3aW3Q5wPXZU20LhM3ot9aLK1fERszyb5RKXUesArwgEymSlf/nruJ20/eJ+w+/prtZhZYPuJf9pRHSsSIk5kbU7sFn44ysDEcUjoOEzWT7KuAWwMee4Gf2ROOCMffZ997ElM0v3dnvxJ+vdBU4v8o/drCGm47MfxFSiTfsc/9mOwQRBhmkv2jWutP/A+kNk7y3fZ5zw9WoYo0BRtFsy7Iog+BGnzDMZ+YuYGLDh0UY4R9Bd5cjqVV9Noi+xbZTifxLuEozEmFgnpWC5nslVL/BZwEXKKUOtH3dA5wPvBOAmITJoWa3j7ymVlRv9fq7aFH6LR3uVlY07fwl10CLwpOVxp+brbBj5uk+ykRIt2gbY1jAESyhGvZLwIGAO2A9j3nwSh5LJIg2nQXadJUtMcbO3k1by2JbjKVVdLxjyuRrJgLkWpSeURMtHNGUkHIZK+13gi8opR6TWudeb9JaejrtfYtmecXrosl0Yk+8I/dZbJkQra6+oOlyQ5BWCTYfBormOmzv1MpdSfQhnHD3au1HmxLNCLpzIzCiVd7hBWN4i1lkI2+SkBDQKQ3M8n+ImCw1trcdEthuRX1LZQVmFpnJi1M+Sn8BcW/7GIm3iQTIlnMZJBqjH57kQQLa5o4M42GS1phhm8MfCr32VolUuXRbJYFP/6EMpPsC4AlSqkl+O7Zaa0vtTUqAcB3P23norcXJ+34KyxaR/XL1Q0sre1bnE3A376TUlOpKBMvNGaS/cO2RyGCSmaiB1hiUYK+4v3Ybh5auWKSSD/Z+pnHrltWZgqhzccognYlxlDMzWbeWCl1vFJqSpDnz1VKzVFKzVRKSVE1IURKenha6CUU7RRqkmS8zCT7FzGqXR4AbAUmRHqBUuoOYDxQ1Ov5fOBx4ExgNHCdUmqPKGPOSBPmbWLWxvRfwV4IqyRyAl9vDgc8On190o5vBzPJfoDW+kWgS2s9A3PdWWuBXwV5/iBgjdZ6h9baCfwAnGI62gx211drOO+NhckOQ4iU8e6y4JVJE6GmOX0WEjfLTLJHKXWg7/8hQMSpjFrr94FgHa7lQOB872Yg/lWvhRBChGXmBu1NwEsYrfL3gD/FcbwmoCzgcRkQtO+itLSQvLzcmA6Sm5tDZWVJ5B1t9s/p1exZXsiFh+0Zdr+dHbuui/64O6Q8gBBZy478FTHZa62XAicopUZqreMd8L0CGKGU6g+0YCxz+EiwHVtaYq89UVlZQmNj8ueA3eZbF7ZubN8PLy6Ph8H/mMpDZ+zPgJKC7uffnrOBLc2dHD24PGFxCiFSS6z5q6qqLOQ2U904PkGTshlKqUuVUtdprbuA24AvgZnAi1prU6N7Mk2tbzHtB6f2vON/xftLuXPy6mSEJITIYNHMwY9qnoHWuhoY5fv6zYDnJwGTonmvdDetegcHVvWjqt+uFvzF74QfQ//HSSvsDksIkUWiadn/07YoMtyFExdxyNMzWFnfykNT19HU4UI3hP+Ytnpb8ruhhBCZI2LLXil1CMYoms1KqW+AB7XW39geWRrZ3NTB5DXbuHrkXt3PdQaZGHHqhDlAz5mhzZ1urvvPcvuDFEJkNTMt++eATuAe37/7bI0oDV309mLunLyahoC1YaeGKRXcLkvLCSESzEyy7wKWAQVa61lE18+f1p75cSMTTSzYsaXZGDnkX19jQ2P4IqF2LU4ghBChmEncXuBN4DPfYuPWlEJMYR6vl5fmb+muSHjxYeErOrQ4d42Jn1q9g/+euCjs/rI2hxAi0cy07C/CqIfzFFDne5zyXB6PqRWP3l26lYHjpvB2QAv+81UN3PVV9MMfd3Z0RUz0ALNl0WghRIKZSfb5GAuYjACuAIbaGVC8vl23jR837GDwP6Zy37eRa4Xf8MlKAO75eldyb3b2nL26aWdHj8c7O7ro8C2t99TMXcWSHp+xwVSMm9JwsWIhRHozk+xfBQYBDwJfYVStTFkXv7OEU56ZCcDLC7aYfl1z564E33skzchnZ/V4POKJ6Zz9ynzqWp3c//2uSVEtTlcsIQshhO3MJPs8YCpQqbWeCMRWsCZF/LB+B63OvnVnAjt8npm9sc/2MRPm9ChBvLy+lYd7zX79YvU2y+IUQggrmUn2BcBjwFSl1Gmk0WicDpeHz1bVdz/e0NjOr95axEhfy7+3u3xlCjY3dfTZtry+lfPeWNjjPsByi5btE0IIu5lJ9lcBGhgHVAGX2xmQ1a76YFn31/7kvKMjeHfLhPmb+XB5Lc4wi0C/OH9XKZ95W5osilIIIexlppW+DqMuzuPAKmCTrRHZoKnDRYfbw5UBa6E+NHVd0Buqf/g4fE2au75aY3l8QghhNzPJ/nmMmvNfYSwlOB5jPdq0ceQzMzmwql+P58yOnBFCiExgJtmP0Fqf6vv6I6XUDDsDskOL083czdLlIoTIXmb67IuUUiUASqli0nw0jhBCZCMzLfsngEVKqaXAwUghNCGESDtmkn0NcDwwHPhJay2DyYUQIs2YSfZ/9/XZb7c7GCGEEPYwVfVSKfUhxlh7D4DW+m5boxJCCGEpM8n+RdujEEIIYSszo3E0UKG1fgU4E1hib0hCCCGsZibZPwV87fv6XozROUIIIdKImWTv0lovB9Bar8PXby+EECJ9mOmzX6+UehCYCRwHbI6wvxBCiBRjpmV/NcZyhL8E6oHf2RqREEIIy0Vs2WutO5B+eiGESGtmWvZCCCHSnCR7IYTIAhG7cZRSvSdVdQEbgX9prXfYEpUQQghLmWnZFwNbgLeB9cBeQCHwio1xCSGEsJCZoZdVWutLfF9/qZSarLW+Vyk11c7AhBBCWMdMy75cKXUggO//MqXUAKDU1siEEEJYxkzL/gbgDaXUYGCD7/FFwAN2BiaEEMI6ZpL9YOBYrXVgmYS5NsUjhBDCBma6cc7AWJbwAaXUcLsDEkIIYb2IyV5r/WfgaGAh8E+l1NcRXiKEECLFmJ1UdRxwFjCIXeWO08prFx7KDcfvnewwhBAiKcxMqloOLAJeAMYC19gdlNVmXXccw/uXcNaI3Rmz724cu1cFwx6dluywhBAiYcy07E8BHgeuwlilaoidAdlheP+S7q9HD+tPSX4u946R2w9CiOwRsmWvlCoALsEYatkJlAPDtdbtkd5UKZUDPAMc4XvtNVrrNQHbnwJOApp9T52vtd4Z60nE4sZRQ/ntkYOZX9PEb95ezPFDKvhxU0JDEEKIhAnXsq8GDgcu01qfAmwxk+h9LgCKtNYnYHT9PNpr+0jgLK31GN8/S7NsUZ65WxHlRXmM2bc/n185krd+fZiVIQghREoJ12f/JHApMEwpNR5wRPG+JwNfAGitZymljvFv8LX6RwDPK6UGARO01r2LrcVs2jXHMmxQOZe+Po9LD9+T44ZURHzN0YPLe+x+YRAAAA6ESURBVDyee/3x5DgcjHx2llVhCSFEUoVsAmutH9ZaH4Gx4PilwLFKqYeVUoeaeN9yILC17lZK+S8s/YCngcuBs4E/KaUOjyn6INTu/RhUVsj7lxzJhYcMYu+KoqjfY2hlMUMqiljy5xOsCksIIZLKzEpV3wPfK6UqgSuA14CjIrysCSgLeJyjtXb5vm4DntRatwEopb7F6NtfHPgGpaWF5OXlmjqJ3nJzc6isLIm8Yy8n7rMb1xw/tPu1kd4jP9dBl9sbU4xCCBFKLPkrEjPlEgDQWjditMifNrH7dOBc4B2l1CiMUTx+BwATlVIjMT5ZnEyQcsktLZ1mQ+ujsrKExsa2qF/30SVHAPR47dkjBvDF6m3dj9++6HAuetu4Lv36kEG8uXhrzHEKIUQwseQvgKqqspDb7Fqp6kOgQyk1A2PY5q1KqduUUudprVcAbwCzgO+BV7XWy2yKI27PnXcwH/guAgDlhbuuj2P27Z+MkIQQImoOrzc1uyHq65tjDizWln04DW1OOro8DKkoYuC4KQDU3jmab9Zt59J3l4R/sRBCRKFu7JiYXldVVRZyII2sQWvS7iUFDOl1s9fhcHD6fgMivnbib2RYpxAiuSTZx+Dao/ciN4qBqD8bHvmCIIQQdpJkH4MHzhhBzZ1jIu53yWF7sPBPowD45PJIA5iEEMI+kuwtdN6BVQCc7/v/9P36M7jc6Po5bkgFvz5kUNJiE0JkN0n2FvL37Jyjqph2zbGce+DAHtuvPWavxAclhBBIsrfEg6fvT2Gug92K8wEozstB7d6vz34DSgoSHZoQQgBRTKoSoV1zzBCuOWYIrU43avcSztw/+A3ZvSuK+J+Th+H1enlk+voERymEyGYyzj5J/GP1hRCiNxlnL4QQIiaS7IUQIgtIshdCiCwgyV4IIbKAJHshhMgCkuxTzO0n7ZPsEIQQGUiSfZJceeSeQZ+/85R9uezwPRIcjRAi00myT5JHzlao3XsuPfbfvto5j//ywGSEJITIYJLsk+ijS4/k48uOZGA/o4zCXuWFSY5ICJGpJNkn0YCSAkbtXclvjxoMQF5OFEXyhRAiCpLsU0iKVq4QQmQASfZCCJEFJNmnEIf04gghbCLJXgghsoAk+xQwqLSgx/9grF8LMGKAMTxz5J5l9CvI7d7uf14IIcyQZJ8CLj9iTyZccDBXHjm4+7krfJOu/jpmODkOuP/0/bvXtv37z/br3q+qX35igxVCpCVZqSoF5DgcfdarPWaviu4FDLbeafz/+qIaAMoL8/AvOjOoXyH1rV0Ji1UIkZ6kZZ9GDhtUBsCwyiKK8owunUfOPoDT9t0tmWEJIdKAtOzTyO9GDubEoRUcVFXKKxceysQlWzlqzzJuHDWU737akezwhBApTJJ9GnE4HBxUVQrsWrwc4IDd+yUxKiFEOpBunAxQVSI3aYUQ4UmyzwCOCLOxdpeLgRBZT5J9htg/yLj7urFjqBs7hrJC6a0TIttJshdCiCwgyT5DXHrUXgCsvuUk3r/4CO46dd/ubfedNjxZYQkhUoTDm6J1devrm2MOrLKyhMbGNivDSXkVFcXUbmvpHn8fjMvjYfA/piYwKiFELPwTKqNVVVUW8gaetOwzhMPhCJvoAfJycoLW1JE1U4TIfJLss8z0a4+j5o7RVBblMf3aY6kbO4anzum55u39P98/SdEJIewiwzSyUG6Og1W3nNz9+DeH7kH/4nwufXcJANcesxeNHV08Mn19skIUQlhMWvYCgNP3G8A9o/dF33wSDoeDO07ZlzW3nMy1R++V7NCEEBaQZC+63XzCPuxWvGsCVnlRHg+cMaL78Vu/PowLDqpKRmhCiDjZ0o2jlMoBngGOADqBa7TWawK2Xwv8AXAB92utP7EjDmGNx3+hGDGghOOGVPDz/QbwnxVTSM0xXEKIUOxq2V8AFGmtTwDGAo/6Nyil9gBuAk4CzgIeUkoV2hSHsMBlR+zJcUMquh//dPspzPvjKOrGjunR0q+QmbpCpCy7kv3JwBcAWutZwDEB244DpmutO7XWO4E1wOE2xSFsUJKfy94VRQA8f/4h/OMso6vni9+OZP4fR/Hz4f2Z+vtjkxmiEKIXu5pi5cDOgMdupVSe1toVZFszUEEvpaWF5EUYNx5Kbm4OlZXZtUZrMs/55jH7c9WoYVT6+vs/v24UAM5xv+yxn8fjxQu0d7nJz3WQ43BQ09zJgs07uf79JXx01TGc8sxMAG48aRhPT69O5GkIkTLs+Fu2K9k3AWUBj3N8iT7YtjKgsfcbtLR0xnzwbJxBmwrn3NhpfnlE/y9DOTB6r3JW3HQS0HPm4L2nDAv7HrGes9fr7a4U6vV66XR7yHE4yA+YXeb2zSzPdThwur3k+ba1u9zkOBzk+l+PF5fbi9vrpcNlvE9bl9s4t8I8Ol0eCvJy6Ohy0+7y4PZ4yc1xMKhfAdvau2jscOHxehlQnM+ODhd7lBawvb0Ll9tLUX4OOQ4HW5o68QIDKotpbu6gtCCP1i43Dl88Jfm51DR3MriskPYuD10eD7k5DtqcHsoKc2loM34uOQ4oysth3fZ2ygvzyM910O7yUJyXQ1Onm/7FeRTn5+IAGtq62KeyiLYuNzs7jJ9WaUEebq+X2pZOcnMc5OU46JefS1uXBweQk+OgpdNF/5J86lqcOD1e+uXnsLPDRUFeDrkOByX5ubi9XlqdbsoL87q/zs9xsHu/AupbnTjdHlqcboaUF1FRWkh1fQsVRUaqcnu81LY66XR5GFJufLp0ejw0dxox1rd24XDAwH4FlBYYsZUV5NLsdNPidFFemEdZQR6bmzsoysvB64UWXyz5uQ4qCvNodrpp7nRRmJdDcV4OnW4vDqC1y82Aknx2drhweYyf+6AyI+YOl4cK3/k0tHbRryCX3Yrzae50MaS8iNrWTlp851lRlM/2ti72rihiZ2cX9a1dDNutmG1tTvrl53LdSfvG/LdcVVUWcptdyX46cC7wjlJqFLAkYNts4AGlVBFQCBwELLUpDiH6CCwJHWrmcV7APoV5u74uLQjyJ+N7qs/H00DFfctMlxbmsU/A46G+/weV9ryFtV9/o5WXChf0RJNzto5dyf5D4Ayl1AzAAVytlLoNWKO1/lgp9RQwDeOewT1a6w6b4hBCCIFNyV5r7QGu7/X0yoDtLwAv2HFsIYQQfcmkKiGEyAKS7IUQIgtIshdCiCwgyV4IIbKAJHshhMgCKbssoRBCCOtIy14IIbKAJHshhMgCkuyFECILZEwB8kgLpqQbpdTxwMNa6zFKqf2BlwEvRh2hG7TWHqXUfcA5GHXFbtFaz45m34SfVAhKqXzgRWAYRr2k+4HlZPY552LMIleAG7gao7TIy2ToOfsppQYC84AzMOJ8mQw+Z6XUAnZV+v0J+DfwJEa8k7XWfw+Vv3y1xUztGymOTGrZh1wwJd0ope4AxgNFvqceA/6itT4FIyGcr5QaCYwGjgcuBv4Vw76p4nJgmy/mXwD/JPPP+VwArfVJwF8xziHTz9l/Yf830O57KqPP2VfwEa31GN+/q4HngEsx1v043ncOofJXNPuGlUnJPtyCKelmLfCrgMdHA9/7vv4cOB3jfCdrrb1a6w1AnlKqKsp9U8W7wL0Bj11k+DlrrT8CrvM93AeoJcPP2ecRjAS2xfc408/5CKBEKTVZKfWtUupUoFBrvVZr7QW+BH5OkPyllCo3u6+ZQDIp2QddMCVZwcRDa/0+EFgc3uH7YcOuxV5CLQITzb4pQWvdorVuVkqVAe8BfyHDzxlAa+1SSr0CPI1x3hl9zkqpq4B6rfWXAU9n9DkDbRgXuLMwikO+5HvOL9R5uH3PNZnZ10yuy6RkH27BlHTnCfjav9hLqEVgotk3ZSil9ga+A17TWr9JFpwzgNb6t8ABGP33xQGbMvGcf4dR+nwKcCTwKjAwYHsmnvMq4HXfJ49VGEm6f8D2UOeRE+S5kPuayXWZlOynA78ECLJgSrpboJQa4/v6FxhrAUwHzlJK5SilhmL8wBui3DclKKUGAZOBO7XWL/qezvRzvkIpdZfvYRtGIpubyeestT5Vaz1aaz0GWAhcCXyeyeeMcYF7FEApNRgoAVqVUvsppRwYLX7/efTIX1rrJsBpZl8zgaRlN0cIfRZMSXI8VrodeEEpVQCsAN7TWruVUtOAmRgX7Rti2DdV3A3sBtyrlPL33d8MPJXB5/wB8JJSaiqQD9yCEXsm/5yDyfTf7QnAy0qpHzBGEf0O48L+BpCLcb/hR6XUHILnr+uj2DcsKZcghBBZIJO6cYQQQoQgyV4IIbKAJHshhMgCkuyFECILSLIXQogskElDL4WISCk1DJgIXAvsprWeGsd7FQGXa63H+2aHbtdaf2xJoEJYTJK9yFYXAluBmJM9sAdwDTBea/2yFUEJYRcZZy+yiq9l/xXGRCYnRsXNYuABjHoka4E/AJdhTIDJAe4DDsIoTpePMeX9VxgVFi/CqH2SA2zVWj+nlHoUo1gVwJta6yeVUi9jlKMdBuwJXKW1nm/v2Qqxi/TZi2y0DaMu+mPAHIy6NL/SWo8GNgNX+fbbobU+GaNmzwDgdF953XzgWIwLxHKt9f/1v7FS6r+AfYFRGAn/UqXUYb7N67XWZ2EUPvNXvBQiISTZi2xXhdHSfsdXoOtMYKhvmwbQWnswPgW8pZSaAAzBSPjBHARM8xW+6gJmAQf7ti3w/b+RXWsVCJEQkuxFtvJg/P43AJuA830Fuh7AaMn790EpdThwgdb6IuBG3+scAe8RaAW+LhzfQh0nAqt926TPVCSNJHuRreYBf8ZY5ehm4FNfYak/YSx5F2gNRqXCuRj9/TXAYKAOKFBKPezfUWv9CfCTUmomRqv+PembF6lAbtAKIUQWkJa9EEJkAUn2QgiRBSTZCyFEFpBkL4QQWUCSvRBCZAFJ9kIIkQUk2QshRBaQZC+EEFng/wPamuq2iZSoVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 50\n",
    "net = MLP(cis_train_x.shape[1], hidden_size, 2)\n",
    "loss, acc_t, acc_v = net.fit(cis_test_x, cis_test_y, cis_val_x, cis_val_y, reg=0, lr=0.01, mini_batch_sz=1, n_epochs=5)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg cross-entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 700 epochs and 70000 iterations total, 100 iter/epoch.\n",
      "  Completed iter 0/70000. Training loss: 0.70.\n",
      "  Completed iter 100/70000. Training loss: 0.69.\n",
      "  Completed iter 200/70000. Training loss: 0.69.\n",
      "  Completed iter 300/70000. Training loss: 0.69.\n",
      "  Completed iter 400/70000. Training loss: 0.69.\n",
      "  Completed iter 500/70000. Training loss: 0.69.\n",
      "  Completed iter 600/70000. Training loss: 0.69.\n",
      "  Completed iter 700/70000. Training loss: 0.69.\n",
      "  Completed iter 800/70000. Training loss: 0.69.\n",
      "  Completed iter 900/70000. Training loss: 0.69.\n",
      "  Completed iter 1000/70000. Training loss: 0.69.\n",
      "  Completed iter 1100/70000. Training loss: 0.69.\n",
      "  Completed iter 1200/70000. Training loss: 0.69.\n",
      "  Completed iter 1300/70000. Training loss: 0.69.\n",
      "  Completed iter 1400/70000. Training loss: 0.69.\n",
      "  Completed iter 1500/70000. Training loss: 0.69.\n",
      "  Completed iter 1600/70000. Training loss: 0.69.\n",
      "  Completed iter 1700/70000. Training loss: 0.68.\n",
      "  Completed iter 1800/70000. Training loss: 0.69.\n",
      "  Completed iter 1900/70000. Training loss: 0.69.\n",
      "  Completed iter 2000/70000. Training loss: 0.69.\n",
      "  Completed iter 2100/70000. Training loss: 0.68.\n",
      "  Completed iter 2200/70000. Training loss: 0.69.\n",
      "  Completed iter 2300/70000. Training loss: 0.68.\n",
      "  Completed iter 2400/70000. Training loss: 0.68.\n",
      "  Completed iter 2500/70000. Training loss: 0.68.\n",
      "  Completed iter 2600/70000. Training loss: 0.69.\n",
      "  Completed iter 2700/70000. Training loss: 0.68.\n",
      "  Completed iter 2800/70000. Training loss: 0.68.\n",
      "  Completed iter 2900/70000. Training loss: 0.68.\n",
      "  Completed iter 3000/70000. Training loss: 0.67.\n",
      "  Completed iter 3100/70000. Training loss: 0.69.\n",
      "  Completed iter 3200/70000. Training loss: 0.67.\n",
      "  Completed iter 3300/70000. Training loss: 0.68.\n",
      "  Completed iter 3400/70000. Training loss: 0.68.\n",
      "  Completed iter 3500/70000. Training loss: 0.69.\n",
      "  Completed iter 3600/70000. Training loss: 0.68.\n",
      "  Completed iter 3700/70000. Training loss: 0.68.\n",
      "  Completed iter 3800/70000. Training loss: 0.67.\n",
      "  Completed iter 3900/70000. Training loss: 0.68.\n",
      "  Completed iter 4000/70000. Training loss: 0.67.\n",
      "  Completed iter 4100/70000. Training loss: 0.67.\n",
      "  Completed iter 4200/70000. Training loss: 0.66.\n",
      "  Completed iter 4300/70000. Training loss: 0.67.\n",
      "  Completed iter 4400/70000. Training loss: 0.66.\n",
      "  Completed iter 4500/70000. Training loss: 0.66.\n",
      "  Completed iter 4600/70000. Training loss: 0.66.\n",
      "  Completed iter 4700/70000. Training loss: 0.67.\n",
      "  Completed iter 4800/70000. Training loss: 0.66.\n",
      "  Completed iter 4900/70000. Training loss: 0.66.\n",
      "  Completed iter 5000/70000. Training loss: 0.65.\n",
      "  Completed iter 5100/70000. Training loss: 0.67.\n",
      "  Completed iter 5200/70000. Training loss: 0.66.\n",
      "  Completed iter 5300/70000. Training loss: 0.65.\n",
      "  Completed iter 5400/70000. Training loss: 0.66.\n",
      "  Completed iter 5500/70000. Training loss: 0.64.\n",
      "  Completed iter 5600/70000. Training loss: 0.65.\n",
      "  Completed iter 5700/70000. Training loss: 0.64.\n",
      "  Completed iter 5800/70000. Training loss: 0.65.\n",
      "  Completed iter 5900/70000. Training loss: 0.65.\n",
      "  Completed iter 6000/70000. Training loss: 0.64.\n",
      "  Completed iter 6100/70000. Training loss: 0.63.\n",
      "  Completed iter 6200/70000. Training loss: 0.65.\n",
      "  Completed iter 6300/70000. Training loss: 0.63.\n",
      "  Completed iter 6400/70000. Training loss: 0.63.\n",
      "  Completed iter 6500/70000. Training loss: 0.63.\n",
      "  Completed iter 6600/70000. Training loss: 0.62.\n",
      "  Completed iter 6700/70000. Training loss: 0.62.\n",
      "  Completed iter 6800/70000. Training loss: 0.62.\n",
      "  Completed iter 6900/70000. Training loss: 0.63.\n",
      "  Completed iter 7000/70000. Training loss: 0.60.\n",
      "  Completed iter 7100/70000. Training loss: 0.61.\n",
      "  Completed iter 7200/70000. Training loss: 0.62.\n",
      "  Completed iter 7300/70000. Training loss: 0.60.\n",
      "  Completed iter 7400/70000. Training loss: 0.61.\n",
      "  Completed iter 7500/70000. Training loss: 0.60.\n",
      "  Completed iter 7600/70000. Training loss: 0.59.\n",
      "  Completed iter 7700/70000. Training loss: 0.58.\n",
      "  Completed iter 7800/70000. Training loss: 0.61.\n",
      "  Completed iter 7900/70000. Training loss: 0.58.\n",
      "  Completed iter 8000/70000. Training loss: 0.60.\n",
      "  Completed iter 8100/70000. Training loss: 0.57.\n",
      "  Completed iter 8200/70000. Training loss: 0.58.\n",
      "  Completed iter 8300/70000. Training loss: 0.55.\n",
      "  Completed iter 8400/70000. Training loss: 0.60.\n",
      "  Completed iter 8500/70000. Training loss: 0.58.\n",
      "  Completed iter 8600/70000. Training loss: 0.57.\n",
      "  Completed iter 8700/70000. Training loss: 0.54.\n",
      "  Completed iter 8800/70000. Training loss: 0.58.\n",
      "  Completed iter 8900/70000. Training loss: 0.57.\n",
      "  Completed iter 9000/70000. Training loss: 0.54.\n",
      "  Completed iter 9100/70000. Training loss: 0.55.\n",
      "  Completed iter 9200/70000. Training loss: 0.53.\n",
      "  Completed iter 9300/70000. Training loss: 0.54.\n",
      "  Completed iter 9400/70000. Training loss: 0.57.\n",
      "  Completed iter 9500/70000. Training loss: 0.53.\n",
      "  Completed iter 9600/70000. Training loss: 0.54.\n",
      "  Completed iter 9700/70000. Training loss: 0.51.\n",
      "  Completed iter 9800/70000. Training loss: 0.53.\n",
      "  Completed iter 9900/70000. Training loss: 0.53.\n",
      "  Completed iter 10000/70000. Training loss: 0.52.\n",
      "  Completed iter 10100/70000. Training loss: 0.52.\n",
      "  Completed iter 10200/70000. Training loss: 0.50.\n",
      "  Completed iter 10300/70000. Training loss: 0.49.\n",
      "  Completed iter 10400/70000. Training loss: 0.52.\n",
      "  Completed iter 10500/70000. Training loss: 0.54.\n",
      "  Completed iter 10600/70000. Training loss: 0.50.\n",
      "  Completed iter 10700/70000. Training loss: 0.50.\n",
      "  Completed iter 10800/70000. Training loss: 0.49.\n",
      "  Completed iter 10900/70000. Training loss: 0.44.\n",
      "  Completed iter 11000/70000. Training loss: 0.46.\n",
      "  Completed iter 11100/70000. Training loss: 0.47.\n",
      "  Completed iter 11200/70000. Training loss: 0.47.\n",
      "  Completed iter 11300/70000. Training loss: 0.46.\n",
      "  Completed iter 11400/70000. Training loss: 0.44.\n",
      "  Completed iter 11500/70000. Training loss: 0.47.\n",
      "  Completed iter 11600/70000. Training loss: 0.43.\n",
      "  Completed iter 11700/70000. Training loss: 0.44.\n",
      "  Completed iter 11800/70000. Training loss: 0.42.\n",
      "  Completed iter 11900/70000. Training loss: 0.43.\n",
      "  Completed iter 12000/70000. Training loss: 0.42.\n",
      "  Completed iter 12100/70000. Training loss: 0.46.\n",
      "  Completed iter 12200/70000. Training loss: 0.41.\n",
      "  Completed iter 12300/70000. Training loss: 0.42.\n",
      "  Completed iter 12400/70000. Training loss: 0.42.\n",
      "  Completed iter 12500/70000. Training loss: 0.43.\n",
      "  Completed iter 12600/70000. Training loss: 0.37.\n",
      "  Completed iter 12700/70000. Training loss: 0.41.\n",
      "  Completed iter 12800/70000. Training loss: 0.41.\n",
      "  Completed iter 12900/70000. Training loss: 0.40.\n",
      "  Completed iter 13000/70000. Training loss: 0.37.\n",
      "  Completed iter 13100/70000. Training loss: 0.38.\n",
      "  Completed iter 13200/70000. Training loss: 0.33.\n",
      "  Completed iter 13300/70000. Training loss: 0.39.\n",
      "  Completed iter 13400/70000. Training loss: 0.35.\n",
      "  Completed iter 13500/70000. Training loss: 0.37.\n",
      "  Completed iter 13600/70000. Training loss: 0.36.\n",
      "  Completed iter 13700/70000. Training loss: 0.33.\n",
      "  Completed iter 13800/70000. Training loss: 0.35.\n",
      "  Completed iter 13900/70000. Training loss: 0.34.\n",
      "  Completed iter 14000/70000. Training loss: 0.32.\n",
      "  Completed iter 14100/70000. Training loss: 0.34.\n",
      "  Completed iter 14200/70000. Training loss: 0.36.\n",
      "  Completed iter 14300/70000. Training loss: 0.35.\n",
      "  Completed iter 14400/70000. Training loss: 0.34.\n",
      "  Completed iter 14500/70000. Training loss: 0.32.\n",
      "  Completed iter 14600/70000. Training loss: 0.32.\n",
      "  Completed iter 14700/70000. Training loss: 0.32.\n",
      "  Completed iter 14800/70000. Training loss: 0.31.\n",
      "  Completed iter 14900/70000. Training loss: 0.33.\n",
      "  Completed iter 15000/70000. Training loss: 0.32.\n",
      "  Completed iter 15100/70000. Training loss: 0.31.\n",
      "  Completed iter 15200/70000. Training loss: 0.33.\n",
      "  Completed iter 15300/70000. Training loss: 0.30.\n",
      "  Completed iter 15400/70000. Training loss: 0.30.\n",
      "  Completed iter 15500/70000. Training loss: 0.32.\n",
      "  Completed iter 15600/70000. Training loss: 0.29.\n",
      "  Completed iter 15700/70000. Training loss: 0.32.\n",
      "  Completed iter 15800/70000. Training loss: 0.33.\n",
      "  Completed iter 15900/70000. Training loss: 0.29.\n",
      "  Completed iter 16000/70000. Training loss: 0.30.\n",
      "  Completed iter 16100/70000. Training loss: 0.29.\n",
      "  Completed iter 16200/70000. Training loss: 0.27.\n",
      "  Completed iter 16300/70000. Training loss: 0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 16400/70000. Training loss: 0.32.\n",
      "  Completed iter 16500/70000. Training loss: 0.30.\n",
      "  Completed iter 16600/70000. Training loss: 0.27.\n",
      "  Completed iter 16700/70000. Training loss: 0.28.\n",
      "  Completed iter 16800/70000. Training loss: 0.24.\n",
      "  Completed iter 16900/70000. Training loss: 0.29.\n",
      "  Completed iter 17000/70000. Training loss: 0.26.\n",
      "  Completed iter 17100/70000. Training loss: 0.26.\n",
      "  Completed iter 17200/70000. Training loss: 0.30.\n",
      "  Completed iter 17300/70000. Training loss: 0.26.\n",
      "  Completed iter 17400/70000. Training loss: 0.27.\n",
      "  Completed iter 17500/70000. Training loss: 0.26.\n",
      "  Completed iter 17600/70000. Training loss: 0.29.\n",
      "  Completed iter 17700/70000. Training loss: 0.26.\n",
      "  Completed iter 17800/70000. Training loss: 0.25.\n",
      "  Completed iter 17900/70000. Training loss: 0.25.\n",
      "  Completed iter 18000/70000. Training loss: 0.24.\n",
      "  Completed iter 18100/70000. Training loss: 0.22.\n",
      "  Completed iter 18200/70000. Training loss: 0.25.\n",
      "  Completed iter 18300/70000. Training loss: 0.25.\n",
      "  Completed iter 18400/70000. Training loss: 0.28.\n",
      "  Completed iter 18500/70000. Training loss: 0.25.\n",
      "  Completed iter 18600/70000. Training loss: 0.27.\n",
      "  Completed iter 18700/70000. Training loss: 0.30.\n",
      "  Completed iter 18800/70000. Training loss: 0.23.\n",
      "  Completed iter 18900/70000. Training loss: 0.25.\n",
      "  Completed iter 19000/70000. Training loss: 0.23.\n",
      "  Completed iter 19100/70000. Training loss: 0.23.\n",
      "  Completed iter 19200/70000. Training loss: 0.23.\n",
      "  Completed iter 19300/70000. Training loss: 0.22.\n",
      "  Completed iter 19400/70000. Training loss: 0.24.\n",
      "  Completed iter 19500/70000. Training loss: 0.22.\n",
      "  Completed iter 19600/70000. Training loss: 0.19.\n",
      "  Completed iter 19700/70000. Training loss: 0.22.\n",
      "  Completed iter 19800/70000. Training loss: 0.22.\n",
      "  Completed iter 19900/70000. Training loss: 0.23.\n",
      "  Completed iter 20000/70000. Training loss: 0.23.\n",
      "  Completed iter 20100/70000. Training loss: 0.24.\n",
      "  Completed iter 20200/70000. Training loss: 0.20.\n",
      "  Completed iter 20300/70000. Training loss: 0.22.\n",
      "  Completed iter 20400/70000. Training loss: 0.22.\n",
      "  Completed iter 20500/70000. Training loss: 0.18.\n",
      "  Completed iter 20600/70000. Training loss: 0.18.\n",
      "  Completed iter 20700/70000. Training loss: 0.21.\n",
      "  Completed iter 20800/70000. Training loss: 0.22.\n",
      "  Completed iter 20900/70000. Training loss: 0.18.\n",
      "  Completed iter 21000/70000. Training loss: 0.23.\n",
      "  Completed iter 21100/70000. Training loss: 0.23.\n",
      "  Completed iter 21200/70000. Training loss: 0.22.\n",
      "  Completed iter 21300/70000. Training loss: 0.20.\n",
      "  Completed iter 21400/70000. Training loss: 0.23.\n",
      "  Completed iter 21500/70000. Training loss: 0.21.\n",
      "  Completed iter 21600/70000. Training loss: 0.23.\n",
      "  Completed iter 21700/70000. Training loss: 0.24.\n",
      "  Completed iter 21800/70000. Training loss: 0.22.\n",
      "  Completed iter 21900/70000. Training loss: 0.22.\n",
      "  Completed iter 22000/70000. Training loss: 0.19.\n",
      "  Completed iter 22100/70000. Training loss: 0.23.\n",
      "  Completed iter 22200/70000. Training loss: 0.22.\n",
      "  Completed iter 22300/70000. Training loss: 0.20.\n",
      "  Completed iter 22400/70000. Training loss: 0.19.\n",
      "  Completed iter 22500/70000. Training loss: 0.20.\n",
      "  Completed iter 22600/70000. Training loss: 0.21.\n",
      "  Completed iter 22700/70000. Training loss: 0.21.\n",
      "  Completed iter 22800/70000. Training loss: 0.17.\n",
      "  Completed iter 22900/70000. Training loss: 0.20.\n",
      "  Completed iter 23000/70000. Training loss: 0.19.\n",
      "  Completed iter 23100/70000. Training loss: 0.21.\n",
      "  Completed iter 23200/70000. Training loss: 0.21.\n",
      "  Completed iter 23300/70000. Training loss: 0.17.\n",
      "  Completed iter 23400/70000. Training loss: 0.21.\n",
      "  Completed iter 23500/70000. Training loss: 0.16.\n",
      "  Completed iter 23600/70000. Training loss: 0.20.\n",
      "  Completed iter 23700/70000. Training loss: 0.21.\n",
      "  Completed iter 23800/70000. Training loss: 0.17.\n",
      "  Completed iter 23900/70000. Training loss: 0.16.\n",
      "  Completed iter 24000/70000. Training loss: 0.16.\n",
      "  Completed iter 24100/70000. Training loss: 0.17.\n",
      "  Completed iter 24200/70000. Training loss: 0.21.\n",
      "  Completed iter 24300/70000. Training loss: 0.18.\n",
      "  Completed iter 24400/70000. Training loss: 0.14.\n",
      "  Completed iter 24500/70000. Training loss: 0.15.\n",
      "  Completed iter 24600/70000. Training loss: 0.17.\n",
      "  Completed iter 24700/70000. Training loss: 0.17.\n",
      "  Completed iter 24800/70000. Training loss: 0.19.\n",
      "  Completed iter 24900/70000. Training loss: 0.15.\n",
      "  Completed iter 25000/70000. Training loss: 0.18.\n",
      "  Completed iter 25100/70000. Training loss: 0.16.\n",
      "  Completed iter 25200/70000. Training loss: 0.18.\n",
      "  Completed iter 25300/70000. Training loss: 0.17.\n",
      "  Completed iter 25400/70000. Training loss: 0.15.\n",
      "  Completed iter 25500/70000. Training loss: 0.16.\n",
      "  Completed iter 25600/70000. Training loss: 0.18.\n",
      "  Completed iter 25700/70000. Training loss: 0.17.\n",
      "  Completed iter 25800/70000. Training loss: 0.16.\n",
      "  Completed iter 25900/70000. Training loss: 0.20.\n",
      "  Completed iter 26000/70000. Training loss: 0.17.\n",
      "  Completed iter 26100/70000. Training loss: 0.16.\n",
      "  Completed iter 26200/70000. Training loss: 0.14.\n",
      "  Completed iter 26300/70000. Training loss: 0.17.\n",
      "  Completed iter 26400/70000. Training loss: 0.17.\n",
      "  Completed iter 26500/70000. Training loss: 0.17.\n",
      "  Completed iter 26600/70000. Training loss: 0.18.\n",
      "  Completed iter 26700/70000. Training loss: 0.17.\n",
      "  Completed iter 26800/70000. Training loss: 0.18.\n",
      "  Completed iter 26900/70000. Training loss: 0.16.\n",
      "  Completed iter 27000/70000. Training loss: 0.17.\n",
      "  Completed iter 27100/70000. Training loss: 0.18.\n",
      "  Completed iter 27200/70000. Training loss: 0.18.\n",
      "  Completed iter 27300/70000. Training loss: 0.12.\n",
      "  Completed iter 27400/70000. Training loss: 0.14.\n",
      "  Completed iter 27500/70000. Training loss: 0.17.\n",
      "  Completed iter 27600/70000. Training loss: 0.17.\n",
      "  Completed iter 27700/70000. Training loss: 0.12.\n",
      "  Completed iter 27800/70000. Training loss: 0.19.\n",
      "  Completed iter 27900/70000. Training loss: 0.14.\n",
      "  Completed iter 28000/70000. Training loss: 0.17.\n",
      "  Completed iter 28100/70000. Training loss: 0.18.\n",
      "  Completed iter 28200/70000. Training loss: 0.15.\n",
      "  Completed iter 28300/70000. Training loss: 0.15.\n",
      "  Completed iter 28400/70000. Training loss: 0.14.\n",
      "  Completed iter 28500/70000. Training loss: 0.17.\n",
      "  Completed iter 28600/70000. Training loss: 0.13.\n",
      "  Completed iter 28700/70000. Training loss: 0.15.\n",
      "  Completed iter 28800/70000. Training loss: 0.13.\n",
      "  Completed iter 28900/70000. Training loss: 0.13.\n",
      "  Completed iter 29000/70000. Training loss: 0.14.\n",
      "  Completed iter 29100/70000. Training loss: 0.15.\n",
      "  Completed iter 29200/70000. Training loss: 0.17.\n",
      "  Completed iter 29300/70000. Training loss: 0.14.\n",
      "  Completed iter 29400/70000. Training loss: 0.13.\n",
      "  Completed iter 29500/70000. Training loss: 0.13.\n",
      "  Completed iter 29600/70000. Training loss: 0.18.\n",
      "  Completed iter 29700/70000. Training loss: 0.18.\n",
      "  Completed iter 29800/70000. Training loss: 0.14.\n",
      "  Completed iter 29900/70000. Training loss: 0.18.\n",
      "  Completed iter 30000/70000. Training loss: 0.14.\n",
      "  Completed iter 30100/70000. Training loss: 0.17.\n",
      "  Completed iter 30200/70000. Training loss: 0.12.\n",
      "  Completed iter 30300/70000. Training loss: 0.12.\n",
      "  Completed iter 30400/70000. Training loss: 0.14.\n",
      "  Completed iter 30500/70000. Training loss: 0.17.\n",
      "  Completed iter 30600/70000. Training loss: 0.15.\n",
      "  Completed iter 30700/70000. Training loss: 0.13.\n",
      "  Completed iter 30800/70000. Training loss: 0.13.\n",
      "  Completed iter 30900/70000. Training loss: 0.15.\n",
      "  Completed iter 31000/70000. Training loss: 0.14.\n",
      "  Completed iter 31100/70000. Training loss: 0.13.\n",
      "  Completed iter 31200/70000. Training loss: 0.11.\n",
      "  Completed iter 31300/70000. Training loss: 0.16.\n",
      "  Completed iter 31400/70000. Training loss: 0.18.\n",
      "  Completed iter 31500/70000. Training loss: 0.16.\n",
      "  Completed iter 31600/70000. Training loss: 0.13.\n",
      "  Completed iter 31700/70000. Training loss: 0.17.\n",
      "  Completed iter 31800/70000. Training loss: 0.13.\n",
      "  Completed iter 31900/70000. Training loss: 0.15.\n",
      "  Completed iter 32000/70000. Training loss: 0.15.\n",
      "  Completed iter 32100/70000. Training loss: 0.11.\n",
      "  Completed iter 32200/70000. Training loss: 0.15.\n",
      "  Completed iter 32300/70000. Training loss: 0.16.\n",
      "  Completed iter 32400/70000. Training loss: 0.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 32500/70000. Training loss: 0.14.\n",
      "  Completed iter 32600/70000. Training loss: 0.14.\n",
      "  Completed iter 32700/70000. Training loss: 0.13.\n",
      "  Completed iter 32800/70000. Training loss: 0.12.\n",
      "  Completed iter 32900/70000. Training loss: 0.13.\n",
      "  Completed iter 33000/70000. Training loss: 0.15.\n",
      "  Completed iter 33100/70000. Training loss: 0.11.\n",
      "  Completed iter 33200/70000. Training loss: 0.10.\n",
      "  Completed iter 33300/70000. Training loss: 0.09.\n",
      "  Completed iter 33400/70000. Training loss: 0.13.\n",
      "  Completed iter 33500/70000. Training loss: 0.13.\n",
      "  Completed iter 33600/70000. Training loss: 0.12.\n",
      "  Completed iter 33700/70000. Training loss: 0.15.\n",
      "  Completed iter 33800/70000. Training loss: 0.16.\n",
      "  Completed iter 33900/70000. Training loss: 0.10.\n",
      "  Completed iter 34000/70000. Training loss: 0.12.\n",
      "  Completed iter 34100/70000. Training loss: 0.14.\n",
      "  Completed iter 34200/70000. Training loss: 0.10.\n",
      "  Completed iter 34300/70000. Training loss: 0.13.\n",
      "  Completed iter 34400/70000. Training loss: 0.12.\n",
      "  Completed iter 34500/70000. Training loss: 0.14.\n",
      "  Completed iter 34600/70000. Training loss: 0.11.\n",
      "  Completed iter 34700/70000. Training loss: 0.12.\n",
      "  Completed iter 34800/70000. Training loss: 0.13.\n",
      "  Completed iter 34900/70000. Training loss: 0.12.\n",
      "  Completed iter 35000/70000. Training loss: 0.12.\n",
      "  Completed iter 35100/70000. Training loss: 0.16.\n",
      "  Completed iter 35200/70000. Training loss: 0.16.\n",
      "  Completed iter 35300/70000. Training loss: 0.12.\n",
      "  Completed iter 35400/70000. Training loss: 0.14.\n",
      "  Completed iter 35500/70000. Training loss: 0.13.\n",
      "  Completed iter 35600/70000. Training loss: 0.12.\n",
      "  Completed iter 35700/70000. Training loss: 0.13.\n",
      "  Completed iter 35800/70000. Training loss: 0.13.\n",
      "  Completed iter 35900/70000. Training loss: 0.13.\n",
      "  Completed iter 36000/70000. Training loss: 0.09.\n",
      "  Completed iter 36100/70000. Training loss: 0.12.\n",
      "  Completed iter 36200/70000. Training loss: 0.14.\n",
      "  Completed iter 36300/70000. Training loss: 0.09.\n",
      "  Completed iter 36400/70000. Training loss: 0.16.\n",
      "  Completed iter 36500/70000. Training loss: 0.12.\n",
      "  Completed iter 36600/70000. Training loss: 0.13.\n",
      "  Completed iter 36700/70000. Training loss: 0.12.\n",
      "  Completed iter 36800/70000. Training loss: 0.15.\n",
      "  Completed iter 36900/70000. Training loss: 0.11.\n",
      "  Completed iter 37000/70000. Training loss: 0.11.\n",
      "  Completed iter 37100/70000. Training loss: 0.10.\n",
      "  Completed iter 37200/70000. Training loss: 0.10.\n",
      "  Completed iter 37300/70000. Training loss: 0.10.\n",
      "  Completed iter 37400/70000. Training loss: 0.12.\n",
      "  Completed iter 37500/70000. Training loss: 0.11.\n",
      "  Completed iter 37600/70000. Training loss: 0.11.\n",
      "  Completed iter 37700/70000. Training loss: 0.11.\n",
      "  Completed iter 37800/70000. Training loss: 0.10.\n",
      "  Completed iter 37900/70000. Training loss: 0.12.\n",
      "  Completed iter 38000/70000. Training loss: 0.14.\n",
      "  Completed iter 38100/70000. Training loss: 0.13.\n",
      "  Completed iter 38200/70000. Training loss: 0.11.\n",
      "  Completed iter 38300/70000. Training loss: 0.11.\n",
      "  Completed iter 38400/70000. Training loss: 0.14.\n",
      "  Completed iter 38500/70000. Training loss: 0.12.\n",
      "  Completed iter 38600/70000. Training loss: 0.13.\n",
      "  Completed iter 38700/70000. Training loss: 0.12.\n",
      "  Completed iter 38800/70000. Training loss: 0.11.\n",
      "  Completed iter 38900/70000. Training loss: 0.14.\n",
      "  Completed iter 39000/70000. Training loss: 0.12.\n",
      "  Completed iter 39100/70000. Training loss: 0.12.\n",
      "  Completed iter 39200/70000. Training loss: 0.11.\n",
      "  Completed iter 39300/70000. Training loss: 0.13.\n",
      "  Completed iter 39400/70000. Training loss: 0.11.\n",
      "  Completed iter 39500/70000. Training loss: 0.11.\n",
      "  Completed iter 39600/70000. Training loss: 0.11.\n",
      "  Completed iter 39700/70000. Training loss: 0.11.\n",
      "  Completed iter 39800/70000. Training loss: 0.12.\n",
      "  Completed iter 39900/70000. Training loss: 0.10.\n",
      "  Completed iter 40000/70000. Training loss: 0.13.\n",
      "  Completed iter 40100/70000. Training loss: 0.12.\n",
      "  Completed iter 40200/70000. Training loss: 0.12.\n",
      "  Completed iter 40300/70000. Training loss: 0.12.\n",
      "  Completed iter 40400/70000. Training loss: 0.12.\n",
      "  Completed iter 40500/70000. Training loss: 0.09.\n",
      "  Completed iter 40600/70000. Training loss: 0.15.\n",
      "  Completed iter 40700/70000. Training loss: 0.11.\n",
      "  Completed iter 40800/70000. Training loss: 0.12.\n",
      "  Completed iter 40900/70000. Training loss: 0.14.\n",
      "  Completed iter 41000/70000. Training loss: 0.14.\n",
      "  Completed iter 41100/70000. Training loss: 0.13.\n",
      "  Completed iter 41200/70000. Training loss: 0.10.\n",
      "  Completed iter 41300/70000. Training loss: 0.16.\n",
      "  Completed iter 41400/70000. Training loss: 0.15.\n",
      "  Completed iter 41500/70000. Training loss: 0.15.\n",
      "  Completed iter 41600/70000. Training loss: 0.12.\n",
      "  Completed iter 41700/70000. Training loss: 0.12.\n",
      "  Completed iter 41800/70000. Training loss: 0.08.\n",
      "  Completed iter 41900/70000. Training loss: 0.10.\n",
      "  Completed iter 42000/70000. Training loss: 0.10.\n",
      "  Completed iter 42100/70000. Training loss: 0.14.\n",
      "  Completed iter 42200/70000. Training loss: 0.13.\n",
      "  Completed iter 42300/70000. Training loss: 0.12.\n",
      "  Completed iter 42400/70000. Training loss: 0.13.\n",
      "  Completed iter 42500/70000. Training loss: 0.11.\n",
      "  Completed iter 42600/70000. Training loss: 0.12.\n",
      "  Completed iter 42700/70000. Training loss: 0.10.\n",
      "  Completed iter 42800/70000. Training loss: 0.10.\n",
      "  Completed iter 42900/70000. Training loss: 0.08.\n",
      "  Completed iter 43000/70000. Training loss: 0.10.\n",
      "  Completed iter 43100/70000. Training loss: 0.10.\n",
      "  Completed iter 43200/70000. Training loss: 0.14.\n",
      "  Completed iter 43300/70000. Training loss: 0.10.\n",
      "  Completed iter 43400/70000. Training loss: 0.12.\n",
      "  Completed iter 43500/70000. Training loss: 0.09.\n",
      "  Completed iter 43600/70000. Training loss: 0.12.\n",
      "  Completed iter 43700/70000. Training loss: 0.10.\n",
      "  Completed iter 43800/70000. Training loss: 0.08.\n",
      "  Completed iter 43900/70000. Training loss: 0.09.\n",
      "  Completed iter 44000/70000. Training loss: 0.11.\n",
      "  Completed iter 44100/70000. Training loss: 0.13.\n",
      "  Completed iter 44200/70000. Training loss: 0.13.\n",
      "  Completed iter 44300/70000. Training loss: 0.13.\n",
      "  Completed iter 44400/70000. Training loss: 0.11.\n",
      "  Completed iter 44500/70000. Training loss: 0.09.\n",
      "  Completed iter 44600/70000. Training loss: 0.11.\n",
      "  Completed iter 44700/70000. Training loss: 0.08.\n",
      "  Completed iter 44800/70000. Training loss: 0.13.\n",
      "  Completed iter 44900/70000. Training loss: 0.14.\n",
      "  Completed iter 45000/70000. Training loss: 0.11.\n",
      "  Completed iter 45100/70000. Training loss: 0.14.\n",
      "  Completed iter 45200/70000. Training loss: 0.11.\n",
      "  Completed iter 45300/70000. Training loss: 0.10.\n",
      "  Completed iter 45400/70000. Training loss: 0.10.\n",
      "  Completed iter 45500/70000. Training loss: 0.10.\n",
      "  Completed iter 45600/70000. Training loss: 0.09.\n",
      "  Completed iter 45700/70000. Training loss: 0.06.\n",
      "  Completed iter 45800/70000. Training loss: 0.11.\n",
      "  Completed iter 45900/70000. Training loss: 0.09.\n",
      "  Completed iter 46000/70000. Training loss: 0.10.\n",
      "  Completed iter 46100/70000. Training loss: 0.11.\n",
      "  Completed iter 46200/70000. Training loss: 0.11.\n",
      "  Completed iter 46300/70000. Training loss: 0.11.\n",
      "  Completed iter 46400/70000. Training loss: 0.08.\n",
      "  Completed iter 46500/70000. Training loss: 0.13.\n",
      "  Completed iter 46600/70000. Training loss: 0.11.\n",
      "  Completed iter 46700/70000. Training loss: 0.07.\n",
      "  Completed iter 46800/70000. Training loss: 0.10.\n",
      "  Completed iter 46900/70000. Training loss: 0.13.\n",
      "  Completed iter 47000/70000. Training loss: 0.09.\n",
      "  Completed iter 47100/70000. Training loss: 0.06.\n",
      "  Completed iter 47200/70000. Training loss: 0.09.\n",
      "  Completed iter 47300/70000. Training loss: 0.14.\n",
      "  Completed iter 47400/70000. Training loss: 0.09.\n",
      "  Completed iter 47500/70000. Training loss: 0.13.\n",
      "  Completed iter 47600/70000. Training loss: 0.11.\n",
      "  Completed iter 47700/70000. Training loss: 0.11.\n",
      "  Completed iter 47800/70000. Training loss: 0.08.\n",
      "  Completed iter 47900/70000. Training loss: 0.08.\n",
      "  Completed iter 48000/70000. Training loss: 0.10.\n",
      "  Completed iter 48100/70000. Training loss: 0.12.\n",
      "  Completed iter 48200/70000. Training loss: 0.12.\n",
      "  Completed iter 48300/70000. Training loss: 0.11.\n",
      "  Completed iter 48400/70000. Training loss: 0.14.\n",
      "  Completed iter 48500/70000. Training loss: 0.08.\n",
      "  Completed iter 48600/70000. Training loss: 0.07.\n",
      "  Completed iter 48700/70000. Training loss: 0.09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 48800/70000. Training loss: 0.10.\n",
      "  Completed iter 48900/70000. Training loss: 0.12.\n",
      "  Completed iter 49000/70000. Training loss: 0.14.\n",
      "  Completed iter 49100/70000. Training loss: 0.11.\n",
      "  Completed iter 49200/70000. Training loss: 0.08.\n",
      "  Completed iter 49300/70000. Training loss: 0.11.\n",
      "  Completed iter 49400/70000. Training loss: 0.10.\n",
      "  Completed iter 49500/70000. Training loss: 0.09.\n",
      "  Completed iter 49600/70000. Training loss: 0.07.\n",
      "  Completed iter 49700/70000. Training loss: 0.09.\n",
      "  Completed iter 49800/70000. Training loss: 0.10.\n",
      "  Completed iter 49900/70000. Training loss: 0.11.\n",
      "  Completed iter 50000/70000. Training loss: 0.09.\n",
      "  Completed iter 50100/70000. Training loss: 0.10.\n",
      "  Completed iter 50200/70000. Training loss: 0.08.\n",
      "  Completed iter 50300/70000. Training loss: 0.11.\n",
      "  Completed iter 50400/70000. Training loss: 0.11.\n",
      "  Completed iter 50500/70000. Training loss: 0.09.\n",
      "  Completed iter 50600/70000. Training loss: 0.11.\n",
      "  Completed iter 50700/70000. Training loss: 0.07.\n",
      "  Completed iter 50800/70000. Training loss: 0.10.\n",
      "  Completed iter 50900/70000. Training loss: 0.09.\n",
      "  Completed iter 51000/70000. Training loss: 0.10.\n",
      "  Completed iter 51100/70000. Training loss: 0.07.\n",
      "  Completed iter 51200/70000. Training loss: 0.10.\n",
      "  Completed iter 51300/70000. Training loss: 0.07.\n",
      "  Completed iter 51400/70000. Training loss: 0.07.\n",
      "  Completed iter 51500/70000. Training loss: 0.09.\n",
      "  Completed iter 51600/70000. Training loss: 0.07.\n",
      "  Completed iter 51700/70000. Training loss: 0.07.\n",
      "  Completed iter 51800/70000. Training loss: 0.09.\n",
      "  Completed iter 51900/70000. Training loss: 0.12.\n",
      "  Completed iter 52000/70000. Training loss: 0.08.\n",
      "  Completed iter 52100/70000. Training loss: 0.11.\n",
      "  Completed iter 52200/70000. Training loss: 0.13.\n",
      "  Completed iter 52300/70000. Training loss: 0.08.\n",
      "  Completed iter 52400/70000. Training loss: 0.12.\n",
      "  Completed iter 52500/70000. Training loss: 0.10.\n",
      "  Completed iter 52600/70000. Training loss: 0.09.\n",
      "  Completed iter 52700/70000. Training loss: 0.08.\n",
      "  Completed iter 52800/70000. Training loss: 0.12.\n",
      "  Completed iter 52900/70000. Training loss: 0.08.\n",
      "  Completed iter 53000/70000. Training loss: 0.07.\n",
      "  Completed iter 53100/70000. Training loss: 0.07.\n",
      "  Completed iter 53200/70000. Training loss: 0.08.\n",
      "  Completed iter 53300/70000. Training loss: 0.10.\n",
      "  Completed iter 53400/70000. Training loss: 0.10.\n",
      "  Completed iter 53500/70000. Training loss: 0.09.\n",
      "  Completed iter 53600/70000. Training loss: 0.11.\n",
      "  Completed iter 53700/70000. Training loss: 0.10.\n",
      "  Completed iter 53800/70000. Training loss: 0.08.\n",
      "  Completed iter 53900/70000. Training loss: 0.10.\n",
      "  Completed iter 54000/70000. Training loss: 0.09.\n",
      "  Completed iter 54100/70000. Training loss: 0.08.\n",
      "  Completed iter 54200/70000. Training loss: 0.10.\n",
      "  Completed iter 54300/70000. Training loss: 0.07.\n",
      "  Completed iter 54400/70000. Training loss: 0.08.\n",
      "  Completed iter 54500/70000. Training loss: 0.10.\n",
      "  Completed iter 54600/70000. Training loss: 0.08.\n",
      "  Completed iter 54700/70000. Training loss: 0.08.\n",
      "  Completed iter 54800/70000. Training loss: 0.10.\n",
      "  Completed iter 54900/70000. Training loss: 0.11.\n",
      "  Completed iter 55000/70000. Training loss: 0.08.\n",
      "  Completed iter 55100/70000. Training loss: 0.09.\n",
      "  Completed iter 55200/70000. Training loss: 0.07.\n",
      "  Completed iter 55300/70000. Training loss: 0.08.\n",
      "  Completed iter 55400/70000. Training loss: 0.11.\n",
      "  Completed iter 55500/70000. Training loss: 0.11.\n",
      "  Completed iter 55600/70000. Training loss: 0.07.\n",
      "  Completed iter 55700/70000. Training loss: 0.09.\n",
      "  Completed iter 55800/70000. Training loss: 0.12.\n",
      "  Completed iter 55900/70000. Training loss: 0.08.\n",
      "  Completed iter 56000/70000. Training loss: 0.08.\n",
      "  Completed iter 56100/70000. Training loss: 0.08.\n",
      "  Completed iter 56200/70000. Training loss: 0.09.\n",
      "  Completed iter 56300/70000. Training loss: 0.13.\n",
      "  Completed iter 56400/70000. Training loss: 0.12.\n",
      "  Completed iter 56500/70000. Training loss: 0.07.\n",
      "  Completed iter 56600/70000. Training loss: 0.09.\n",
      "  Completed iter 56700/70000. Training loss: 0.09.\n",
      "  Completed iter 56800/70000. Training loss: 0.09.\n",
      "  Completed iter 56900/70000. Training loss: 0.12.\n",
      "  Completed iter 57000/70000. Training loss: 0.06.\n",
      "  Completed iter 57100/70000. Training loss: 0.07.\n",
      "  Completed iter 57200/70000. Training loss: 0.08.\n",
      "  Completed iter 57300/70000. Training loss: 0.09.\n",
      "  Completed iter 57400/70000. Training loss: 0.10.\n",
      "  Completed iter 57500/70000. Training loss: 0.07.\n",
      "  Completed iter 57600/70000. Training loss: 0.09.\n",
      "  Completed iter 57700/70000. Training loss: 0.06.\n",
      "  Completed iter 57800/70000. Training loss: 0.07.\n",
      "  Completed iter 57900/70000. Training loss: 0.07.\n",
      "  Completed iter 58000/70000. Training loss: 0.05.\n",
      "  Completed iter 58100/70000. Training loss: 0.10.\n",
      "  Completed iter 58200/70000. Training loss: 0.09.\n",
      "  Completed iter 58300/70000. Training loss: 0.07.\n",
      "  Completed iter 58400/70000. Training loss: 0.10.\n",
      "  Completed iter 58500/70000. Training loss: 0.12.\n",
      "  Completed iter 58600/70000. Training loss: 0.09.\n",
      "  Completed iter 58700/70000. Training loss: 0.08.\n",
      "  Completed iter 58800/70000. Training loss: 0.12.\n",
      "  Completed iter 58900/70000. Training loss: 0.11.\n",
      "  Completed iter 59000/70000. Training loss: 0.09.\n",
      "  Completed iter 59100/70000. Training loss: 0.10.\n",
      "  Completed iter 59200/70000. Training loss: 0.09.\n",
      "  Completed iter 59300/70000. Training loss: 0.10.\n",
      "  Completed iter 59400/70000. Training loss: 0.09.\n",
      "  Completed iter 59500/70000. Training loss: 0.07.\n",
      "  Completed iter 59600/70000. Training loss: 0.08.\n",
      "  Completed iter 59700/70000. Training loss: 0.09.\n",
      "  Completed iter 59800/70000. Training loss: 0.10.\n",
      "  Completed iter 59900/70000. Training loss: 0.06.\n",
      "  Completed iter 60000/70000. Training loss: 0.08.\n",
      "  Completed iter 60100/70000. Training loss: 0.08.\n",
      "  Completed iter 60200/70000. Training loss: 0.07.\n",
      "  Completed iter 60300/70000. Training loss: 0.06.\n",
      "  Completed iter 60400/70000. Training loss: 0.09.\n",
      "  Completed iter 60500/70000. Training loss: 0.07.\n",
      "  Completed iter 60600/70000. Training loss: 0.09.\n",
      "  Completed iter 60700/70000. Training loss: 0.09.\n",
      "  Completed iter 60800/70000. Training loss: 0.05.\n",
      "  Completed iter 60900/70000. Training loss: 0.12.\n",
      "  Completed iter 61000/70000. Training loss: 0.06.\n",
      "  Completed iter 61100/70000. Training loss: 0.06.\n",
      "  Completed iter 61200/70000. Training loss: 0.09.\n",
      "  Completed iter 61300/70000. Training loss: 0.07.\n",
      "  Completed iter 61400/70000. Training loss: 0.10.\n",
      "  Completed iter 61500/70000. Training loss: 0.09.\n",
      "  Completed iter 61600/70000. Training loss: 0.05.\n",
      "  Completed iter 61700/70000. Training loss: 0.08.\n",
      "  Completed iter 61800/70000. Training loss: 0.08.\n",
      "  Completed iter 61900/70000. Training loss: 0.10.\n",
      "  Completed iter 62000/70000. Training loss: 0.09.\n",
      "  Completed iter 62100/70000. Training loss: 0.08.\n",
      "  Completed iter 62200/70000. Training loss: 0.08.\n",
      "  Completed iter 62300/70000. Training loss: 0.10.\n",
      "  Completed iter 62400/70000. Training loss: 0.07.\n",
      "  Completed iter 62500/70000. Training loss: 0.07.\n",
      "  Completed iter 62600/70000. Training loss: 0.09.\n",
      "  Completed iter 62700/70000. Training loss: 0.08.\n",
      "  Completed iter 62800/70000. Training loss: 0.09.\n",
      "  Completed iter 62900/70000. Training loss: 0.09.\n",
      "  Completed iter 63000/70000. Training loss: 0.07.\n",
      "  Completed iter 63100/70000. Training loss: 0.08.\n",
      "  Completed iter 63200/70000. Training loss: 0.09.\n",
      "  Completed iter 63300/70000. Training loss: 0.08.\n",
      "  Completed iter 63400/70000. Training loss: 0.07.\n",
      "  Completed iter 63500/70000. Training loss: 0.09.\n",
      "  Completed iter 63600/70000. Training loss: 0.12.\n",
      "  Completed iter 63700/70000. Training loss: 0.11.\n",
      "  Completed iter 63800/70000. Training loss: 0.08.\n",
      "  Completed iter 63900/70000. Training loss: 0.06.\n",
      "  Completed iter 64000/70000. Training loss: 0.06.\n",
      "  Completed iter 64100/70000. Training loss: 0.08.\n",
      "  Completed iter 64200/70000. Training loss: 0.08.\n",
      "  Completed iter 64300/70000. Training loss: 0.10.\n",
      "  Completed iter 64400/70000. Training loss: 0.08.\n",
      "  Completed iter 64500/70000. Training loss: 0.07.\n",
      "  Completed iter 64600/70000. Training loss: 0.10.\n",
      "  Completed iter 64700/70000. Training loss: 0.07.\n",
      "  Completed iter 64800/70000. Training loss: 0.07.\n",
      "  Completed iter 64900/70000. Training loss: 0.09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 65000/70000. Training loss: 0.09.\n",
      "  Completed iter 65100/70000. Training loss: 0.08.\n",
      "  Completed iter 65200/70000. Training loss: 0.05.\n",
      "  Completed iter 65300/70000. Training loss: 0.08.\n",
      "  Completed iter 65400/70000. Training loss: 0.07.\n",
      "  Completed iter 65500/70000. Training loss: 0.06.\n",
      "  Completed iter 65600/70000. Training loss: 0.09.\n",
      "  Completed iter 65700/70000. Training loss: 0.08.\n",
      "  Completed iter 65800/70000. Training loss: 0.07.\n",
      "  Completed iter 65900/70000. Training loss: 0.09.\n",
      "  Completed iter 66000/70000. Training loss: 0.08.\n",
      "  Completed iter 66100/70000. Training loss: 0.07.\n",
      "  Completed iter 66200/70000. Training loss: 0.04.\n",
      "  Completed iter 66300/70000. Training loss: 0.07.\n",
      "  Completed iter 66400/70000. Training loss: 0.08.\n",
      "  Completed iter 66500/70000. Training loss: 0.07.\n",
      "  Completed iter 66600/70000. Training loss: 0.09.\n",
      "  Completed iter 66700/70000. Training loss: 0.06.\n",
      "  Completed iter 66800/70000. Training loss: 0.10.\n",
      "  Completed iter 66900/70000. Training loss: 0.09.\n",
      "  Completed iter 67000/70000. Training loss: 0.07.\n",
      "  Completed iter 67100/70000. Training loss: 0.07.\n",
      "  Completed iter 67200/70000. Training loss: 0.09.\n",
      "  Completed iter 67300/70000. Training loss: 0.06.\n",
      "  Completed iter 67400/70000. Training loss: 0.07.\n",
      "  Completed iter 67500/70000. Training loss: 0.09.\n",
      "  Completed iter 67600/70000. Training loss: 0.08.\n",
      "  Completed iter 67700/70000. Training loss: 0.09.\n",
      "  Completed iter 67800/70000. Training loss: 0.07.\n",
      "  Completed iter 67900/70000. Training loss: 0.11.\n",
      "  Completed iter 68000/70000. Training loss: 0.11.\n",
      "  Completed iter 68100/70000. Training loss: 0.08.\n",
      "  Completed iter 68200/70000. Training loss: 0.09.\n",
      "  Completed iter 68300/70000. Training loss: 0.08.\n",
      "  Completed iter 68400/70000. Training loss: 0.08.\n",
      "  Completed iter 68500/70000. Training loss: 0.09.\n",
      "  Completed iter 68600/70000. Training loss: 0.09.\n",
      "  Completed iter 68700/70000. Training loss: 0.08.\n",
      "  Completed iter 68800/70000. Training loss: 0.07.\n",
      "  Completed iter 68900/70000. Training loss: 0.06.\n",
      "  Completed iter 69000/70000. Training loss: 0.05.\n",
      "  Completed iter 69100/70000. Training loss: 0.09.\n",
      "  Completed iter 69200/70000. Training loss: 0.06.\n",
      "  Completed iter 69300/70000. Training loss: 0.06.\n",
      "  Completed iter 69400/70000. Training loss: 0.12.\n",
      "  Completed iter 69500/70000. Training loss: 0.07.\n",
      "  Completed iter 69600/70000. Training loss: 0.08.\n",
      "  Completed iter 69700/70000. Training loss: 0.08.\n",
      "  Completed iter 69800/70000. Training loss: 0.09.\n",
      "  Completed iter 69900/70000. Training loss: 0.07.\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 50\n",
    "net = MLP(cis_train_x.shape[1], hidden_size, 2)\n",
    "loss, acc_t, acc_v = net.fit(cis_test_x, cis_test_y, cis_val_x, cis_val_y, reg=0, lr=0.01, mini_batch_sz=100, n_epochs=700)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Avg cross-entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 2\n",
    "In extension 2, we investigate how the single layer network performs on the CIS dataset. We use the best hyperparameter values that we found through grid search for the Single Layer Network, and find that the network does terribly. It does not have the power of the MLP to produce good results from so few data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train network...There will be 30000 epochs and 30000 iterations total, 1 iter/epoch.\n",
      "  Completed iter 0/30000. Training loss: 0.69.\n",
      "  Completed iter 100/30000. Training loss: 0.69.\n",
      "  Completed iter 200/30000. Training loss: 0.69.\n",
      "  Completed iter 300/30000. Training loss: 0.69.\n",
      "  Completed iter 400/30000. Training loss: 0.69.\n",
      "  Completed iter 500/30000. Training loss: 0.69.\n",
      "  Completed iter 600/30000. Training loss: 0.69.\n",
      "  Completed iter 700/30000. Training loss: 0.69.\n",
      "  Completed iter 800/30000. Training loss: 0.69.\n",
      "  Completed iter 900/30000. Training loss: 0.69.\n",
      "  Completed iter 1000/30000. Training loss: 0.69.\n",
      "  Completed iter 1100/30000. Training loss: 0.69.\n",
      "  Completed iter 1200/30000. Training loss: 0.69.\n",
      "  Completed iter 1300/30000. Training loss: 0.69.\n",
      "  Completed iter 1400/30000. Training loss: 0.69.\n",
      "  Completed iter 1500/30000. Training loss: 0.69.\n",
      "  Completed iter 1600/30000. Training loss: 0.69.\n",
      "  Completed iter 1700/30000. Training loss: 0.69.\n",
      "  Completed iter 1800/30000. Training loss: 0.70.\n",
      "  Completed iter 1900/30000. Training loss: 0.69.\n",
      "  Completed iter 2000/30000. Training loss: 0.68.\n",
      "  Completed iter 2100/30000. Training loss: 0.69.\n",
      "  Completed iter 2200/30000. Training loss: 0.70.\n",
      "  Completed iter 2300/30000. Training loss: 0.69.\n",
      "  Completed iter 2400/30000. Training loss: 0.68.\n",
      "  Completed iter 2500/30000. Training loss: 0.69.\n",
      "  Completed iter 2600/30000. Training loss: 0.69.\n",
      "  Completed iter 2700/30000. Training loss: 0.69.\n",
      "  Completed iter 2800/30000. Training loss: 0.68.\n",
      "  Completed iter 2900/30000. Training loss: 0.69.\n",
      "  Completed iter 3000/30000. Training loss: 0.69.\n",
      "  Completed iter 3100/30000. Training loss: 0.70.\n",
      "  Completed iter 3200/30000. Training loss: 0.69.\n",
      "  Completed iter 3300/30000. Training loss: 0.69.\n",
      "  Completed iter 3400/30000. Training loss: 0.68.\n",
      "  Completed iter 3500/30000. Training loss: 0.69.\n",
      "  Completed iter 3600/30000. Training loss: 0.69.\n",
      "  Completed iter 3700/30000. Training loss: 0.69.\n",
      "  Completed iter 3800/30000. Training loss: 0.69.\n",
      "  Completed iter 3900/30000. Training loss: 0.69.\n",
      "  Completed iter 4000/30000. Training loss: 0.69.\n",
      "  Completed iter 4100/30000. Training loss: 0.70.\n",
      "  Completed iter 4200/30000. Training loss: 0.68.\n",
      "  Completed iter 4300/30000. Training loss: 0.69.\n",
      "  Completed iter 4400/30000. Training loss: 0.68.\n",
      "  Completed iter 4500/30000. Training loss: 0.69.\n",
      "  Completed iter 4600/30000. Training loss: 0.69.\n",
      "  Completed iter 4700/30000. Training loss: 0.68.\n",
      "  Completed iter 4800/30000. Training loss: 0.70.\n",
      "  Completed iter 4900/30000. Training loss: 0.68.\n",
      "  Completed iter 5000/30000. Training loss: 0.69.\n",
      "  Completed iter 5100/30000. Training loss: 0.69.\n",
      "  Completed iter 5200/30000. Training loss: 0.70.\n",
      "  Completed iter 5300/30000. Training loss: 0.68.\n",
      "  Completed iter 5400/30000. Training loss: 0.68.\n",
      "  Completed iter 5500/30000. Training loss: 0.68.\n",
      "  Completed iter 5600/30000. Training loss: 0.69.\n",
      "  Completed iter 5700/30000. Training loss: 0.69.\n",
      "  Completed iter 5800/30000. Training loss: 0.69.\n",
      "  Completed iter 5900/30000. Training loss: 0.70.\n",
      "  Completed iter 6000/30000. Training loss: 0.69.\n",
      "  Completed iter 6100/30000. Training loss: 0.70.\n",
      "  Completed iter 6200/30000. Training loss: 0.70.\n",
      "  Completed iter 6300/30000. Training loss: 0.68.\n",
      "  Completed iter 6400/30000. Training loss: 0.70.\n",
      "  Completed iter 6500/30000. Training loss: 0.69.\n",
      "  Completed iter 6600/30000. Training loss: 0.70.\n",
      "  Completed iter 6700/30000. Training loss: 0.69.\n",
      "  Completed iter 6800/30000. Training loss: 0.69.\n",
      "  Completed iter 6900/30000. Training loss: 0.70.\n",
      "  Completed iter 7000/30000. Training loss: 0.69.\n",
      "  Completed iter 7100/30000. Training loss: 0.68.\n",
      "  Completed iter 7200/30000. Training loss: 0.69.\n",
      "  Completed iter 7300/30000. Training loss: 0.70.\n",
      "  Completed iter 7400/30000. Training loss: 0.69.\n",
      "  Completed iter 7500/30000. Training loss: 0.69.\n",
      "  Completed iter 7600/30000. Training loss: 0.68.\n",
      "  Completed iter 7700/30000. Training loss: 0.69.\n",
      "  Completed iter 7800/30000. Training loss: 0.69.\n",
      "  Completed iter 7900/30000. Training loss: 0.69.\n",
      "  Completed iter 8000/30000. Training loss: 0.70.\n",
      "  Completed iter 8100/30000. Training loss: 0.69.\n",
      "  Completed iter 8200/30000. Training loss: 0.68.\n",
      "  Completed iter 8300/30000. Training loss: 0.69.\n",
      "  Completed iter 8400/30000. Training loss: 0.69.\n",
      "  Completed iter 8500/30000. Training loss: 0.69.\n",
      "  Completed iter 8600/30000. Training loss: 0.70.\n",
      "  Completed iter 8700/30000. Training loss: 0.69.\n",
      "  Completed iter 8800/30000. Training loss: 0.69.\n",
      "  Completed iter 8900/30000. Training loss: 0.68.\n",
      "  Completed iter 9000/30000. Training loss: 0.69.\n",
      "  Completed iter 9100/30000. Training loss: 0.68.\n",
      "  Completed iter 9200/30000. Training loss: 0.68.\n",
      "  Completed iter 9300/30000. Training loss: 0.70.\n",
      "  Completed iter 9400/30000. Training loss: 0.70.\n",
      "  Completed iter 9500/30000. Training loss: 0.69.\n",
      "  Completed iter 9600/30000. Training loss: 0.69.\n",
      "  Completed iter 9700/30000. Training loss: 0.69.\n",
      "  Completed iter 9800/30000. Training loss: 0.69.\n",
      "  Completed iter 9900/30000. Training loss: 0.69.\n",
      "  Completed iter 10000/30000. Training loss: 0.69.\n",
      "  Completed iter 10100/30000. Training loss: 0.68.\n",
      "  Completed iter 10200/30000. Training loss: 0.69.\n",
      "  Completed iter 10300/30000. Training loss: 0.69.\n",
      "  Completed iter 10400/30000. Training loss: 0.69.\n",
      "  Completed iter 10500/30000. Training loss: 0.69.\n",
      "  Completed iter 10600/30000. Training loss: 0.69.\n",
      "  Completed iter 10700/30000. Training loss: 0.69.\n",
      "  Completed iter 10800/30000. Training loss: 0.68.\n",
      "  Completed iter 10900/30000. Training loss: 0.69.\n",
      "  Completed iter 11000/30000. Training loss: 0.69.\n",
      "  Completed iter 11100/30000. Training loss: 0.69.\n",
      "  Completed iter 11200/30000. Training loss: 0.69.\n",
      "  Completed iter 11300/30000. Training loss: 0.69.\n",
      "  Completed iter 11400/30000. Training loss: 0.70.\n",
      "  Completed iter 11500/30000. Training loss: 0.69.\n",
      "  Completed iter 11600/30000. Training loss: 0.68.\n",
      "  Completed iter 11700/30000. Training loss: 0.69.\n",
      "  Completed iter 11800/30000. Training loss: 0.69.\n",
      "  Completed iter 11900/30000. Training loss: 0.70.\n",
      "  Completed iter 12000/30000. Training loss: 0.69.\n",
      "  Completed iter 12100/30000. Training loss: 0.68.\n",
      "  Completed iter 12200/30000. Training loss: 0.69.\n",
      "  Completed iter 12300/30000. Training loss: 0.69.\n",
      "  Completed iter 12400/30000. Training loss: 0.69.\n",
      "  Completed iter 12500/30000. Training loss: 0.68.\n",
      "  Completed iter 12600/30000. Training loss: 0.69.\n",
      "  Completed iter 12700/30000. Training loss: 0.69.\n",
      "  Completed iter 12800/30000. Training loss: 0.70.\n",
      "  Completed iter 12900/30000. Training loss: 0.68.\n",
      "  Completed iter 13000/30000. Training loss: 0.70.\n",
      "  Completed iter 13100/30000. Training loss: 0.69.\n",
      "  Completed iter 13200/30000. Training loss: 0.69.\n",
      "  Completed iter 13300/30000. Training loss: 0.69.\n",
      "  Completed iter 13400/30000. Training loss: 0.68.\n",
      "  Completed iter 13500/30000. Training loss: 0.69.\n",
      "  Completed iter 13600/30000. Training loss: 0.68.\n",
      "  Completed iter 13700/30000. Training loss: 0.69.\n",
      "  Completed iter 13800/30000. Training loss: 0.68.\n",
      "  Completed iter 13900/30000. Training loss: 0.69.\n",
      "  Completed iter 14000/30000. Training loss: 0.69.\n",
      "  Completed iter 14100/30000. Training loss: 0.68.\n",
      "  Completed iter 14200/30000. Training loss: 0.69.\n",
      "  Completed iter 14300/30000. Training loss: 0.69.\n",
      "  Completed iter 14400/30000. Training loss: 0.68.\n",
      "  Completed iter 14500/30000. Training loss: 0.69.\n",
      "  Completed iter 14600/30000. Training loss: 0.69.\n",
      "  Completed iter 14700/30000. Training loss: 0.69.\n",
      "  Completed iter 14800/30000. Training loss: 0.69.\n",
      "  Completed iter 14900/30000. Training loss: 0.70.\n",
      "  Completed iter 15000/30000. Training loss: 0.68.\n",
      "  Completed iter 15100/30000. Training loss: 0.69.\n",
      "  Completed iter 15200/30000. Training loss: 0.69.\n",
      "  Completed iter 15300/30000. Training loss: 0.69.\n",
      "  Completed iter 15400/30000. Training loss: 0.70.\n",
      "  Completed iter 15500/30000. Training loss: 0.69.\n",
      "  Completed iter 15600/30000. Training loss: 0.69.\n",
      "  Completed iter 15700/30000. Training loss: 0.69.\n",
      "  Completed iter 15800/30000. Training loss: 0.68.\n",
      "  Completed iter 15900/30000. Training loss: 0.68.\n",
      "  Completed iter 16000/30000. Training loss: 0.69.\n",
      "  Completed iter 16100/30000. Training loss: 0.69.\n",
      "  Completed iter 16200/30000. Training loss: 0.70.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed iter 16300/30000. Training loss: 0.69.\n",
      "  Completed iter 16400/30000. Training loss: 0.68.\n",
      "  Completed iter 16500/30000. Training loss: 0.69.\n",
      "  Completed iter 16600/30000. Training loss: 0.69.\n",
      "  Completed iter 16700/30000. Training loss: 0.69.\n",
      "  Completed iter 16800/30000. Training loss: 0.70.\n",
      "  Completed iter 16900/30000. Training loss: 0.68.\n",
      "  Completed iter 17000/30000. Training loss: 0.69.\n",
      "  Completed iter 17100/30000. Training loss: 0.68.\n",
      "  Completed iter 17200/30000. Training loss: 0.68.\n",
      "  Completed iter 17300/30000. Training loss: 0.69.\n",
      "  Completed iter 17400/30000. Training loss: 0.69.\n",
      "  Completed iter 17500/30000. Training loss: 0.69.\n",
      "  Completed iter 17600/30000. Training loss: 0.69.\n",
      "  Completed iter 17700/30000. Training loss: 0.69.\n",
      "  Completed iter 17800/30000. Training loss: 0.68.\n",
      "  Completed iter 17900/30000. Training loss: 0.69.\n",
      "  Completed iter 18000/30000. Training loss: 0.69.\n",
      "  Completed iter 18100/30000. Training loss: 0.68.\n",
      "  Completed iter 18200/30000. Training loss: 0.69.\n",
      "  Completed iter 18300/30000. Training loss: 0.69.\n",
      "  Completed iter 18400/30000. Training loss: 0.69.\n",
      "  Completed iter 18500/30000. Training loss: 0.70.\n",
      "  Completed iter 18600/30000. Training loss: 0.70.\n",
      "  Completed iter 18700/30000. Training loss: 0.69.\n",
      "  Completed iter 18800/30000. Training loss: 0.68.\n",
      "  Completed iter 18900/30000. Training loss: 0.68.\n",
      "  Completed iter 19000/30000. Training loss: 0.69.\n",
      "  Completed iter 19100/30000. Training loss: 0.70.\n",
      "  Completed iter 19200/30000. Training loss: 0.69.\n",
      "  Completed iter 19300/30000. Training loss: 0.68.\n",
      "  Completed iter 19400/30000. Training loss: 0.69.\n",
      "  Completed iter 19500/30000. Training loss: 0.70.\n",
      "  Completed iter 19600/30000. Training loss: 0.69.\n",
      "  Completed iter 19700/30000. Training loss: 0.67.\n",
      "  Completed iter 19800/30000. Training loss: 0.69.\n",
      "  Completed iter 19900/30000. Training loss: 0.70.\n",
      "  Completed iter 20000/30000. Training loss: 0.69.\n",
      "  Completed iter 20100/30000. Training loss: 0.69.\n",
      "  Completed iter 20200/30000. Training loss: 0.69.\n",
      "  Completed iter 20300/30000. Training loss: 0.70.\n",
      "  Completed iter 20400/30000. Training loss: 0.69.\n",
      "  Completed iter 20500/30000. Training loss: 0.69.\n",
      "  Completed iter 20600/30000. Training loss: 0.69.\n",
      "  Completed iter 20700/30000. Training loss: 0.69.\n",
      "  Completed iter 20800/30000. Training loss: 0.68.\n",
      "  Completed iter 20900/30000. Training loss: 0.68.\n",
      "  Completed iter 21000/30000. Training loss: 0.69.\n",
      "  Completed iter 21100/30000. Training loss: 0.69.\n",
      "  Completed iter 21200/30000. Training loss: 0.69.\n",
      "  Completed iter 21300/30000. Training loss: 0.69.\n",
      "  Completed iter 21400/30000. Training loss: 0.68.\n",
      "  Completed iter 21500/30000. Training loss: 0.68.\n",
      "  Completed iter 21600/30000. Training loss: 0.69.\n",
      "  Completed iter 21700/30000. Training loss: 0.69.\n",
      "  Completed iter 21800/30000. Training loss: 0.70.\n",
      "  Completed iter 21900/30000. Training loss: 0.69.\n",
      "  Completed iter 22000/30000. Training loss: 0.69.\n",
      "  Completed iter 22100/30000. Training loss: 0.68.\n",
      "  Completed iter 22200/30000. Training loss: 0.69.\n",
      "  Completed iter 22300/30000. Training loss: 0.69.\n",
      "  Completed iter 22400/30000. Training loss: 0.69.\n",
      "  Completed iter 22500/30000. Training loss: 0.70.\n",
      "  Completed iter 22600/30000. Training loss: 0.69.\n",
      "  Completed iter 22700/30000. Training loss: 0.69.\n",
      "  Completed iter 22800/30000. Training loss: 0.69.\n",
      "  Completed iter 22900/30000. Training loss: 0.69.\n",
      "  Completed iter 23000/30000. Training loss: 0.68.\n",
      "  Completed iter 23100/30000. Training loss: 0.69.\n",
      "  Completed iter 23200/30000. Training loss: 0.68.\n",
      "  Completed iter 23300/30000. Training loss: 0.68.\n",
      "  Completed iter 23400/30000. Training loss: 0.69.\n",
      "  Completed iter 23500/30000. Training loss: 0.68.\n",
      "  Completed iter 23600/30000. Training loss: 0.68.\n",
      "  Completed iter 23700/30000. Training loss: 0.69.\n",
      "  Completed iter 23800/30000. Training loss: 0.69.\n",
      "  Completed iter 23900/30000. Training loss: 0.68.\n",
      "  Completed iter 24000/30000. Training loss: 0.68.\n",
      "  Completed iter 24100/30000. Training loss: 0.70.\n",
      "  Completed iter 24200/30000. Training loss: 0.69.\n",
      "  Completed iter 24300/30000. Training loss: 0.70.\n",
      "  Completed iter 24400/30000. Training loss: 0.69.\n",
      "  Completed iter 24500/30000. Training loss: 0.69.\n",
      "  Completed iter 24600/30000. Training loss: 0.69.\n",
      "  Completed iter 24700/30000. Training loss: 0.69.\n",
      "  Completed iter 24800/30000. Training loss: 0.69.\n",
      "  Completed iter 24900/30000. Training loss: 0.69.\n",
      "  Completed iter 25000/30000. Training loss: 0.68.\n",
      "  Completed iter 25100/30000. Training loss: 0.70.\n",
      "  Completed iter 25200/30000. Training loss: 0.68.\n",
      "  Completed iter 25300/30000. Training loss: 0.69.\n",
      "  Completed iter 25400/30000. Training loss: 0.68.\n",
      "  Completed iter 25500/30000. Training loss: 0.68.\n",
      "  Completed iter 25600/30000. Training loss: 0.69.\n",
      "  Completed iter 25700/30000. Training loss: 0.68.\n",
      "  Completed iter 25800/30000. Training loss: 0.69.\n",
      "  Completed iter 25900/30000. Training loss: 0.69.\n",
      "  Completed iter 26000/30000. Training loss: 0.69.\n",
      "  Completed iter 26100/30000. Training loss: 0.68.\n",
      "  Completed iter 26200/30000. Training loss: 0.68.\n",
      "  Completed iter 26300/30000. Training loss: 0.69.\n",
      "  Completed iter 26400/30000. Training loss: 0.68.\n",
      "  Completed iter 26500/30000. Training loss: 0.69.\n",
      "  Completed iter 26600/30000. Training loss: 0.68.\n",
      "  Completed iter 26700/30000. Training loss: 0.69.\n",
      "  Completed iter 26800/30000. Training loss: 0.69.\n",
      "  Completed iter 26900/30000. Training loss: 0.69.\n",
      "  Completed iter 27000/30000. Training loss: 0.69.\n",
      "  Completed iter 27100/30000. Training loss: 0.69.\n",
      "  Completed iter 27200/30000. Training loss: 0.68.\n",
      "  Completed iter 27300/30000. Training loss: 0.69.\n",
      "  Completed iter 27400/30000. Training loss: 0.69.\n",
      "  Completed iter 27500/30000. Training loss: 0.69.\n",
      "  Completed iter 27600/30000. Training loss: 0.68.\n",
      "  Completed iter 27700/30000. Training loss: 0.69.\n",
      "  Completed iter 27800/30000. Training loss: 0.68.\n",
      "  Completed iter 27900/30000. Training loss: 0.68.\n",
      "  Completed iter 28000/30000. Training loss: 0.69.\n",
      "  Completed iter 28100/30000. Training loss: 0.70.\n",
      "  Completed iter 28200/30000. Training loss: 0.69.\n",
      "  Completed iter 28300/30000. Training loss: 0.69.\n",
      "  Completed iter 28400/30000. Training loss: 0.68.\n",
      "  Completed iter 28500/30000. Training loss: 0.69.\n",
      "  Completed iter 28600/30000. Training loss: 0.70.\n",
      "  Completed iter 28700/30000. Training loss: 0.69.\n",
      "  Completed iter 28800/30000. Training loss: 0.68.\n",
      "  Completed iter 28900/30000. Training loss: 0.69.\n",
      "  Completed iter 29000/30000. Training loss: 0.69.\n",
      "  Completed iter 29100/30000. Training loss: 0.68.\n",
      "  Completed iter 29200/30000. Training loss: 0.69.\n",
      "  Completed iter 29300/30000. Training loss: 0.69.\n",
      "  Completed iter 29400/30000. Training loss: 0.70.\n",
      "  Completed iter 29500/30000. Training loss: 0.69.\n",
      "  Completed iter 29600/30000. Training loss: 0.69.\n",
      "  Completed iter 29700/30000. Training loss: 0.69.\n",
      "  Completed iter 29800/30000. Training loss: 0.69.\n",
      "  Completed iter 29900/30000. Training loss: 0.69.\n",
      "Finished training!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import single_layer_net as sln\n",
    "\n",
    "best_lr = .071\n",
    "best_reg = .18\n",
    "best_batch = 203\n",
    "\n",
    "net = sln.SingleLayerNetSoftmax()\n",
    "loss = net.fit(cis_train_x, cis_train_y,\n",
    "            lr=best_lr, reg=best_reg, mini_batch_sz=best_batch, n_epochs=30000, verbose=2)\n",
    "plt.plot(loss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
