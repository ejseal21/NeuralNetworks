{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cole Turner and Ethan Seal**\n",
    "\n",
    "Fall 2019\n",
    "\n",
    "CS343: Neural Networks\n",
    "\n",
    "Project 4: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "rgen = np.random.RandomState(1)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sanity check that Tensorflow is installed correctly:*\n",
    "\n",
    "Executing the following cell should return 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.print(tf.reduce_sum([tf.Variable(1), tf.Variable(2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1) Implement ConvNet4 in Tensorflow, train/test on STL-10\n",
    "\n",
    "### 1a) Use the high level `Keras::Sequential` API in Tensorflow 2.0 to implement the architecture of ConvNet4 from the last project. Train and test your network on the STL-10 dataset. \n",
    "\n",
    "Recall the `Keras::Sequential` common worflow:\n",
    "\n",
    "- Build structure of network with `keras::Sequential`.\n",
    "- Compile network with your choice of optimizer, loss, and metrics.\n",
    "- Fit the model (remembering to pass in the appropriate training and validation sets). This results a history object that can be used to examine training/validation accuracy and loss.\n",
    "- Evaluate the model on the test set. This returns test loss and accuracy.\n",
    "\n",
    "**Notes**:\n",
    "- You should use the usual STL-10 data acquistion and preprocessing code from your last project.\n",
    "- You don't need to do a hyperparameter search. Values that worked on the CNN project should get you in the ballpark here. The goal is to show that you know how to put together a `keras::Sequential` model and have it work successfully.\n",
    "- Tensorflow needs the RGB color channel AFTER the spatial dimensions. For example: (64, 64, 3), not (3, 64, 64). You may therefore need to slightly modify the preprocesssing pipeline for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These documentation pages should be helpful:\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_stl10_dataset\n",
    "from preprocess_data import preprocess_stl, create_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_imgs, stl_labels = load_stl10_dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.loadtxt(os.path.join('data', 'stl10_binary', 'class_names.txt'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess image pixel values for the MLP net\n",
    "stl_imgs, stl_labels = preprocess_stl(stl_imgs, stl_labels)\n",
    "print(f'stl_imgs dtype is {stl_imgs.dtype} and it should be float64')\n",
    "print(f'stl_imgs max is {np.max(stl_imgs[:, 1:]):.3f} and it should be 0.668')\n",
    "print(f'stl_imgs shape is {stl_imgs.shape} and it should be (5000, 32, 32, 3)')\n",
    "print(f'stl_labels span {stl_labels.min()}->{stl_labels.max()} and it should be 0->9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = create_splits(stl_imgs, stl_labels)  \n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Make 2 \"high quality\" plots showing the following\n",
    "\n",
    "- Plot the training and validation accuracy (y axis) over training epochs (x axis).\n",
    "- Plot the training and validation loss (y axis) over epochs (x axis).\n",
    "\n",
    "A high quality plot consists of:\n",
    "- A useful title\n",
    "- X and Y axis labels\n",
    "- A legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** What accuracy do you get on the STL-10 test set? Briefly summarize the hyperparameters that you used to obtain this result.\n",
    "\n",
    "**Question 2:** How do the loss and accurary results compare to the CNN projct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2) Transfer learning\n",
    "\n",
    "Use Tensorflow 2.0 to download the pre-trained MobileNetV2 network (you may also use InceptionV3, but MobileNetV2 likely will run noticeably faster on your machine). We will use transfer learning to accelerate training to solve a novel problem: **the binary classification task of discriminating whether an image is of a hotdog or not.**\n",
    "\n",
    "### Overview of the task\n",
    "\n",
    "- Run some hotdog-or-not dataset images through the network. How does the net seem to classify things correctly?\n",
    "- Remove the output layer.\n",
    "- Add a new Dense output layer.\n",
    "- Freeze (disable) training on all non-output layers.\n",
    "- Train the last layer on a food dataset. Assess performance. Plot some example images and their classification below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "- Get the **food dataset** on filer: `Courses/CS343/Course_Materials/hot-dog-not-hot-dog`. Copy it into a `data` subfolder in your project directory.\n",
    "- Run the below code to load in the hot-dog-or-not dataset. Check the shapes to ensure everything is loaded in correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Load in hotdot image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_base_dir = 'data/hot-dog-not-hot-dog/numpy/'\n",
    "hotdog_train_x = np.load(os.path.join(ds_base_dir, 'train_x.npy'))\n",
    "hotdog_train_y = np.load(os.path.join(ds_base_dir, 'train_y.npy'))\n",
    "hotdog_test_x = np.load(os.path.join(ds_base_dir, 'test_x.npy'))\n",
    "hotdog_test_y = np.load(os.path.join(ds_base_dir, 'test_y.npy'))\n",
    "\n",
    "print(f'Training hotdog split shape: {hotdog_train_x.shape}. Should be (16000, 96, 96, 3)')\n",
    "print(f'Test hotdog split shape: {hotdog_test_x.shape}. Should be (4000, 96, 96, 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Preprocess hotdog dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_train_x = 2*(hotdog_train_x - 0.5)\n",
    "hotdog_test_x = 2*(hotdog_test_x - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Create hotdog validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PROP = 0.2  # proportion of trainng set to reserve for validation\n",
    "VAL_SZ = int(VAL_PROP*len(hotdog_train_x))\n",
    "hotdog_val_x = hotdog_train_x[-VAL_SZ:]\n",
    "hotdog_val_y = hotdog_train_y[-VAL_SZ:]\n",
    "hotdog_train_x = hotdog_train_x[:len(hotdog_train_x)-VAL_SZ]\n",
    "hotdog_train_y = hotdog_train_y[:len(hotdog_train_y)-VAL_SZ]\n",
    "\n",
    "print(f'Validation hotdog split shape: {hotdog_train_x.shape}. Should be (12800, 96, 96, 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) Load in pre-trained MobileNetV2 network.\n",
    "\n",
    "**TODO:**\n",
    "- Load in pre-trained MobileNetV2 network (look up constructor in `tf.keras.applications` or look at the tutorial from class) and set it to a variable called `model`. https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "- Set the `trainable` field of the model object to be `False` (use dot notation).\n",
    "- If you call the `summary()` method on the network object, you should see a table with many rows. The top and bottom rows should be:\n",
    "\n",
    "\n",
    "    input_3 (InputLayer)            [(None, 96, 96, 3)]  0                                           \n",
    "    __________________________________________________________________________________________________\n",
    "    out_relu (ReLU)                 (None, 3, 3, 1280)   0           Conv_1_bn[0][0]  \n",
    "\n",
    "and you should see the following at the bottom:\n",
    "\n",
    "    Total params: 2,257,984\n",
    "    Trainable params: 0\n",
    "    Non-trainable params: 2,257,984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e) Replace output layer\n",
    "\n",
    "**TODO:**\n",
    "- Create a Dense layer object with the correct number of units to deal with the hot-dog or not problem, which will be the new output layer. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "- Create a new `keras/Sequential` model object composed of a Python list of the following:\n",
    "    - the original model object\n",
    "    - \"Flatten layer\"\n",
    "    - the dense output layer\n",
    "- Compile the augmented model with the Adam optimizer (learning rate of 0.0001), binary_crossentropy loss, and accuracy metric. https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam https://www.tensorflow.org/api_docs/python/tf/losses\n",
    "\n",
    "A summary on the augmented model should yield:\n",
    "\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    mobilenetv2_1.00_96 (Model)  (None, 3, 3, 1280)        2257984   \n",
    "    _________________________________________________________________\n",
    "    flatten_4 (Flatten)          (None, 11520)             0         \n",
    "    _________________________________________________________________\n",
    "    dense_4 (Dense)              (None, 1)                 11521     \n",
    "    =================================================================\n",
    "    Total params: 2,269,505\n",
    "    Trainable params: 11,521\n",
    "    Non-trainable params: 2,257,984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** What is the accuracy and loss for the network with the untrained output layer?\n",
    "\n",
    "**Question 4:** Briefly defend your choice of number of units in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f) Fit the augmented model on the hotdog training data\n",
    "\n",
    "**Notes**\n",
    "- Remember to also pass in the hotdog validation data. Train for 10 epochs with a batch size of 32.\n",
    "- Setting the verbose optional parameter to 2 will give you helpful printouts of performance on the validation set as it completes every epoch of training.\n",
    "\n",
    "\n",
    "**NOTE:**\n",
    "- If training time is taking much more 2.5 minutes per epoch on your computer, you could try reducing the number of data samples in train and validation. For example, by default train `N = 12800`. Try `N = 6400` instead. You could do the same for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2g) Plot hotdog results\n",
    "\n",
    "Produce 2 high quality plots showing the following:\n",
    "\n",
    "- Training and validation loss over epoch.\n",
    "- Training and validation accuracy over epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** What accuracy do you achieve on the test set? Briefly summarize the hyperparameters that were used in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
