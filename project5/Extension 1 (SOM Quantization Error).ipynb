{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension: SOM quantization error\n",
    "\n",
    "Do an analysis (make plots, explain findings) where you investigate how various SOM parameters affect the quantization error. Parameters you might experiment with are:\n",
    "- iteration count\n",
    "- SOM size\n",
    "\n",
    "**NOTE:** Some parameters may need to adjusted together in some fashion. For example, decreasing the SOM size decreases the grid size. Therefore, the Gaussian neighborhood size $\\sigma$ probably needs to be rescaled, as does the learning rate (how much vectors move around in the space duing each update)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Summary\n",
    "In this project we try a bunch of different SOM Sizes, then Learning Rates with and without those SOM sizes, and finally adjustments to Sigma, with and without the SOM Sizes and Learning Rates. We attempt to see what changes cause what and where we can make improvements.\n",
    "\n",
    "We find that overall, SOM Size at the larger level provides the lowest final Quantization error. I hypothesize this is because there is more to learn with a larger SOM size. For example, when we use 500, we have a final error of .1 while using size 7 gives us about .03. Over time, there can be more finegrained stuff we learn with a larger grid size and make the distance between nodes closer. \n",
    "\n",
    "Learning rate is also important. Learning Rate causes the most changes in the first iteration. This is because it changes the distance that different nodes can move. If we have a large grid and the nodes can only move a small distance, this would increase error for the first iteration. This is because a small change would not consitute the distance needed to travel. So, increasing error rate helps our first iteration have lower error unless we make learning rate too high and the node moves too much. However, over time as more iterations are done, learning rate decays and we do not view and changes to later errors. Overall, high LR = More first iteration accuracy and a low LR has high first iteration error. \n",
    "\n",
    "Sigma has little changes to add. We see a slight change in the range Sigma [7, 15]. Overall though, outside that range, which only creates a first iteration change of [.14, .16], we view no change. Therefore, Sigma 15 and Sigma 500 cause no difference. Same thing with Sigma 7 and Sigma .0005. This is interesting because it probably has to do with the Sigma Decay. \n",
    "\n",
    "Overall this extension was super interesting. I thought Learning Rate would cause bigger adjustments than it did and mapping this all in my head to movement on euclidean axes was helpful. I understand what the hyperparameters do significantly more now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "iris.head()\n",
    "# make iris_x\n",
    "iris_x = iris.copy()\n",
    "iris_x = iris_x.drop(columns='species')\n",
    "iris_x = iris_x.to_numpy()\n",
    "for i in range(iris_x.shape[0]):\n",
    "    iris_x[i] = iris_x[i] / np.linalg.norm(iris_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# make iris_y\n",
    "iris_y = iris['species']\n",
    "# print(iris_y)\n",
    "int_coded = pd.factorize(iris_y)\n",
    "# print(int_coded)\n",
    "iris_y = int_coded[0]\n",
    "print(iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.15\n",
      "Your initial u-matrix is (before any training):\n",
      "[[0.268 0.495 0.516 0.496 0.635 0.582 0.39 ]\n",
      " [0.538 0.956 0.931 0.794 0.776 0.771 0.464]\n",
      " [0.506 0.911 0.831 0.988 1.    0.751 0.502]\n",
      " [0.524 0.771 0.748 0.85  0.879 0.886 0.618]\n",
      " [0.405 0.745 0.755 0.714 0.782 0.907 0.586]\n",
      " [0.586 0.798 0.733 0.761 0.801 0.959 0.494]\n",
      " [0.311 0.508 0.44  0.409 0.48  0.548 0.417]]\n",
      "Your u-matrix is (after 1 step):\n",
      "[[0.267 0.494 0.516 0.498 0.643 0.595 0.4  ]\n",
      " [0.532 0.946 0.924 0.794 0.782 0.783 0.473]\n",
      " [0.497 0.894 0.819 0.98  1.    0.755 0.51 ]\n",
      " [0.511 0.753 0.732 0.837 0.872 0.885 0.621]\n",
      " [0.392 0.721 0.734 0.698 0.771 0.902 0.587]\n",
      " [0.564 0.771 0.71  0.741 0.787 0.951 0.495]\n",
      " [0.3   0.49  0.425 0.398 0.471 0.543 0.416]]\n",
      "\n",
      "Quantization error after 100 iterations: 0.07\n",
      "Your u-matrix is (after 100 steps):\n",
      "[[0.131 0.271 0.289 0.261 0.217 0.147 0.066]\n",
      " [0.348 0.549 0.529 0.479 0.386 0.285 0.137]\n",
      " [0.518 0.774 0.719 0.63  0.518 0.398 0.218]\n",
      " [0.634 0.971 0.913 0.797 0.647 0.515 0.289]\n",
      " [0.618 0.965 1.    0.905 0.734 0.572 0.316]\n",
      " [0.448 0.839 0.926 0.923 0.781 0.637 0.343]\n",
      " [0.266 0.445 0.576 0.593 0.501 0.412 0.169]]\n",
      "\n",
      "Quantization error after 1000 iterations: 0.03\n"
     ]
    }
   ],
   "source": [
    "som_sz = 7\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 0:\n",
    "Above is out first, normal plot from the regular notebook. We will use this as a baseline.\n",
    "It has an error output of [.15, .07, .03]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM Size Changes\n",
    "### Decreases\n",
    "In these next several code blocks, we will be messing around with SOM size. First we will decrease then eventually increase SOM size. Learning Rate and Sigma will not be touched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.22\n",
      "Your initial u-matrix is (before any training):\n",
      "[[0.291 0.445 0.519 0.41  0.259]\n",
      " [0.636 0.829 0.868 0.863 0.505]\n",
      " [0.411 0.68  0.768 0.742 0.542]\n",
      " [0.502 0.758 0.84  1.    0.537]\n",
      " [0.294 0.574 0.5   0.463 0.303]]\n",
      "Your u-matrix is (after 1 step):\n",
      "[[0.29  0.442 0.514 0.406 0.257]\n",
      " [0.636 0.826 0.862 0.855 0.501]\n",
      " [0.413 0.679 0.764 0.738 0.539]\n",
      " [0.506 0.761 0.84  1.    0.537]\n",
      " [0.298 0.579 0.503 0.464 0.304]]\n",
      "\n",
      "Quantization error after 100 iterations: 0.08\n",
      "Your u-matrix is (after 100 steps):\n",
      "[[0.304 0.5   0.606 0.554 0.23 ]\n",
      " [0.51  0.922 0.997 0.916 0.538]\n",
      " [0.617 1.    0.973 0.811 0.444]\n",
      " [0.56  0.891 0.8   0.595 0.296]\n",
      " [0.217 0.519 0.433 0.292 0.155]]\n",
      "\n",
      "Quantization error after 1000 iterations: 0.04\n"
     ]
    }
   ],
   "source": [
    "som_sz = 5\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1: Decreasing SOM size to 5\n",
    "When we decrease out SOM, we get a higher error rate. This is only decreasing to SOM: 5 but it has a [.22,.08,.04] output, higher across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.23\n",
      "Your initial u-matrix is (before any training):\n",
      "[[0.287 0.588 0.498]\n",
      " [0.385 1.    0.853]\n",
      " [0.289 0.697 0.512]]\n",
      "Your u-matrix is (after 1 step):\n",
      "[[0.288 0.589 0.499]\n",
      " [0.385 1.    0.853]\n",
      " [0.289 0.696 0.511]]\n",
      "\n",
      "Quantization error after 100 iterations: 0.13\n",
      "Your u-matrix is (after 100 steps):\n",
      "[[0.264 0.645 0.484]\n",
      " [0.6   1.    0.645]\n",
      " [0.414 0.594 0.267]]\n",
      "\n",
      "Quantization error after 1000 iterations: 0.09\n"
     ]
    }
   ],
   "source": [
    "som_sz = 3\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 2: Decreasing SOM size to 3\n",
    "SOM Size = 3 is again causing us a higher error rate. More significantly now. Our grid size is getting small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.34\n",
      "Your initial u-matrix is (before any training):\n",
      "[[0.647 0.951]\n",
      " [1.    0.672]]\n",
      "Your u-matrix is (after 1 step):\n",
      "[[0.647 0.951]\n",
      " [1.    0.672]]\n",
      "\n",
      "Quantization error after 100 iterations: 0.17\n",
      "Your u-matrix is (after 100 steps):\n",
      "[[0.498 1.   ]\n",
      " [0.969 0.498]]\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 3: Decreasing SOM size to 2\n",
    "Now our SOM size is at 2. This is small enough to cause large errors. This is obviously more inefficient than a larger SOM size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Your initial u-matrix is (before any training):\n",
      "[[0.28  0.562 0.482 0.572 0.598 0.604 0.583 0.636 0.343]\n",
      " [0.59  0.805 0.784 0.852 0.981 0.868 0.915 0.854 0.617]\n",
      " [0.617 0.909 0.97  1.    0.734 0.791 0.837 0.973 0.555]\n",
      " [0.554 0.911 0.898 0.864 0.8   0.784 0.9   0.999 0.582]\n",
      " [0.536 0.891 0.882 0.938 0.92  0.997 0.838 0.832 0.557]\n",
      " [0.586 0.88  0.889 0.936 0.909 0.833 0.782 0.859 0.541]\n",
      " [0.619 0.679 0.645 0.782 0.952 0.823 0.955 0.802 0.578]\n",
      " [0.521 0.814 0.618 0.715 0.893 0.869 0.76  0.888 0.583]\n",
      " [0.386 0.545 0.547 0.457 0.529 0.547 0.559 0.515 0.353]]\n",
      "Your u-matrix is (after 1 step):\n",
      "[[0.288 0.574 0.489 0.576 0.599 0.604 0.582 0.636 0.344]\n",
      " [0.605 0.82  0.793 0.855 0.979 0.865 0.909 0.85  0.616]\n",
      " [0.631 0.924 0.978 1.    0.73  0.784 0.828 0.963 0.55 ]\n",
      " [0.563 0.922 0.903 0.86  0.791 0.773 0.886 0.986 0.575]\n",
      " [0.545 0.902 0.885 0.933 0.91  0.981 0.825 0.82  0.55 ]\n",
      " [0.598 0.89  0.892 0.933 0.901 0.822 0.77  0.848 0.535]\n",
      " [0.632 0.69  0.651 0.782 0.946 0.815 0.943 0.794 0.574]\n",
      " [0.535 0.83  0.626 0.718 0.892 0.866 0.756 0.885 0.582]\n",
      " [0.398 0.557 0.555 0.461 0.532 0.547 0.56  0.515 0.354]]\n",
      "\n",
      "Quantization error after 100 iterations: 0.05\n",
      "Your u-matrix is (after 100 steps):\n",
      "[[0.338 0.478 0.419 0.42  0.384 0.303 0.264 0.268 0.093]\n",
      " [0.558 0.82  0.762 0.742 0.698 0.607 0.495 0.404 0.229]\n",
      " [0.48  0.772 0.823 0.882 0.858 0.811 0.706 0.613 0.381]\n",
      " [0.414 0.704 0.817 0.877 0.956 0.926 0.845 0.708 0.43 ]\n",
      " [0.347 0.61  0.731 0.844 0.935 1.    0.949 0.84  0.494]\n",
      " [0.274 0.455 0.554 0.665 0.768 0.868 0.908 0.896 0.537]\n",
      " [0.193 0.328 0.402 0.489 0.56  0.618 0.721 0.743 0.448]\n",
      " [0.097 0.186 0.269 0.347 0.412 0.461 0.57  0.687 0.44 ]\n",
      " [0.035 0.109 0.148 0.187 0.226 0.262 0.305 0.446 0.265]]\n",
      "\n",
      "Quantization error after 1000 iterations: 0.03\n"
     ]
    }
   ],
   "source": [
    "som_sz = 9\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing SOM Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 4: Increasing SOM size to 9\n",
    "Our first cell had error of  [.15, .07, .03]. We see here an error of [.14,.05,.03] This is a small decrease and could be boiled down to randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Your initial u-matrix is (before any training):\n",
      "[[0.314 0.563 0.519 0.537 0.515 0.528 0.5   0.619 0.534 0.572 0.401]\n",
      " [0.482 0.785 0.887 0.808 0.829 0.918 0.871 0.791 0.853 0.957 0.504]\n",
      " [0.397 0.779 0.792 0.872 0.852 0.96  0.862 0.854 0.808 0.808 0.459]\n",
      " [0.475 0.96  0.902 0.824 0.847 0.881 0.916 0.842 1.    0.764 0.432]\n",
      " [0.364 0.738 0.824 0.793 0.81  0.84  0.736 0.774 0.779 0.848 0.608]\n",
      " [0.376 0.704 0.666 0.674 0.855 0.909 0.722 0.809 0.799 0.829 0.477]\n",
      " [0.368 0.865 0.943 0.682 0.695 0.739 0.916 0.773 0.852 0.853 0.436]\n",
      " [0.597 0.778 0.741 0.812 0.809 0.99  0.719 0.868 0.805 0.847 0.432]\n",
      " [0.582 0.764 0.979 0.917 0.795 0.763 0.821 0.696 0.71  0.776 0.526]\n",
      " [0.586 0.74  0.815 0.821 0.792 0.809 0.794 0.796 0.749 0.818 0.407]\n",
      " [0.296 0.601 0.475 0.485 0.439 0.507 0.504 0.465 0.577 0.465 0.281]]\n",
      "Your u-matrix is (after 1 step):\n",
      "[[0.321 0.572 0.522 0.533 0.505 0.515 0.484 0.594 0.512 0.547 0.384]\n",
      " [0.495 0.797 0.89  0.801 0.811 0.891 0.839 0.757 0.813 0.912 0.481]\n",
      " [0.406 0.791 0.793 0.862 0.832 0.93  0.828 0.816 0.768 0.767 0.436]\n",
      " [0.487 0.973 0.902 0.814 0.826 0.85  0.878 0.803 0.949 0.725 0.41 ]\n",
      " [0.374 0.749 0.825 0.784 0.792 0.813 0.707 0.738 0.741 0.806 0.578]\n",
      " [0.386 0.715 0.669 0.668 0.839 0.882 0.696 0.775 0.763 0.79  0.455]\n",
      " [0.378 0.883 0.951 0.681 0.685 0.721 0.888 0.745 0.818 0.817 0.418]\n",
      " [0.616 0.797 0.752 0.812 0.804 0.974 0.702 0.844 0.78  0.818 0.417]\n",
      " [0.605 0.788 1.    0.926 0.796 0.756 0.807 0.682 0.693 0.756 0.513]\n",
      " [0.613 0.771 0.839 0.836 0.801 0.812 0.791 0.789 0.741 0.807 0.401]\n",
      " [0.314 0.628 0.494 0.497 0.448 0.513 0.507 0.466 0.574 0.462 0.281]]\n",
      "\n",
      "Quantization error after 100 iterations: 0.04\n",
      "Your u-matrix is (after 100 steps):\n",
      "[[0.194 0.268 0.241 0.271 0.354 0.338 0.34  0.289 0.201 0.177 0.096]\n",
      " [0.224 0.373 0.397 0.404 0.525 0.552 0.557 0.459 0.308 0.271 0.175]\n",
      " [0.17  0.287 0.344 0.404 0.514 0.597 0.543 0.497 0.391 0.298 0.179]\n",
      " [0.148 0.235 0.313 0.414 0.474 0.574 0.566 0.503 0.457 0.418 0.219]\n",
      " [0.164 0.227 0.284 0.376 0.455 0.546 0.568 0.528 0.496 0.502 0.326]\n",
      " [0.147 0.213 0.248 0.349 0.431 0.487 0.533 0.531 0.559 0.549 0.346]\n",
      " [0.137 0.214 0.234 0.28  0.38  0.476 0.482 0.557 0.619 0.631 0.323]\n",
      " [0.13  0.198 0.205 0.247 0.341 0.429 0.457 0.532 0.674 0.705 0.413]\n",
      " [0.115 0.185 0.23  0.273 0.314 0.454 0.469 0.553 0.647 0.967 0.56 ]\n",
      " [0.151 0.194 0.233 0.292 0.277 0.442 0.6   0.618 0.802 1.    0.799]\n",
      " [0.09  0.149 0.155 0.187 0.199 0.307 0.475 0.483 0.537 0.785 0.476]]\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 11\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 5: Increasing SOM size to 11\n",
    "Considering more decrease in error, especially after 1000 iterations, we can start to see that increasing SOM size might be quite useful. Our initial error is not decreasing however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.15\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 20\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 6: Increasing SOM size to 20\n",
    "This plot does not have much change except maybe that it is important to view the difference in error in the first iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 7: Increasing SOM size to 25\n",
    "Here we see another increase in error in the first iteration. This could be because with a larger grid size, the initial values are spaced further apart, increasing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.15\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.01\n"
     ]
    }
   ],
   "source": [
    "som_sz = 50\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 8: Increasing SOM size to 50\n",
    "A SOM Size of 50 nets us a very low final error. Our initial error does not increase as we hypothesized above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.02\n",
      "Quantization error after 100 iterations: 0.02\n",
      "\n",
      "Quantization error after 1000 iterations: 0.01\n"
     ]
    }
   ],
   "source": [
    "som_sz = 500\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 9: Increasing SOM size to 500\n",
    "This is the big kahuna, what happens if we blow the SOM size out of the water to 500. We result in a low initial error, secondary error and final error. This is interesting because maybe there is overall more information being learned or space for clustering causing a decrease in error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decreasing Learning Rate with SOM Changes\n",
    "What happens if we change the learning rate to reflect our SOM changes? We will explore below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.24\n",
      "Quantization error after 100 iterations: 0.08\n",
      "\n",
      "Quantization error after 1000 iterations: 0.04\n"
     ]
    }
   ],
   "source": [
    "som_sz = 5\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.15, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 10: Decreasing SOM size to 5 and LR to .15\n",
    "Here we see an increase in the error here. Compared to the standard SOM 5 above,  [.22,.08,.04], we have a slight overall error increase in the first iteration, though that could be random, and no change in the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.25\n",
      "Quantization error after 100 iterations: 0.13\n",
      "\n",
      "Quantization error after 1000 iterations: 0.09\n"
     ]
    }
   ],
   "source": [
    "som_sz = 3\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.1, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 11: Decreasing SOM size to 3 and LR to .1\n",
    "Again , we increase in our first iteration. Above, our SOM size of 3 and LR of .2 gave us: [.23, .13, .09]. Learning rate isn't helping us but not hurting us either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.37\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.08, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 12: Decreasing SOM size to 2 and LR to .08\n",
    "Here we have an increase in error in the first iteration. However, we have no change in error in the second and third sets of iterations. Above we had: [.34, .17, .16]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.38\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.02, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 13: Decreasing SOM size to 2 and LR to .02\n",
    "Again, we have an increase in the error after 1 iteration. This is likely because the values can't move as far to handle change and therefore do not get close on the first iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.35\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.15, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 14: Decreasing SOM size to 2 and LR to .15\n",
    "Now, we are increasing our learning rate briefly. We have an increase in accuracy after our first iteration. Again: [.34, .17, .16] was our original, with .2. Do we increase over a Learning Rate of .02 here, yes. It seems there is movement in that first iteration that is heavily influenced by learning rate but at this SOM Size, the Learning Rate has little influence over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.39\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.001, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 15: Decreasing SOM size to 2 and LR to .001\n",
    "Just to be thorough, let's heavily decrease our Learning Rate. Again, we see an increase in error after our first iteration. Remember, our first one was [.34, .17, .16] with a learning rate of .2. This is a decent size change in our first iteration but not overall disasterous with decrease at lower levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing Learning Rate With SOM SZ 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.33\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 16: Decreasing SOM size to 2 and LR to .25\n",
    "We increased out learning rate here to beyond .2 and we immdiately see an increase over .2 in our first iteration in error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing SOM Size and Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.13\n",
      "Quantization error after 100 iterations: 0.05\n",
      "\n",
      "Quantization error after 1000 iterations: 0.03\n"
     ]
    }
   ],
   "source": [
    "som_sz = 9\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 17: Increasing SOM size to 9 and LR to .25\n",
    "Here we have a decrease in our first iteration again. This makes sense considering our finidings above. Let's remember this output from our first SOM SZ 9 and LR .2: [.14,.05,.03]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.13\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 20\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.35, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 18: Increasing SOM size to 20 and LR to .35\n",
    "Our SOM SZ 20 and LR 2 had [.15, .03, .02]. We see no change again except int he first iteration where higher learning rate would matter more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.02\n",
      "Quantization error after 100 iterations: 0.02\n",
      "\n",
      "Quantization error after 1000 iterations: 0.01\n"
     ]
    }
   ],
   "source": [
    "som_sz = 500\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 19: Increasing SOM size to 500 and LR to 2\n",
    "The Big Kahuna is back! This Learning Rate of 2 is large, the SOM SZ is large, and now our results are good! We actually have no increase in change over the first SOM Size of 500 and LR of .2, but that is okay. Considering the SOM Size and the absurd Learning Rate, we have not got too much difference negatively, or positively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiddling With Learning Rate at LR 25. Increasing First."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.15\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.3, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 20: Increasing SOM size to 25 and LR to .3\n",
    "We had [.16, .03, .02] in our error cascade earlier with a learning rate of .2. Here we have better results than we did earlier. This is unsurprising and falls right in with what we learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.4, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 21: Increasing SOM size to 25 and LR to .4\n",
    "Again, falling right in line here is the increase in accuracy in our first iteration. At this point, we seem to be beating the dead horse, but we are looking for any decrease in error over time. Again, LR .2 for SOM SZ 25 is: [.16, .03, .02]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.13\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.5, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 22: Increasing SOM size to 25 and LR to .5\n",
    "Here is a decrease in the first iteration again, not much to see or learn here. We are also decreasing error over previous LR's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.11\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.7, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 23: Increasing SOM size to 25 and LR to .7\n",
    "Again, decrease in first iteration error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.10\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=.9, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 24: Increasing SOM size to 25 and LR to .9\n",
    "We are pushing the learning rate high now and no changes over later iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.09\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=2, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 25: Increasing SOM size to 25 and LR to 2\n",
    "Now, we are starting to get absurd with the learning rates and not learning much at later iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.15\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=20, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 26: Increasing SOM size to 25 and LR to 20\n",
    "WE HAVE CHANGES! Our learning rate in our first iteration causes it to go haywire. We likely overshot the first iteration big time and therefore increased our error heavily as we moved datapoints too far. It took an extremely high Learning Rate to do so, but it is possible..\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Sigma with Learning Rate and SOM Size. Decreasing First."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.24\n",
      "Quantization error after 100 iterations: 0.08\n",
      "\n",
      "Quantization error after 1000 iterations: 0.04\n"
     ]
    }
   ],
   "source": [
    "som_sz = 5\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.15, init_sigma=8.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 27: Decreasing SOM size to 5 and LR to .15 and Sigma to 8\n",
    "Our initial error iterations are [.22,.08,.04]. We have an increase consistent with our learning rate errors. Sigma seems to provide no change here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.25\n",
      "Quantization error after 100 iterations: 0.13\n",
      "\n",
      "Quantization error after 1000 iterations: 0.09\n"
     ]
    }
   ],
   "source": [
    "som_sz = 3\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.1, init_sigma=5.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 28: Decreasing SOM size to 3 and LR to .1 and Sigma to 5\n",
    "Our first plot at SOM 3 LR 2 and Sigma 10 is: [.23, .13, .09]. This has the same increase of our first iteration in the Learning Rate increase, which is consistent here. Sigma doesn't seem to cause any changes so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.37\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.08, init_sigma=3.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 29: Decreasing SOM size to 2 and LR to .08 and Sigma to 3\n",
    "This is the same error cascade as our learning rate increase without the Sigma change. Our original one was: [.34, .17, .16]. Again, no influence from Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.38\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.02, init_sigma=1.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 30: Decreasing SOM size to 2 and LR to .02 and Sigma to 1\n",
    "This is the same increase in error rate with the first iteration. Again, Sigma changes nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.39\n",
      "Quantization error after 100 iterations: 0.17\n",
      "\n",
      "Quantization error after 1000 iterations: 0.16\n"
     ]
    }
   ],
   "source": [
    "som_sz = 2\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.001, init_sigma=.01, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 31: Decreasing SOM size to 2 and LR to .001 and Sigma to 0.01\n",
    "There is only an increase in the first iteration error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing LR, Sigma and SOM SZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.13\n",
      "Quantization error after 100 iterations: 0.05\n",
      "\n",
      "Quantization error after 1000 iterations: 0.03\n"
     ]
    }
   ],
   "source": [
    "som_sz = 9\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=12.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 32: Increasing SOM size to 9 and LR to .25 and Sigma to 12\n",
    "We have the same error rate as with the above vanilla SOM Sz=9 and LR=.2. Our original was: [.14,.05,.03]. Again, not seeing so many changes with Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.13\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 20\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.35, init_sigma=18.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 33: Increasing SOM size to 20 and LR to .35 and Sigma to 18\n",
    "Our vanilla had: [.15, .03, .02]. We now have the exact same as with no change to Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.02\n",
      "Quantization error after 100 iterations: 0.02\n",
      "\n",
      "Quantization error after 1000 iterations: 0.01\n"
     ]
    }
   ],
   "source": [
    "som_sz = 500\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=2, init_sigma=50.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 34: Increasing SOM size to 500 and LR to 2 and Sigma to 50\n",
    "Another Big Kahuna, another no change. Sigma isn't changing us here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing Sigma with SOM SZ = 25 and LR = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.15\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=10.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 35: Baseline. [.15, .03, .02]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=15.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 36: Increasing SOM size to 25 and LR to .25 and Sigma to 15\n",
    "We see a first iteration change again! This constitutes a decrease overall in the first iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=25.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 37: Increasing SOM size to 25 and LR to .25 and Sigma to 25\n",
    "This is no change from Sigma. It is becoming apparent Sigma has little influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=50.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 38: Increasing SOM size to 25 and LR to .25 and Sigma to 50\n",
    "We have an increase in Sigma to 50 here and again no change from earlier Sigmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.14\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=500.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 39: Increasing SOM size to 25 and LR to .25 and Sigma to 500\n",
    "A Sigma Big Kahuna and we get nowhere! Sigma at 500 provides no change. This is likely because of decay rate providing most of the difference, or Sigma has little overall influence on error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=7.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 40: Decreasing SOM size to 25 and LR to .25 and Sigma to 7\n",
    "This actually increases our error slightly for the first iteration but has no change on later iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=5.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 41: Decreasing SOM size to 25 and LR to .25 and Sigma to 5\n",
    "This provides no change again, Sigma maintaining the same line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=2.0, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 42: Decreasing SOM size to 25 and LR to .25 and Sigma to 2\n",
    "Again, Sigma changes nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=.8, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 43: Decreasing SOM size to 25 and LR to .25 and Sigma to 0.8\n",
    "Same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=.05, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 44: Decreasing SOM size to 25 and LR to .25 and Sigma to 0.05\n",
    "Our Sigma is super small and we had no difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error after 1 iterations: 0.16\n",
      "Quantization error after 100 iterations: 0.03\n",
      "\n",
      "Quantization error after 1000 iterations: 0.02\n"
     ]
    }
   ],
   "source": [
    "som_sz = 25\n",
    "n_features = 4\n",
    "max_iter = 1\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.25, init_sigma=.0005, verbose=False)\n",
    "iris_u_map0 = iris_som.u_matrix()\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your initial u-matrix is (before any training):\\n{iris_u_map0}')\n",
    "# print(f'Your u-matrix is (after 1 step):\\n{iris_u_map}\\n')\n",
    "\n",
    "max_iter = 100\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "iris_u_map2 = iris_som.u_matrix()\n",
    "print(f'Quantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')\n",
    "# print(f'Your u-matrix is (after 100 steps):\\n{iris_u_map2}')\n",
    "\n",
    "max_iter = 1000\n",
    "iris_som = som.SOM(som_sz, n_features, max_iter, init_lr=0.2, init_sigma=10.0, verbose=False)\n",
    "iris_som.fit(iris_x.copy())\n",
    "print(f'\\nQuantization error after {max_iter} iterations: {iris_som.error(iris_x):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 45: Decreasing SOM size to 25 and LR to .25 and Sigma to 0.0005\n",
    "Even with a tiny Sigma, we receive no difference. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
