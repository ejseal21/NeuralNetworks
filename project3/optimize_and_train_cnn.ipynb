{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cole Turner and Ethan Seal**\n",
    "\n",
    "Fall 2019\n",
    "\n",
    "CS343: Neural Networks\n",
    "\n",
    "Project 3: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global note: Make sure any debug printouts do not appear if `verbose=False`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4) Implement weight optimizers for gradient descent\n",
    "\n",
    "To change the weights during training, we need an optimization algorithm to have our loss decrease over epochs as we learn the structure of the input patterns. Until now, we used **Stochastic gradient descent (SGD)**, which is the simplest algorithm. We will implement 3 popular algorithms:\n",
    "\n",
    "- `SGD` (stochastic gradient descent)\n",
    "- `SGD_Momentum` (stochastic gradient descent with momentum)\n",
    "- `Adam` (Adaptive Moment Estimation)\n",
    "\n",
    "Implement each of these according to the update equations (in `optimizer.py::update_weights` in each subclass). Let's use $w_t$ in the math below to represent the weights in a layer at time step $t$, $dw$ to represent the gradient of the weights in a layer, and $\\eta$ represent the learning rate. We use vectorized notation below (update applies to all weights element-wise). Then:\n",
    "\n",
    "**SGD**: \n",
    "\n",
    "$w_{t} = w_{t-1} - \\eta \\times dw$\n",
    "\n",
    "**SGD (momentum)**:\n",
    "\n",
    "$v_{t} = m \\times v_{t-1} - \\eta \\times dw$\n",
    "\n",
    "$w_{t} = w_{t-1} + v_t$\n",
    "\n",
    "where $v_t$ is called the `velocity` at time $t$. At the first time step (0), velocity should be set to all zeros and have the same shape as $w$. $m$ is a constant that determines how much of the gradient obtained on the previous time step should factor into the weight update for the current time step.\n",
    "\n",
    "\n",
    "**Adam**:\n",
    "\n",
    "$m_{t} = \\beta_1 \\times m_{t-1} + (1 - \\beta_1)\\times dw$\n",
    "\n",
    "$v_{t} = \\beta_2 \\times v_{t-1} + (1 - \\beta_2)\\times dw^2$\n",
    "\n",
    "$n = m_{t} / \\left (1-(\\beta_1^t) \\right )$\n",
    "\n",
    "$u = v_{t} / \\left (1-(\\beta_2^t) \\right )$\n",
    "\n",
    "$w_{t} = w_{t-1} - \\left ( \\eta \\times n \\right ) / \\left ( \\sqrt(u) + \\epsilon \\right ) $\n",
    "\n",
    "\n",
    "Like SGD (momentum), Adam records momentum terms $m$ and $v$. At time step 0, you should initialize them to zeros in an array equal in size to the weights. $n$ and $u$ are variables computed on each time step. The remaining quantities are constants. Note that $t$ keeps track of the integer time step, and needs to be incremented on each update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGD' object has no attribute 'velocity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0b6831f7cdb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_wts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnew_wts_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\onedrive\\documents\\classes\\NeuralNetworks\\project3\\optimizer.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, wts, d_wts)\u001b[0m\n\u001b[0;32m     17\u001b[0m         '''Stores weights and their gradient before an update step is performed.\n\u001b[0;32m     18\u001b[0m         '''\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvelocity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvelocity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SGD' object has no attribute 'velocity'"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.arange(-3, 3, dtype=np.float64)\n",
    "d_wts = np.random.randn(len(wts))\n",
    "\n",
    "optimizer = SGD()\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "\n",
    "print(f'SGD: Wts after 1 iter {new_wts_1}')\n",
    "print(f'SGD: Wts after 2 iter {new_wts_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    SGD: Wts after 1 iter [-3.1764052 -2.0400157 -1.0978738 -0.2240893  0.8132442  2.0977278]\n",
    "    SGD: Wts after 2 iter [-3.3528105 -2.0800314 -1.1957476 -0.4481786  0.6264884  2.1954556]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test SGD_Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD M: Wts after 1 iter\n",
      "[[ 1.6879486  0.3879897  0.9343517  2.2075258]\n",
      " [ 1.7181501 -0.9567621  0.9187816 -0.0659476]\n",
      " [ 0.1520801  0.3452366  0.0576     1.52849  ]]\n",
      "SGD M: Wts after 2 iter\n",
      "[[ 1.5661825  0.3685217  0.8633335  2.1541379]\n",
      " [ 1.4790974 -0.9239367  0.8686908  0.0707077]\n",
      " [ 0.5605585  0.2406577 -0.0807098  1.6472364]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.random.randn(3, 4)\n",
    "d_wts = np.random.randn(3, 4)\n",
    "\n",
    "optimizer = SGD_Momentum(lr=0.1, m=0.6)\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "\n",
    "print(f'SGD M: Wts after 1 iter\\n{new_wts_1}')\n",
    "print(f'SGD M: Wts after 2 iter\\n{new_wts_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    SGD M: Wts after 1 iter\n",
    "    [[ 1.6879486  0.3879897  0.9343517  2.2075258]\n",
    "     [ 1.7181501 -0.9567621  0.9187816 -0.0659476]\n",
    "     [ 0.1520801  0.3452366  0.0576     1.52849  ]]\n",
    "    SGD M: Wts after 2 iter\n",
    "    [[ 1.5661825  0.3685217  0.8633335  2.1541379]\n",
    "     [ 1.4790974 -0.9239367  0.8686908  0.0707077]\n",
    "     [ 0.5605585  0.2406577 -0.0807098  1.6472364]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Wts after 1 iter\n",
      "[[ 1.6640523  0.3001572  0.878738   2.1408932]\n",
      " [ 1.767558  -0.8772779  0.8500884 -0.0513572]\n",
      " [-0.0032189  0.3105985  0.0440436  1.5542735]]\n",
      "Adam: Wts after 2 iter\n",
      "[[ 1.5640523  0.2001572  0.778738   2.0408932]\n",
      " [ 1.667558  -0.7772779  0.7500884  0.0486428]\n",
      " [ 0.0967811  0.2105985 -0.0559564  1.6542735]]\n",
      "Adam: Wts after 3 iter\n",
      "[[ 1.4640523  0.1001572  0.678738   1.9408932]\n",
      " [ 1.567558  -0.6772779  0.6500884  0.1486428]\n",
      " [ 0.1967811  0.1105985 -0.1559564  1.7542735]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.random.randn(3, 4)\n",
    "d_wts = np.random.randn(3, 4)\n",
    "\n",
    "optimizer = Adam(lr=0.1)\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "new_wts_3 = optimizer.update_weights()\n",
    "\n",
    "print(f'Adam: Wts after 1 iter\\n{new_wts_1}')\n",
    "print(f'Adam: Wts after 2 iter\\n{new_wts_2}')\n",
    "print(f'Adam: Wts after 3 iter\\n{new_wts_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    Adam: Wts after 1 iter\n",
    "    [[ 1.6640523  0.3001572  0.878738   2.1408932]\n",
    "     [ 1.767558  -0.8772779  0.8500884 -0.0513572]\n",
    "     [-0.0032189  0.3105985  0.0440436  1.5542735]]\n",
    "    Adam: Wts after 2 iter\n",
    "    [[ 1.5640523  0.2001572  0.778738   2.0408932]\n",
    "     [ 1.667558  -0.7772779  0.7500884  0.0486428]\n",
    "     [ 0.0967811  0.2105985 -0.0559564  1.6542735]]\n",
    "    Adam: Wts after 3 iter\n",
    "    [[ 1.4640523  0.1001572  0.678738   1.9408932]\n",
    "     [ 1.567558  -0.6772779  0.6500884  0.1486428]\n",
    "     [ 0.1967811  0.1105985 -0.1559564  1.7542735]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5) Write network training methods\n",
    "\n",
    "Implement methods in `network.py` to actually train the network, using all the building blocks that you have created. The methods to implement are:\n",
    "\n",
    "- `predict`\n",
    "- `fit`. Add an optional parameter `print_every=1` that controls the frequency (in iterations) with which to wait before printing out the loss and iteration number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6) Overfitting a convolutional neural network\n",
    "\n",
    "Usually we try to prevent overfitting, but we can use it as a valuable debugging tool to test out a complex backprop-style neural network. Assuming everything is working, it is almost always the case that we should be able to overfit a tiny dataset with a huge model with tons of parameters (i.e. your CNN). You will use this strategy to verify that your network is working.\n",
    "\n",
    "Let's use a small amount of real data from STL-10. If everything is working properly, the network should overfit and you should see a significant drop in the loss from its starting value of ~2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a) Move your `preprocess_data.py` from the MLP project\n",
    "\n",
    "Make the one following change:\n",
    "\n",
    "- Re-arrange dimensions of `imgs` so that when it is returned, `shape=(Num imgs, RGB color chans, height, width)` (No longer flatten non-batch dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_stl10_dataset\n",
    "import preprocess_data\n",
    "from network import ConvNet4\n",
    "import optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b) Load in STL-10 at 16x16 resolution\n",
    "\n",
    "If you don't want to wait for STL-10 to download from the internet and resize, copy over your data and numpy folders from your MLP project.\n",
    "\n",
    "**Notes:**\n",
    "- You will need to download the new version of `load_stl10_dataset`.\n",
    "- The different train/test split here won't work if you hard coded the proportions in your `create_splits` implementation! *This isn't catastrophic, it just means that it will take longer to compute accuracy on the validation set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are: (5000, 96, 96, 3)\n",
      "Labels are: (5000,)\n",
      "Resizing 5000 images to 16x16...Done!\n",
      "Saving Numpy arrays the images and labels to ./numpy...Done!\n",
      "imgs.shape (5000, 16, 16, 3)\n",
      "data.shape (5000, 768)\n",
      "Train data shape:  (4548, 768)\n",
      "Train labels shape:  (4548,)\n",
      "Test data shape:  (400, 768)\n",
      "Test labels shape:  (400,)\n",
      "Validation data shape:  (2, 768)\n",
      "Validation labels shape:  (2,)\n",
      "dev data shape:  (50, 768)\n",
      "dev labels shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "# Download the STL-10 dataset from the internet, convert it to Numpy ndarray, resize to 16x16\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "load_stl10_dataset.purge_cached_dataset()\n",
    "stl_imgs, stl_labels = load_stl10_dataset.load(scale_fact=6)\n",
    "# preprocess\n",
    "stl_imgs, stl_labels = preprocess_data.preprocess_stl(stl_imgs, stl_labels)\n",
    "# create splits\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.create_splits(\n",
    "    stl_imgs, stl_labels, n_train_samps=4548, n_test_samps=400, n_valid_samps=2, n_dev_samps=50)\n",
    "\n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)\n",
    "\n",
    "classes = np.loadtxt(os.path.join('data', 'stl10_binary', 'class_names.txt'), dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c) Train and overfit the network on a small STL-10 sample with each optimizer\n",
    "\n",
    "**Goal:** If your network works, you should see a drop in loss over epochs to 0.\n",
    "\n",
    "In 3 seperate cells below\n",
    "\n",
    "- Create 3 different `ConvNet4` networks.\n",
    "- Compile each with a different optimizer (each net uses a different optimizer).\n",
    "- Train each on the **dev** set and validate on the tiny validation set (we dont care about out-of-training-set performance here).\n",
    "\n",
    "You will be making plots demonstrating the overfitting for each optimizer below. **You should train the nets with the same number of epochs such that at least 2/3 of them clearly show loss convergence to a small value; one optimizer may not converge yet, and that's ok**. Cut off the simulations based on the 2/3 that do converge.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- Weight scales and learning rates of `1e-2` should work well.\n",
    "- Start by testing the Adam optimizer.\n",
    "- Remember that the input shape is (3, 16, 16). You need to specify this to the network constructor.\n",
    "- The hyperparameters are up to you, though I wouldn't recommend a batch size that is too small (close to 1), otherwise it may be tricky to see whether the loss is actually decreasing on average.\n",
    "- Decreasing `acc_freq` will make the `fit` function evaluate the training and validation accuracy more often. This is a computationally intensive process, so small values come with an increase in training time. On the other hand, checking the accuracy too infrequently means you won't know whether the network is trending toward overfitting the training data, which is what you're checking for.\n",
    "- Each training session takes ~30 mins on my laptop.\n",
    "\n",
    "**Caveat emptor:** Training convolutional networks is notoriously computationally intensive. If you experiment with hyperparameters, each training session may take several hours. Use the loss/accuracy print outs to quickly gauge whether your hyperparameter choices are getting your network to decrease in loss. Monitor print outs and interrupt the Jupyter kernel if things are not trending in the right direction. Consider using the Davis 102 iMacs if this is running too slow on your laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_scale = 1e-2\n",
    "lr = 1e-2\n",
    "input_shape = (3, 16, 16)\n",
    "mini_batch_sz = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "50 iterations. 5 iter/epoch.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_samps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1b7e298a9ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvNet4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwt_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwt_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0madam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0madam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_sz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini_batch_sz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\onedrive\\documents\\classes\\NeuralNetworks\\project3\\network.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, y_train, x_validate, y_validate, mini_batch_sz, n_epochs, acc_freq, print_every)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;31m#generate random indices with replacement for cur_samps and cur_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;31m#indices are guaranteed to match for samps and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mrandom_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini_batch_sz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mcur_samps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mcur_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_samps' is not defined"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "\n",
    "adam = ConvNet4(input_shape=input_shape, wt_scale=wt_scale)\n",
    "adam.compile('adam')\n",
    "adam.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=mini_batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Why does decreasing the mini-batch size make the loss print-outs more erratic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6d) Evaluate the different optimizers\n",
    "\n",
    "Make 2 \"high quality\" plots showing the following\n",
    "\n",
    "- Plot the accuracy (y axis) for the three optimizers as a function of training epoch (x axis).\n",
    "- Plot the loss (y axis) for the three optimizers as a function of training iteration (x axis).\n",
    "\n",
    "A high quality plot consists of:\n",
    "- A useful title\n",
    "- X and Y axis labels\n",
    "- A legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Which optimizer works best and why do think it is best?\n",
    "\n",
    "**Question 5**: What is happening with the training set accuracy and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Training convolutional neural network on STL-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a) Load in STL-10 at 32x32 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the STL-10 dataset from the internet, convert it to Numpy ndarray, resize to 32x32\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "load_stl10_dataset.purge_cached_dataset()\n",
    "stl_imgs, stl_labels = load_stl10_dataset.load(scale_fact=3)\n",
    "# preprocess\n",
    "stl_imgs, stl_labels = preprocess_data.preprocess_stl(stl_imgs, stl_labels)\n",
    "# create splits\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.create_splits(\n",
    "    stl_imgs, stl_labels, n_train_samps=4548, n_test_samps=400, n_valid_samps=2, n_dev_samps=50)\n",
    "\n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)\n",
    "\n",
    "classes = np.loadtxt(os.path.join('data', 'stl10_binary', 'class_names.txt'), dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b) Set up accelerated convolution and max pooling layers\n",
    "\n",
    "As you may have noticed, we had to downsize STL-10 to 16x16 resolution to train the network on the dev set (N=50) in a reasonable amount of time. The training set is N=4000, how will we ever manage to process that amount of data!?\n",
    "\n",
    "On one hand, this is an unfortunate inevitable reality of working with large (\"big\") datasets: you can easily find a dataset that is too time consuming to process for any computer, despite how fast/many CPU/GPUs it has.\n",
    "\n",
    "On the other hand, we can do better for this project and STL-10 :) If you were to time (profile) different parts of the training process, you'd notice that largest bottleneck is convolution and max pooling operations (both forward/backward). You implemented those operations intuitively, which does not always yield the best performance. **By swapping out forward/backward convolution and maxpooling for implementations that use different algorithms (im2col, reshaping) that are compiled to C code, we will speed up training up by several orders of magnitude**.\n",
    "\n",
    "Follow these steps to subsitute in the \"accelerated\" convolution and max pooling layers.\n",
    "\n",
    "- Install the `cython` python package: `pip3 install cython` (or `pip3 install cython --user` if working in Davis 102)\n",
    "- Dowload files `im2col_cython.pyx`, `accelerated_layer.py`, `setup.py` from the project website. Put them in your base project folder.\n",
    "- Open terminal, `cd` to Project directory.\n",
    "- Compile the im2col functions: `python3 setup.py build_ext --inplace`. A `.c` and `.so` file should have appeared in your project folder.\n",
    "- Restart Jupyter Notebook kernel\n",
    "- Create a class called `Conv4NetAccel` in `network.py` by copy-pasting the contents of `Conv4Net`. Import `accelerated_layer` at the top and replace the `Conv2D` and `MaxPool2D` layers with `Conv2DAccel` and `MaxPool2DAccel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c) Training convolutional neural network on STL-10\n",
    "\n",
    "You are now ready to train on the entire training set.\n",
    "\n",
    "- Create a `Conv4NetAccel` object with hyperparameters of your choice.\n",
    "- Your goal is to achieve 45% accuracy on the test and/or validation set.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- I suggest using your intuition about hyperparameters and over/underfitting to guide your choice, rather than a grid search. This should not be overly challenging.\n",
    "- Use the best / most efficient optimizer based on your prior analysis.\n",
    "- It should take on the order of 1 sec per training iteration. If that's way off, seek help as something could be wrong with running the acclerated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import ConvNet4Accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d) Analysis of STL-10 training quality\n",
    "\n",
    "Use your trained network that achieves 45%+ accuracy on the test set to make \"high quality\" plots showing the following \n",
    "\n",
    "- Plot the accuracy of the training and validation sets as a function of training epoch. You may have to convert iterations to epochs.\n",
    "- Plot the loss as a function of training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(netT.validation_acc_history)\n",
    "plt.plot(netT.train_acc_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(netT.loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7f) Visualize layer weights\n",
    "\n",
    "Run the following code and submit the inline image of the weight visualization of the 1st layer (convolutional layer) of the network.\n",
    "\n",
    "**Note:**\n",
    "- Setting optional parameter to `True` will let you save a .PNG file in your project folder of your weights. I'd suggest setting it to `False` unless look at your weights and they look like they are worth saving. You don't want a training run that produces undesirable weights to overwrite your good looking results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(wts, saveFig=True, filename='convWts_adam_overfit.png'):\n",
    "    grid_sz = int(np.sqrt(len(wts)))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for x in range(grid_sz):\n",
    "        for y in range(grid_sz):\n",
    "            lin_ind = np.ravel_multi_index((x, y), dims=(grid_sz, grid_sz))\n",
    "            plt.subplot(grid_sz, grid_sz, lin_ind+1)\n",
    "            currImg = wts[lin_ind]\n",
    "            low, high = np.min(currImg), np.max(currImg)\n",
    "            currImg = 255*(currImg - low) / (high - low)\n",
    "            currImg = currImg.astype('uint8')\n",
    "            plt.imshow(currImg)\n",
    "            plt.gca().axis('off')\n",
    "    if saveFig:\n",
    "        plt.savefig('convWts_adam_overfit.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsitute your trained network below\n",
    "# netT is my network's name\n",
    "# You shouldn't see RGB noise\n",
    "plot_weights(netT.layers[0].wts.transpose(0, 2, 3, 1), saveFig=False, filename='convWts_adam_train_20epoch.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** What do the learned filters look like? Does this make sense to you / is this what you expected? In which area of the brain do these filters resemble cell receptive fields?\n",
    "\n",
    "Note: you should not see RGB \"noise\". If you do, and you pass the \"overfit\" test with the Adam optimizer, you probably need to increase the number of training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "**General advice:** When making modifications for extensions, make small changes, then check to make sure you pass test code. Also, test out the network runtime on small examples before/after the changes. If you're not careful, the simulation time can become intractable really quickly!\n",
    "\n",
    "**Remember:** One thorough extension usually is worth more than several \"shallow\" extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Pedal to the metal: achieve high accuracy on STL-10\n",
    "\n",
    "You can achieve higher (>50%) classification accuracy on the STL-10 test set. Find the hyperparameters to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Experiment with different network architectures.\n",
    "\n",
    "The design of the `Network` class is modular. As long as you're careful about shapes, adding/removing network layers (e.g. `Conv2D`, `Dense`, etc.) should be straight forward. Experiment with adding another sequence of `Conv2D` and `MaxPooling2D` layers. Add another `Dense` hidden layer before the output layer. How do the changes affect classification accuracy and loss? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Experiment with different network hyperparameters.\n",
    "\n",
    "Explore the affect one or more change below has on classification. Be careful about how the hyperparameters may affect the shape of network layers. Thorough analysis will get you more points (not try a few ad hoc values).\n",
    "\n",
    "- Experiment with different numbers of hidden units in the Dense layers.\n",
    "- Experiment different max pooling window sizes and strides.\n",
    "- Experiment with kernel sizes (not 7x7). Can you get away with smaller ones? Do they perform just as well? What is the change in runtime like? What is the impact on their visualized appearance?\n",
    "- Experiment with number of kernels in the convolutional layer. Is more/fewer better? What is the impact on their visualized appearance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Add and test some training bells and whistles\n",
    "\n",
    "Add features like early stopping, learning rate decay (learning rate at the end of an epoch becomes some fraction of its former value), etc and assess how they affect training loss convergence and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Additional optimizers\n",
    "\n",
    "Research other optimizers used in backpropogation and implement one or more of them within the model structure. Compare its performance to ones you have implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Optimize your algorithms\n",
    "\n",
    "Find the main performance bottlenecks in the network and improve your code to reduce runtime (e.g. reduce explicit for loops, increase vectorization, etc). Research faster algorithms to do operations like convolution and implement them. Given the complexity of the network, I suggest focusing on one area at a time and make sure everything you change passes the test code before proceeding. Quantify and discuss your performance improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Additional loss functions\n",
    "\n",
    "Implement support for sigmoid, or another activation functions and associated losses. Test it out and compare with softmax/cross entropy. Make sure any necessary changes to the layer's gradient are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Additional datasets\n",
    "\n",
    "Do classification and analyxe the results with an image dataset of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Performance analysis\n",
    "\n",
    "Do a thorough comparative analysis of the non-accelerated network and accelerated networks with respect to runtime."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
